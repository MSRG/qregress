/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /home/gjones/scratch/sine5qubits/sine_train.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/sine5qubits/sine_test.bin... 
Successfully loaded /home/gjones/scratch/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/sine5qubits/sine_train.bin 
 at time Mon Apr  8 15:02:35 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 15:02:52 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:11:34 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 15:14:32 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:23:27 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 15:30:31 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 15:32:39 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:41:40 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 15:43:05 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 15:51:54 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3087.9217505455017 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 15:54:19 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:02:48 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 16:05:43 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:14:19 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 16:21:28 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 16:23:40 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:32:51 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 16:34:19 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:43:07 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3070.4342494010925 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 16:45:30 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 16:53:56 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 16:56:48 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:05:27 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 17:12:34 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 17:14:44 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:23:52 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 17:25:19 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:34:10 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3066.6326785087585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 17:36:37 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:45:12 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 17:48:06 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 17:56:51 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 18:03:58 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 18:06:07 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:15:11 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 18:16:37 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:25:21 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3069.773622751236 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 18:27:47 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:36:16 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 18:39:08 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 18:47:46 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 18:54:53 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 18:57:07 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:06:12 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 19:07:40 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:16:32 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3073.0811247825623 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 19:19:01 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:27:37 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 19:30:28 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:39:04 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 19:46:11 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 19:48:25 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 19:57:27 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 19:58:52 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:07:40 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3069.434851169586 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  8 20:10:09 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:18:44 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 20:21:38 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:30:17 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 20:37:20 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 20:39:27 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:48:33 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 20:49:59 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 20:58:43 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3059.2462282180786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  8 21:01:08 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:09:41 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 21:12:34 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:21:11 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 21:28:11 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 21:30:21 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:39:24 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 21:40:49 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 21:49:34 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3049.3676419258118 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  8 21:52:03 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:00:28 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 22:03:20 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:11:51 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 22:18:58 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 22:21:07 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:30:16 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 22:31:43 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:40:36 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3067.204726457596 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  8 22:43:05 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 22:51:36 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 22:54:32 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:03:18 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Mon Apr  8 23:10:24 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Mon Apr  8 23:12:32 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:21:41 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Mon Apr  8 23:23:10 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:31:52 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3074.472794532776 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  8 23:34:19 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:43:01 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Mon Apr  8 23:45:52 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  8 23:54:30 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 00:01:42 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 00:03:57 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:12:55 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 00:14:20 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:23:11 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3077.8279025554657 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 00:25:37 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:34:12 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 00:37:03 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 00:45:41 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 00:52:52 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 00:55:00 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:04:10 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 01:05:36 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:14:25 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3074.732490539551 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 01:16:52 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:25:22 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 01:28:15 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:36:52 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 01:43:51 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 01:45:58 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 01:55:07 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 01:56:33 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:05:23 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3055.231747150421 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 02:07:48 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:16:13 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 02:19:04 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:27:43 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 02:34:48 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 02:36:58 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:46:05 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 02:47:31 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 02:56:15 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3056.7231917381287 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 02:58:44 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:07:13 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 03:10:09 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:18:47 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 03:25:47 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 03:27:56 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:37:01 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 03:38:29 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:47:13 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3056.1557166576385 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 03:49:40 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 03:58:13 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 04:01:07 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:09:46 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 04:16:51 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 04:18:58 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:27:59 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 04:29:29 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:38:13 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3059.317540407181 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 04:40:40 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 04:49:09 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 04:51:59 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:00:33 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 05:07:47 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 05:09:58 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:19:02 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 05:20:28 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:29:13 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3064.905330657959 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 05:31:44 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:40:20 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 05:43:14 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 05:51:51 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 05:58:50 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 06:01:02 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:10:09 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 06:11:35 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:20:34 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3075.392522096634 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 06:22:59 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:31:28 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 06:34:19 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 06:43:03 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 06:49:58 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 06:52:08 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:01:16 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 07:02:44 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:11:40 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3063.7485308647156 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 07:14:03 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:22:28 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 07:25:21 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:33:59 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 07:41:03 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 07:43:13 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 07:52:34 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 07:54:02 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:02:54 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3076.1573984622955 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  9 08:05:20 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:13:48 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 08:16:41 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:25:19 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 08:32:17 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 08:34:26 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:43:27 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 08:44:52 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 08:53:36 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3041.3975126743317 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  9 08:56:01 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:04:40 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 09:07:32 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:16:13 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 09:23:07 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 09:25:17 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:34:08 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 09:35:38 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:44:20 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3048.554368019104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  9 09:46:49 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 09:55:28 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 09:58:19 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:07:01 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 10:14:02 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 10:16:12 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:25:18 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 10:26:45 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:35:42 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3083.6408536434174 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  9 10:38:13 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:46:40 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 10:49:33 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 10:58:14 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 11:05:14 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 11:07:27 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:16:30 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 11:17:59 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:26:57 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3072.5256927013397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  9 11:29:27 2024]  Iteration number: 0 with current cost as 0.10615144292210577 and parameters 
[-2.88080789  2.14133299 -2.10794948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53706726  1.14432445
  1.24914503 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:38:06 2024]  Iteration number: 50 with current cost as 0.06586746339315569 and parameters 
[-4.87422824  1.4971199  -2.99656089 -0.11656396  0.55388013 -2.7701224
  3.06858082  2.18958512  1.18553481 -1.06647719 -1.86364003  1.1443187
  3.27979804 -1.87356769  0.72962598  2.88578334 -0.54533471 -0.47522748
 -2.02655444  0.7289676   1.60511935  2.83074175 -1.26457815 -0.25138188]. 
Working on 0.4 fold... 
[Tue Apr  9 11:40:58 2024]  Iteration number: 0 with current cost as 0.1116905181677924 and parameters 
[-2.874976    2.14230205 -2.1064499  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.52856384  1.14432445
  1.2377615  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 11:49:38 2024]  Iteration number: 50 with current cost as 0.08228885414323607 and parameters 
[-4.52304162  1.53606993 -2.99276315 -0.11656203  0.55389368 -2.77014835
  3.06858663  2.18953687  1.18550028 -1.06651823 -0.21387257  1.14428414
  1.79446401 -1.87359457  0.72960997  2.88580516 -0.54536863 -0.4752776
 -2.02659168  0.72893442  1.60510018  2.83078581 -1.26464752 -0.2513631 ]. 
Working on 0.6 fold... 
[Tue Apr  9 11:56:42 2024]  Iteration number: 0 with current cost as 0.11144671550517377 and parameters 
[-2.87630484  2.14322261 -2.10903531 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.53066184  1.14432445
  1.23797853 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Tue Apr  9 11:58:50 2024]  Iteration number: 0 with current cost as 0.10333984530037343 and parameters 
[-2.88579441  2.13849385 -2.10181548 -0.11653103  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.53910099  1.14432445
  1.26140897 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 12:07:52 2024]  Iteration number: 50 with current cost as 0.046627607364026435 and parameters 
[-3.44255103  1.54652397 -3.14121947 -0.11652798  0.55388658 -2.77010892
  3.06858684  2.18960055  1.18552248 -1.06648469 -2.8917003   1.14432389
  4.42793749 -1.87354163  0.72964606  2.88578566 -0.54534664 -0.4752301
 -2.02654573  0.72897064  1.60512497  2.8307622  -1.26456936 -0.25135889]. 
Working on 1.0 fold... 
[Tue Apr  9 12:09:19 2024]  Iteration number: 0 with current cost as 0.1026950898367947 and parameters 
[-2.88070568  2.14307738 -2.11179711 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.53922273  1.14432445
  1.24707457 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512663  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  9 12:18:07 2024]  Iteration number: 50 with current cost as 0.05282999939487909 and parameters 
[-0.93349771  1.58916095 -3.14869166 -0.11653387  0.55389293 -2.77012956
  3.06858588  2.1896036   1.18550745 -1.06647935  3.27119319  1.14432353
 -1.70299023 -1.87353571  0.72965109  2.88579576 -0.54534511 -0.4752254
 -2.02654288  0.7289718   1.60514112  2.83076771 -1.26456905 -0.25138118]. 
Training complete taking 3064.228238582611 seconds. 
Discarding model... 

Training complete taking 76658.11131453514 total seconds. 
Now scoring model... 
Scoring complete taking 0.829031229019165 seconds. 
Saved predicted values as A1-A1-CZ_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.09292031150749848,), 'R2_train': 0.8149737846912403, 'MAE_train': 0.25380691355309276, 'MSE_test': 0.07446224247250767, 'R2_test': 0.8611305276622707, 'MAE_test': 0.23605130724007783}. 
Saved model results as A1-A1-CZ_Full-Pauli-CRX_results.json. 
