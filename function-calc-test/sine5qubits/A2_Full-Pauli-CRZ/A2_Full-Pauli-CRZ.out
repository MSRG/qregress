/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:31 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:47 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Thu Apr  4 21:39:51 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:47:07 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Thu Apr  4 21:47:45 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:54:16 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Thu Apr  4 21:54:59 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:01:40 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:08 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 22:09:32 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2159.456018924713 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:13:46 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Thu Apr  4 22:15:51 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:23:09 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Thu Apr  4 22:23:57 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:30:13 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:57 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:37:42 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Thu Apr  4 22:39:09 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 22:45:32 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2161.271509170532 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:49:47 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:49 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:59:01 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Thu Apr  4 22:59:37 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:05:57 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Thu Apr  4 23:06:41 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:13:23 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Thu Apr  4 23:14:49 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 23:21:09 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2138.253473520279 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:25:25 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Thu Apr  4 23:27:38 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:34:58 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Thu Apr  4 23:35:33 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:41:49 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Thu Apr  4 23:42:32 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:49:21 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Thu Apr  4 23:50:46 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 23:57:28 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2173.122227907181 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:01:37 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 00:03:40 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:11:15 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 00:11:53 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:18:16 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 00:19:01 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:25:41 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 00:27:10 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 00:34:17 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2214.6572132110596 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:38:34 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 00:40:39 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:47:59 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 00:48:35 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:54:53 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 00:55:35 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:02:39 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 01:04:06 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 01:10:37 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2181.30371594429 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:14:57 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 01:17:11 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:24:31 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 01:25:07 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:31:23 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 01:32:07 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:38:49 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 01:40:16 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 01:46:40 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2159.6768622398376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:50:52 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 01:52:58 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:00:22 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 02:01:01 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:07:17 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 02:08:01 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:14:36 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 02:16:02 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 02:22:24 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2137.088359117508 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:26:31 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 02:28:34 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:35:56 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 02:36:33 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:42:48 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 02:43:32 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:50:19 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 02:51:46 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 02:58:08 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2146.578239440918 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:02:16 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 03:04:19 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:11:54 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 03:12:32 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:18:47 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 03:19:31 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:26:07 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 03:27:35 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 03:34:09 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2217.1068108081818 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 03:39:15 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 03:41:17 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:48:44 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 03:49:20 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:55:41 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 03:56:24 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:03:13 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 04:04:40 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 04:11:01 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2165.6350536346436 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 04:15:19 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 04:17:23 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:24:39 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 04:25:15 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:31:30 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 04:32:16 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:38:57 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 04:40:25 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 04:46:49 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2137.6071541309357 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:50:57 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 04:52:59 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:00:17 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 05:00:53 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:07:13 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 05:07:56 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:14:43 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 05:16:10 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 05:22:34 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2146.6651566028595 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:26:45 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 05:28:53 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:36:06 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 05:36:44 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:43:21 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 05:44:05 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:50:44 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 05:52:11 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 05:58:37 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2173.312745332718 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 06:02:57 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 06:05:00 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:12:17 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 06:12:53 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:19:07 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 06:19:51 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:26:37 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 06:28:03 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 06:34:36 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2143.7712450027466 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 06:38:40 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 06:40:44 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:48:17 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 06:48:59 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:55:25 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 06:56:10 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:02:54 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 07:04:22 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 07:10:46 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2169.6414103507996 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 07:14:51 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 07:16:54 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:24:10 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 07:24:47 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:31:03 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 07:31:48 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:38:25 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 07:39:52 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 07:46:14 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2129.447897672653 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 07:50:21 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 07:52:24 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:59:36 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 08:00:12 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:06:28 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 08:07:11 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:13:53 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 08:15:20 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 08:21:43 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2130.8739352226257 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 08:25:52 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 08:27:55 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:35:08 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 08:35:45 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:42:03 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 08:42:46 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:49:25 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 08:50:53 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 08:57:15 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2129.589772939682 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 09:01:21 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 09:03:24 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:10:37 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 09:11:13 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:17:30 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 09:18:13 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:24:49 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 09:26:16 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 09:32:39 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2125.0096039772034 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 09:36:45 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 09:38:47 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:46:05 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 09:46:41 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:52:58 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 09:53:41 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:00:19 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 10:01:46 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 10:08:10 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2131.7491869926453 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 10:12:17 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 10:14:19 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:21:33 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 10:22:10 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:28:50 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 10:29:37 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:36:14 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 10:37:41 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 10:44:08 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2155.569060564041 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 10:48:12 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 10:50:18 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:57:41 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 10:58:17 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:04:37 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 11:05:20 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:12:01 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 11:13:26 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 11:19:49 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2145.1238453388214 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 11:23:57 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 11:26:02 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:33:17 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 11:33:53 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:40:15 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 11:40:58 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:48:12 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 11:49:39 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 11:56:09 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2178.6969912052155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 12:00:16 2024]  Iteration number: 0 with current cost as 0.19658123911652528 and parameters 
[-3.18563064  1.97258156 -2.08092715 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.37450919  1.14432445
  1.6637859  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.4 fold... 
[Fri Apr  5 12:02:24 2024]  Iteration number: 0 with current cost as 0.16930257672653132 and parameters 
[-3.07229234  1.99092334 -2.08469025 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.38941693  1.14432445
  1.5350357  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:09:39 2024]  Iteration number: 50 with current cost as 0.08851861791163726 and parameters 
[-2.3428761   1.61450043  0.02559457 -0.11656213  0.55394074 -2.77010815
  3.06859525  2.18959989  1.18549107 -1.06645958 -1.51130094  1.14428197
  1.54891306 -1.8735356   0.72963249  2.88577624 -0.54535416 -0.47519542
 -2.0265387   0.72897582  1.60510248  2.83080665 -1.26456876 -0.25136859]. 
Working on 0.6 fold... 
[Fri Apr  5 12:10:15 2024]  Iteration number: 0 with current cost as 0.18501337866501105 and parameters 
[-3.09847112  1.99353872 -2.08291691 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.39372266  1.14432445
  1.56458656 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:16:36 2024]  Iteration number: 50 with current cost as 0.07801698255263143 and parameters 
[-3.23847408  1.55452724 -0.01582999 -0.11653025  0.5538885  -2.77011071
  3.06858664  2.18959889  1.18552236 -1.06648909 -0.73008791  1.14432734
  1.56039037 -1.87354743  0.72965061  2.88578554 -0.54534179 -0.47522306
 -2.02654036  0.72897298  1.60512868  2.8307719  -1.26456567 -0.25135957]. 
Working on 0.8 fold... 
[Fri Apr  5 12:17:19 2024]  Iteration number: 0 with current cost as 0.1944793591194147 and parameters 
[-3.15088557  2.01258061 -2.08722432 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.40796736  1.14432445
  1.6182376  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:24:13 2024]  Iteration number: 50 with current cost as 0.08217328303612229 and parameters 
[-2.05891056  1.60462358 -0.01418682 -0.116533    0.55388393 -2.77009977
  3.06858001  2.18958458  1.18551271 -1.06645642 -1.72767144  1.1443244
  1.54335615 -1.87352311  0.72965078  2.88577751 -0.54533266 -0.47522991
 -2.02653949  0.72897522  1.60513183  2.83076884 -1.26456119 -0.25135766]. 
Working on 1.0 fold... 
[Fri Apr  5 12:25:40 2024]  Iteration number: 0 with current cost as 0.17968787195597605 and parameters 
[-3.15001051  1.96237429 -2.07956423 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.36547191  1.14432445
  1.626267   -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 12:32:07 2024]  Iteration number: 50 with current cost as 0.08546362316993726 and parameters 
[-1.64313734  1.62013365 -1.15421458 -0.11663355  0.55389098 -2.7702061
  3.06854259  2.18964125  1.18548536 -1.06653237 -0.10337613  1.14428582
  1.59082009 -1.87359589  0.72959732  2.88576978 -0.5453944  -0.47525519
 -2.02651858  0.72895862  1.60507814  2.83078575 -1.26451902 -0.25130885]. 
Training complete taking 2158.918968439102 seconds. 
Discarding model... 

Training complete taking 53910.1285405159 total seconds. 
Now scoring model... 
Scoring complete taking 0.8498897552490234 seconds. 
Saved predicted values as A2_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.1407149969298037,), 'R2_train': 0.7198033142946978, 'MAE_train': 0.3167696807349129, 'MSE_test': 0.17116522942184326, 'R2_test': 0.6807828464049581, 'MAE_test': 0.3632658211861695}. 
Saved model results as A2_Full-Pauli-CRZ_results.json. 
