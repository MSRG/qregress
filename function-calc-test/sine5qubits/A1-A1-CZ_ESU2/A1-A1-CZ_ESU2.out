/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:03:30 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:26 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:06:00 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:07:47 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 22:09:35 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:11:13 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 501.49296975135803 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:47 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:23 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:16:08 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 22:17:49 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:19:20 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 487.343474149704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:20:49 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:22:19 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:24:04 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 22:25:48 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:27:19 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 478.76684641838074 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:28:50 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:30:23 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:32:11 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 22:33:50 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:35:20 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 482.19451904296875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:36:52 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:38:21 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:40:05 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 22:41:45 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:43:15 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 475.59496998786926 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:44:44 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:46:11 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:47:56 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 22:49:40 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:51:08 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 470.74167943000793 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:52:39 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:54:10 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 22:55:54 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 22:57:41 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:59:11 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 484.0361545085907 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:00:44 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:02:19 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:04:06 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 23:05:50 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:07:21 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 488.37583780288696 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:08:52 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:10:24 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:12:12 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 23:13:53 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:15:21 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 478.43567633628845 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:16:49 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:18:20 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:20:03 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 23:21:44 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:23:14 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 475.2129774093628 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:24:43 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:26:19 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:28:02 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 23:29:46 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:31:18 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 483.4985957145691 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:32:47 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:34:19 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:36:01 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 23:37:47 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:39:16 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 479.47743344306946 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:40:46 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:42:12 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:43:50 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 23:45:32 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:47:01 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 465.47191429138184 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:48:30 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:50:01 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:51:44 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Thu Apr  4 23:53:21 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:54:50 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 467.8982448577881 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:56:18 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:57:46 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Thu Apr  4 23:59:29 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 00:01:15 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:02:44 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 473.3194115161896 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:04:13 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:05:44 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 00:07:27 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 00:09:09 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:10:41 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 478.37392807006836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:12:15 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:13:45 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 00:15:27 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 00:17:08 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:18:40 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 477.4305474758148 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:20:12 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:21:42 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 00:23:26 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 00:25:07 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:26:35 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 476.03065156936646 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:28:04 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:29:31 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 00:31:18 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 00:32:58 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:34:31 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 478.04614067077637 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:36:02 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:37:33 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 00:39:15 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 00:41:00 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:42:28 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 475.90516114234924 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:44:00 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:45:26 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 00:47:06 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 00:48:49 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:50:19 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 472.4521839618683 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:51:54 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:53:23 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 00:55:05 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 00:56:47 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:58:14 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 470.98836493492126 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:59:42 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:01:12 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 01:02:56 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 01:04:43 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:06:12 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 478.3203020095825 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:07:39 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:09:08 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 01:10:51 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 01:12:36 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:14:08 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 477.37864232063293 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:15:38 2024]  Iteration number: 0 with current cost as 0.07841272152963238 and parameters 
[-1.62758965  2.23743462 -2.12427962 -0.11653101  0.55388708 -2.77010899
  3.06858496  2.18960147  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:17:09 2024]  Iteration number: 0 with current cost as 0.09192647886471714 and parameters 
[-1.72971462  2.23743464 -2.12427961 -0.11653105  0.55388708 -2.770109
  3.06858498  2.18960145  1.18551998 -1.06648311]. 
Working on 0.6 fold... 
[Fri Apr  5 01:18:55 2024]  Iteration number: 0 with current cost as 0.08811372203949702 and parameters 
[-1.68668551  2.23743461 -2.12427964 -0.11653103  0.55388706 -2.77010902
  3.06858496  2.18960145  1.18551998 -1.06648311]. 
Working on 0.8 fold... 
[Fri Apr  5 01:20:42 2024]  Iteration number: 0 with current cost as 0.07501703925010861 and parameters 
[-1.65240351  2.23743466 -2.12427957 -0.116531    0.55388708 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:22:14 2024]  Iteration number: 0 with current cost as 0.07723046457001949 and parameters 
[-1.63772619  2.23743466 -2.12427962 -0.11653103  0.5538871  -2.77010899
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Training complete taking 485.94624161720276 seconds. 
Discarding model... 

Training complete taking 11962.733739852905 total seconds. 
Now scoring model... 
Scoring complete taking 1.8802340030670166 seconds. 
Saved predicted values as A1-A1-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.13185444939246627,), 'R2_train': 0.7374467503723372, 'MAE_train': 0.3015344148317692, 'MSE_test': 0.12411660685960388, 'R2_test': 0.7685268784470692, 'MAE_test': 0.30838384683179354}. 
Saved model results as A1-A1-CZ_ESU2_results.json. 
