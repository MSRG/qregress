/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:18 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:39:51 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:41:21 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:42:51 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:44:14 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 446.2621839046478 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:45:44 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:47:10 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:48:38 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:04 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:51:20 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 425.1538383960724 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:51 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:19 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:55:47 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:57:17 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:58:31 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 431.943284034729 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:59:59 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:25 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:02:53 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:04:22 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:05:44 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 432.79094767570496 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:07:15 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:08:42 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:10:11 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:40 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:12:59 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 435.7131028175354 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:14:29 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:15:56 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:17:21 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:18:49 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:20:07 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 428.93922448158264 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:21:37 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:23:11 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:24:38 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:26:06 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:27:22 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 432.1078722476959 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:28:49 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:30:18 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:31:46 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:33:12 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:28 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 427.92217350006104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:35:55 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:37:26 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:38:57 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:40:22 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:41:37 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 426.9862525463104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:43:03 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:44:33 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:46:00 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:47:27 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:48:43 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 425.20408511161804 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:50:08 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:41 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:53:08 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:54:34 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:55:49 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 425.9511811733246 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:57:14 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:58:38 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:00:03 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:01:29 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:02:45 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 417.81381011009216 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:04:12 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:05:41 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:07:07 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:08:34 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:09:53 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 430.66201543807983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:11:24 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:12:49 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:14:15 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:15:44 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:16:58 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 423.1180145740509 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:18:27 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:20:02 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:21:28 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:22:56 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:24:12 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 435.2844524383545 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:25:43 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:27:08 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:28:34 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:30:02 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:31:24 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 429.7865455150604 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:32:52 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:34:18 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:35:42 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:37:11 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:38:28 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 422.22536182403564 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:39:53 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:41:21 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:42:49 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:44:19 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:45:39 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 432.35943269729614 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:47:04 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:48:33 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:49:58 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:51:24 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:52:40 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 421.5646047592163 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:07 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:55:33 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:56:58 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:58:23 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:59:38 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 416.75293135643005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:01:03 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:02:29 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:03:54 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:05:24 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:06:42 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 425.54643201828003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:08:09 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:09:37 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:11:05 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:12:33 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:13:52 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 430.62654304504395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:15:28 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:16:57 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:18:25 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:19:56 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:21:10 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 438.1063697338104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:22:38 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:24:04 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:25:32 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:26:57 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:28:10 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 418.405944108963 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:29:35 2024]  Iteration number: 0 with current cost as 0.09612021220549163 and parameters 
[-1.7366268   2.23743465 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552001 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:31:01 2024]  Iteration number: 0 with current cost as 0.11733575410349487 and parameters 
[-1.78920332  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18552    -1.0664831 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:32:27 2024]  Iteration number: 0 with current cost as 0.10656535943676676 and parameters 
[-1.7995232   2.23743465 -2.12427961 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960147  1.18552    -1.0664831 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:33:54 2024]  Iteration number: 0 with current cost as 0.0987099375697209 and parameters 
[-1.7142947   2.23743464 -2.12427962 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960147  1.18552    -1.0664831 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:35:07 2024]  Iteration number: 0 with current cost as 0.11308150743594231 and parameters 
[-1.76144309  2.23743464 -2.12427961 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648311]. 
Training complete taking 417.5578908920288 seconds. 
Discarding model... 

Training complete taking 10698.785624027252 total seconds. 
Now scoring model... 
Scoring complete taking 1.797839641571045 seconds. 
Saved predicted values as A2_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.14365252632687758,), 'R2_train': 0.7139540017183517, 'MAE_train': 0.3217629423134078, 'MSE_test': 0.17057288770998175, 'R2_test': 0.6818875429362263, 'MAE_test': 0.36081526875288644}. 
Saved model results as A2_ESU2_results.json. 
