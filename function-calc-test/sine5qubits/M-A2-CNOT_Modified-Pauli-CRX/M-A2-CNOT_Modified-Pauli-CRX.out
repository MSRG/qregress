/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:43 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:14 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:44:03 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:51:41 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:59:41 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:07:00 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2432.170070886612 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:18:47 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:24:38 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:32:16 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:40:14 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:47:32 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2428.2214834690094 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:59:13 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:05:01 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:12:40 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:20:43 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:28:10 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2437.1886947155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:39:52 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:45:37 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:53:11 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:01:17 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:08:35 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2450.888528585434 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:20:42 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:26:55 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:34:33 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:42:31 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:49:53 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2464.9778759479523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:01:47 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:07:35 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:15:14 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:23:12 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:30:46 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2440.5572650432587 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:42:27 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:48:30 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:56:07 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:04:04 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:11:25 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2445.9391152858734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 02:23:13 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:29:01 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:36:41 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:45:03 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:52:21 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2448.886392593384 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:04:03 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:09:53 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:17:31 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:25:28 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:33:08 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2449.6567282676697 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:44:53 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:50:36 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:58:10 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:06:12 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:13:28 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2416.736611843109 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:25:09 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:30:56 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:38:34 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:46:36 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:53:55 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2428.8447592258453 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:05:37 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:11:23 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:19:10 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:27:08 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:34:32 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2431.717823266983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 05:46:11 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:51:56 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:59:31 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:07:29 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:15:10 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2441.9210307598114 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 06:26:52 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:33:06 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:40:44 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:49:15 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:56:35 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2485.079176425934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 07:08:17 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:14:01 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:21:38 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:29:37 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:37:16 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2445.9435555934906 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 07:49:03 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:54:48 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:02:27 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:10:26 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:17:40 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2419.653864622116 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 08:29:22 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:35:09 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:42:46 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:50:45 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:58:09 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2429.53715801239 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 09:09:51 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:15:39 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:23:14 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:31:13 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:38:36 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2426.4564237594604 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 09:50:18 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:56:05 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:03:56 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 10:11:55 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 10:19:35 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2466.10915017128 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 10:31:30 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 10:37:35 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:45:21 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 10:53:18 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 11:00:36 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2451.845461130142 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 11:12:17 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 11:18:01 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 11:25:37 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 11:33:32 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 11:40:47 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2427.3718976974487 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 11:52:43 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 11:58:28 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 12:06:06 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 12:14:04 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 12:21:23 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2427.475594520569 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 12:33:11 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 12:38:54 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 12:46:30 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 12:54:33 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 13:01:50 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2427.493225812912 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 13:13:39 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 13:19:24 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 13:27:02 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 13:34:58 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 13:42:12 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2417.151218891144 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 13:53:55 2024]  Iteration number: 0 with current cost as 0.36312953939842707 and parameters 
[-3.37900099  2.00117643 -2.20859048 -0.11653103  0.55388708 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648308  1.80434377  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 13:59:40 2024]  Iteration number: 0 with current cost as 0.40176341563278833 and parameters 
[-3.31950669  2.04643423 -2.18894226 -0.11653103  0.55388708 -2.77010905
  3.06858495  2.18960145  1.18551998 -1.06648308  1.55714871  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 14:07:16 2024]  Iteration number: 0 with current cost as 0.3995399839572755 and parameters 
[-3.35162756  2.03420034 -2.20308383 -0.11653091  0.55388715 -2.77010894
  3.06858502  2.18960153  1.18552006 -1.06648305  1.5937197   1.14432453
  1.31029899 -1.87354676  0.72965084  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 14:15:14 2024]  Iteration number: 0 with current cost as 0.398721269631617 and parameters 
[-3.22556445  2.05138842 -2.16130694 -0.11653095  0.55388708 -2.77010897
  3.06858502  2.18960153  1.18551998 -1.06648308  1.61519205  1.14432449
  1.31029899 -1.87354673  0.7296508   2.88578423 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 14:22:33 2024]  Iteration number: 0 with current cost as 0.35044354095669794 and parameters 
[-3.43774681  2.01183992 -2.20936474 -0.11653099  0.55388712 -2.77010905
  3.06858498  2.18960145  1.18551998 -1.06648308  1.7613258   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2453.035856485367 seconds. 
Discarding model... 

Training complete taking 60994.860365629196 total seconds. 
Now scoring model... 
Scoring complete taking 1.2673702239990234 seconds. 
Saved predicted values as M-A2-CNOT_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.34135891249460437,), 'R2_train': 0.32027404325163245, 'MAE_train': 0.4943430672173526, 'MSE_test': 0.39595174413651724, 'R2_test': 0.26156387514460033, 'MAE_test': 0.5588593630453398}. 
Saved model results as M-A2-CNOT_Modified-Pauli-CRX_results.json. 
