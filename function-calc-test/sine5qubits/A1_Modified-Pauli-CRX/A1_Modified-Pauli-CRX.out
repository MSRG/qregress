/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:01 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:44:06 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:51:29 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:55:36 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:02:39 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 22:10:29 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2117.522082090378 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:13:19 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:19:14 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:26:29 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:38 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:37:40 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 22:45:38 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2109.1019220352173 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:48:28 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:54:23 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:01:45 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:05:50 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:12:58 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 23:20:44 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2112.7056188583374 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:23:40 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:29:31 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:37:08 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:41:15 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:48:12 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Thu Apr  4 23:56:00 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2109.615063905716 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:58:50 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:04:42 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:11:51 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:15:59 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:22:58 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 00:30:56 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2097.028135538101 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:33:47 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:39:46 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:47:06 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:51:21 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:58:33 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 01:06:50 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2173.251187801361 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:10:01 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:15:57 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:23:13 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:27:26 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:34:44 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 01:42:33 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2132.3488717079163 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:45:33 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:51:33 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:58:56 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:03:04 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:11:00 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 02:18:47 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2163.8195054531097 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:21:36 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:27:36 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:34:48 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:38:54 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:45:49 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 02:54:11 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2125.4253771305084 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:57:02 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:03:26 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:10:39 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:14:54 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:22:00 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 03:29:55 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2141.7228689193726 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 03:32:43 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:38:36 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:45:50 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:49:57 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:56:54 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 04:04:42 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2089.766709089279 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 04:07:41 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:13:33 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:20:43 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:24:50 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:31:45 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 04:39:30 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2084.325386285782 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:42:17 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:48:08 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:55:18 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:59:25 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:06:20 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 05:14:08 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2080.378132581711 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:16:58 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:23:00 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:30:27 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:34:44 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:42:03 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 05:49:54 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2148.5954110622406 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:52:47 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:58:48 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:05:59 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:10:18 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:17:45 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 06:25:33 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2134.2534878253937 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 06:28:21 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:34:14 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:41:23 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:45:31 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:52:27 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 07:00:34 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2108.3976771831512 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 07:03:29 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:09:32 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:16:56 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:21:07 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:28:28 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 07:36:31 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2152.42258810997 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 07:39:21 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:45:16 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:52:25 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:56:32 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:04:02 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 08:11:49 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2116.9607853889465 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 08:14:39 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:20:38 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:27:50 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:31:59 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:39:11 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 08:47:05 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2117.079501390457 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 08:49:56 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:55:50 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:03:13 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:07:20 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:14:29 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 09:22:19 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2113.8866143226624 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 09:25:08 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:31:01 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:38:39 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:42:51 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:49:48 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 09:57:34 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2116.451119184494 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 10:00:28 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 10:06:43 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:13:54 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 10:18:03 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 10:25:02 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 10:33:09 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2132.7469635009766 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 10:35:59 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 10:41:51 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:49:02 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 10:53:08 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 11:00:04 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 11:07:50 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2080.051350593567 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 11:10:39 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 11:16:40 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 11:23:56 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 11:28:02 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 11:34:59 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 11:43:11 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2130.022336959839 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 11:46:09 2024]  Iteration number: 0 with current cost as 0.10886289139926165 and parameters 
[-3.01946569  1.87572389 -2.31217779 -0.116531    0.55388711 -2.77010896
  3.06858498  2.18960148  1.18552001 -1.06648308  1.72642169  1.14432448
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 11:52:07 2024]  Iteration number: 0 with current cost as 0.7147319556447385 and parameters 
[-3.16117809  1.43687511 -2.53284277 -0.11653099  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648316  3.13018353  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 11:59:27 2024]  Iteration number: 0 with current cost as 0.10820736462115377 and parameters 
[-3.01166437  1.88838011 -2.30207841 -0.11653103  0.55388711 -2.77010897
  3.06858498  2.18960147  1.18552    -1.06648308  1.67615515  1.14432448
  1.31029899 -1.87354677  0.72965079  2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 12:03:35 2024]  Iteration number: 0 with current cost as 0.7511699742745804 and parameters 
[-3.17173858  1.30654822 -2.60326707 -0.11653103  0.55388712 -2.77010897
  3.06858495  2.18960145  1.18552006 -1.06648312  3.42618526  1.14432453
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 12:10:31 2024]  Iteration number: 0 with current cost as 0.7536853464293118 and parameters 
[-3.19460937  1.41327771 -2.55474106 -0.11653099  0.55388715 -2.77010897
  3.06858495  2.18960153  1.18552002 -1.06648312  3.26872305  1.14432449
  1.31029902 -1.87354669  0.72965073  2.88578419 -0.5453432  -0.47522485
 -2.0265424   0.7289737 ]. 
[Fri Apr  5 12:18:16 2024]  Iteration number: 50 with current cost as 0.10052516664852842 and parameters 
[-1.1478518   1.72941769 -3.1310024  -0.11651856  0.55392134 -2.77008509
  3.06859579  2.18960542  1.18551406 -1.06645987  1.28836778  1.14433091
  1.31032239 -1.87354631  0.72964944  2.88577455 -0.54534163 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2097.639130115509 seconds. 
Discarding model... 

Training complete taking 52985.51940321922 total seconds. 
Now scoring model... 
Scoring complete taking 1.1550593376159668 seconds. 
Saved predicted values as A1_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.17325841861344496,), 'R2_train': 0.6550017004211234, 'MAE_train': 0.34710497271108487, 'MSE_test': 0.17606388601190798, 'R2_test': 0.6716470235605522, 'MAE_test': 0.3613922358355658}. 
Saved model results as A1_Modified-Pauli-CRX_results.json. 
