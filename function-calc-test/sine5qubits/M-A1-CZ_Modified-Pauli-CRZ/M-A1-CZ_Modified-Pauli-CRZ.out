/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:03:30 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:14 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:05:25 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:51 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:29 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:09:40 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 404.34531140327454 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:10:59 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:12:11 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:14:00 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:15:36 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:16:46 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 426.55116844177246 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:18:06 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:19:15 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:20:44 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:22:21 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:23:33 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 407.0782287120819 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:24:51 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:26:03 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:27:31 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:29:08 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:30:19 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.3250660896301 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:31:41 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:32:52 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:34:20 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:36:00 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:37:09 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.2097463607788 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:38:30 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:39:41 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:41:10 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:42:47 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:43:58 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.5981111526489 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:45:17 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:46:28 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:47:55 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:49:41 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:50:51 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 413.98309326171875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:52:12 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:53:22 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:54:55 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:56:39 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:57:49 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 417.2637405395508 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:59:14 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:00:24 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:01:53 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:03:32 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:04:44 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 414.3788709640503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:06:05 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:07:15 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:08:43 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:10:20 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:11:31 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 407.7610538005829 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:12:50 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:14:02 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:15:30 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:17:08 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:18:19 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 407.32350993156433 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:19:39 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:20:50 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:22:18 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:23:57 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:25:08 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 409.63970160484314 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:26:27 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:27:39 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:29:09 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:30:47 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:31:57 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 414.409982919693 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:33:27 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:34:43 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:36:12 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:37:49 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:38:59 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 418.26942014694214 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:40:21 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:41:33 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:43:01 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:44:42 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:45:53 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 411.5689945220947 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:47:13 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:48:24 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:49:55 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:51:33 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:52:49 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 420.1405363082886 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:19 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:55:31 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:56:59 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:58:42 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:59:52 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 420.38112711906433 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:01:13 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:02:25 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:03:55 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:05:34 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:06:44 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 410.7415199279785 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:08:04 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:09:14 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:10:42 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:12:19 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:13:29 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 406.66202044487 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:14:49 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:15:59 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:17:27 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:19:14 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:20:24 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 413.3449647426605 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:21:44 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:22:54 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:24:22 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:25:58 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:27:13 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 409.3570659160614 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:28:48 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:29:57 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:31:27 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:33:20 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:34:53 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 460.0301876068115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:36:13 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:37:23 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:38:51 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:40:27 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:41:39 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 405.1009702682495 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:42:57 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:44:10 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:45:38 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:47:14 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:48:23 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 404.4078850746155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:49:43 2024]  Iteration number: 0 with current cost as 0.0770583677237591 and parameters 
[-4.66635377  2.23743454 -2.12427944 -0.11653103  0.55388698 -2.77010917
  3.06858489  2.18960136  1.18551998 -1.06648328  0.60271491  1.14432435
  1.31029899 -1.8735469   0.72965061  2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:50:53 2024]  Iteration number: 0 with current cost as 0.08738633694569592 and parameters 
[-4.56668008  2.23743455 -2.12427938 -0.11653103  0.55388699 -2.77010906
  3.06858498  2.18960137  1.18551998 -1.06648317  0.60271502  1.14432437
  1.31029899 -1.87354672  0.72965072  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:52:22 2024]  Iteration number: 0 with current cost as 0.08304526121967443 and parameters 
[-4.5668804   2.23743464 -2.12427947 -0.11653103  0.55388708 -2.77010914
  3.06858498  2.18960145  1.18552007 -1.06648308  0.60271519  1.14432445
  1.31029915 -1.87354663  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:54:00 2024]  Iteration number: 0 with current cost as 0.07566735962892585 and parameters 
[-4.66352059  2.23743447 -2.12427964 -0.11653103  0.553887   -2.77010914
  3.0685849   2.18960137  1.18551998 -1.06648325  0.60271502  1.14432445
  1.31029899 -1.8735468   0.72965064  2.88578403 -0.54534343 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:55:11 2024]  Iteration number: 0 with current cost as 0.08118794179286522 and parameters 
[-4.61868084  2.23743454 -2.12427945 -0.11653103  0.55388708 -2.77010916
  3.06858498  2.18960136  1.18551998 -1.06648318  0.6027151   1.14432436
  1.31029899 -1.87354671  0.7296508   2.8857841  -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 407.6387951374054 seconds. 
Discarding model... 

Training complete taking 10335.512145280838 total seconds. 
Now scoring model... 
Scoring complete taking 1.2162621021270752 seconds. 
Saved predicted values as M-A1-CZ_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.13014806432688478,), 'R2_train': 0.7408445647513653, 'MAE_train': 0.29940538565954056, 'MSE_test': 0.17072722243591038, 'R2_test': 0.6815997140817434, 'MAE_test': 0.35890187162512577}. 
Saved model results as M-A1-CZ_Modified-Pauli-CRZ_results.json. 
