/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:31 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:59 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:47:19 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Thu Apr  4 21:51:44 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 21:59:59 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:25 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 22:17:35 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Thu Apr  4 22:21:28 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:29:37 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3441.7026414871216 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:35:19 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:44:36 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Thu Apr  4 22:48:56 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 22:57:08 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Thu Apr  4 23:05:32 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Thu Apr  4 23:14:57 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Thu Apr  4 23:18:50 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:26:43 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3429.23247218132 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:32:28 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:42:03 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Thu Apr  4 23:46:27 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 23:54:34 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 00:02:58 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 00:12:03 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 00:15:54 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:23:54 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3427.651631832123 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:29:36 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:39:17 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 00:43:36 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 00:51:49 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 01:00:24 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 01:09:38 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 01:13:33 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:21:34 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3457.2031512260437 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:27:14 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:36:33 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 01:40:52 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 01:49:07 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 01:57:30 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 02:06:47 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 02:10:55 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:18:50 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3435.8832457065582 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:24:30 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:33:48 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 02:38:09 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 02:46:21 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 02:54:42 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 03:03:50 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 03:07:44 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:15:39 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3412.5750896930695 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:21:23 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:30:40 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 03:35:25 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 03:43:59 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 03:52:31 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 04:01:42 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 04:05:44 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:13:49 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3490.684098005295 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:19:34 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:29:02 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 04:33:25 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 04:41:40 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 04:50:02 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 04:59:10 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 05:03:04 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:11:10 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3445.3551931381226 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:16:58 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:26:28 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 05:30:48 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 05:39:04 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 05:47:32 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 05:56:41 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 06:00:34 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:08:53 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3466.3148770332336 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 06:14:46 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:24:03 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 06:28:24 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 06:36:34 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 06:44:54 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 06:53:56 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 06:57:47 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:05:40 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3396.2804493904114 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 07:11:20 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:20:35 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 07:24:55 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 07:33:26 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 07:41:55 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 07:51:10 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 07:55:04 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:02:58 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3437.9931116104126 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 08:08:40 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:18:00 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 08:22:20 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 08:30:33 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 08:38:56 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 08:48:07 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 08:52:37 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:00:36 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3455.958415746689 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 09:06:14 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:15:30 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 09:19:50 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 09:28:04 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 09:36:25 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 09:45:30 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 09:49:22 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:57:18 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3406.276481151581 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 10:03:01 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:12:20 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 10:16:42 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 10:25:06 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 10:33:32 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 10:42:39 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 10:46:31 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:54:24 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3423.131438970566 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 11:00:03 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:09:17 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 11:13:35 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 11:21:49 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 11:31:04 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 11:40:27 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 11:44:20 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:52:15 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3470.6122307777405 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 11:57:55 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:07:12 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 12:11:32 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 12:19:49 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 12:28:10 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 12:37:17 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 12:41:10 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:49:07 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3413.818650484085 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 12:54:50 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:04:05 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 13:08:25 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 13:16:37 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 13:24:57 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 13:34:04 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 13:37:57 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:45:53 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3404.084745168686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 13:51:32 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 14:00:50 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 14:05:11 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 14:13:23 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 14:21:53 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 14:31:00 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 14:34:54 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 14:42:47 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3415.1399354934692 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 14:48:27 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 14:57:42 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 15:02:02 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 15:10:17 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 15:18:38 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 15:27:43 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 15:31:35 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 15:39:29 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3401.224952697754 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 15:45:12 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 15:54:35 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 15:58:57 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 16:07:11 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 16:15:45 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 16:24:51 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 16:28:44 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 16:36:37 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3428.9708647727966 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 16:42:19 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 16:51:58 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 16:56:20 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 17:04:31 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 17:12:53 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 17:22:14 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 17:26:07 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 17:34:02 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3443.919648885727 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 17:39:41 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 17:49:01 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 17:53:37 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 18:01:48 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 18:10:14 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 18:19:20 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 18:23:17 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 18:31:27 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3443.1927587985992 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 18:37:06 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 18:46:20 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 18:50:39 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 18:58:52 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 19:07:17 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 19:16:22 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 19:20:14 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 19:28:09 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3404.0226697921753 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 19:33:49 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 19:43:04 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 19:47:52 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 19:56:05 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 20:04:28 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 20:13:33 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 20:17:25 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 20:25:20 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3430.448890209198 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 20:30:59 2024]  Iteration number: 0 with current cost as 0.10748837865136085 and parameters 
[-2.88637162  2.2283641  -2.11736719 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57740339  1.14432445
  1.2798102  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 20:40:16 2024]  Iteration number: 50 with current cost as 0.07772255704431122 and parameters 
[-5.18764472  1.55412305 -3.14177312 -0.11653274  0.55388628 -2.77010849
  3.06858682  2.18960453  1.18552022 -1.06648296  3.05635571  1.14432423
 -1.48146659 -1.87354372  0.7296529   2.88578545 -0.54534151 -0.47522597
 -2.02653835  0.72897394  1.60512813  2.83077255 -1.26456608 -0.25135885]. 
Working on 0.4 fold... 
[Fri Apr  5 20:44:36 2024]  Iteration number: 0 with current cost as 0.1302152197030368 and parameters 
[-2.88063275  2.24186408 -2.11571456 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57451201  1.14432445
  1.27291736 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 20:52:51 2024]  Iteration number: 0 with current cost as 0.10896183412384111 and parameters 
[-2.87309304  2.23465425 -2.11409718 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.56415807  1.14432445
  1.25956043 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Fri Apr  5 21:01:13 2024]  Iteration number: 0 with current cost as 0.12573950872275952 and parameters 
[-2.88371498  2.24373693 -2.11676854 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.57887555  1.14432445
  1.27829246 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
[Fri Apr  5 21:10:36 2024]  Iteration number: 50 with current cost as 0.08721209929551263 and parameters 
[-5.55313721  1.5476012  -3.14164549 -0.11653281  0.55388596 -2.77011165
  3.06858377  2.1896014   1.18552082 -1.06648272  3.09690794  1.14432321
 -1.51405337 -1.87354878  0.72965055  2.88578171 -0.54534428 -0.47522781
 -2.02654439  0.72897302  1.60512356  2.83077003 -1.26456891 -0.25136367]. 
Working on 1.0 fold... 
[Fri Apr  5 21:14:33 2024]  Iteration number: 0 with current cost as 0.1217193025840672 and parameters 
[-2.89296345  2.23246926 -2.11952044 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.06648308  0.58652408  1.14432445
  1.29104539 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 21:22:27 2024]  Iteration number: 50 with current cost as 0.09436095145816534 and parameters 
[-4.84263435  1.6009854  -3.09831542 -0.11651834  0.55388913 -2.77009847
  3.06858798  2.18961435  1.1855274  -1.06648064  2.1924822   1.14432834
 -0.38375441 -1.87354324  0.72965675  2.88579317 -0.54533341 -0.47523038
 -2.02653355  0.72897767  1.60512706  2.83077552 -1.26456997 -0.25136448]. 
Training complete taking 3432.952205181122 seconds. 
Discarding model... 

Training complete taking 85814.63134455681 total seconds. 
Now scoring model... 
Scoring complete taking 0.8808598518371582 seconds. 
Saved predicted values as A1_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.14391362185922027,), 'R2_train': 0.7134340990469159, 'MAE_train': 0.3214914193477709, 'MSE_test': 0.1703904102204143, 'R2_test': 0.6822278570585024, 'MAE_test': 0.358657464644045}. 
Saved model results as A1_Full-Pauli-CRX_results.json. 
