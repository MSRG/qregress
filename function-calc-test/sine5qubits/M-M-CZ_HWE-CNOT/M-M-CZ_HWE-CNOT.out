/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:46 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Thu Apr  4 21:43:46 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Thu Apr  4 21:50:18 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Thu Apr  4 21:52:34 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Thu Apr  4 21:58:47 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:59:25 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Thu Apr  4 22:04:13 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1881.9245731830597 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:09:07 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Thu Apr  4 22:15:08 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Thu Apr  4 22:21:45 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Thu Apr  4 22:23:58 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Thu Apr  4 22:30:07 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:41 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Thu Apr  4 22:35:18 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1863.3399002552032 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:40:11 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Thu Apr  4 22:46:07 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Thu Apr  4 22:52:34 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Thu Apr  4 22:54:46 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Thu Apr  4 23:00:50 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:01:26 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Thu Apr  4 23:06:03 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1843.7836327552795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:10:56 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Thu Apr  4 23:16:50 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Thu Apr  4 23:23:20 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Thu Apr  4 23:25:32 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Thu Apr  4 23:31:41 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:32:16 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Thu Apr  4 23:36:58 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1854.101059436798 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:41:48 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Thu Apr  4 23:47:48 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Thu Apr  4 23:54:20 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Thu Apr  4 23:56:36 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 00:02:55 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:03:36 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 00:08:26 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1891.041288614273 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:13:20 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 00:19:16 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 00:25:54 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 00:28:13 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 00:34:26 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:35:02 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 00:39:40 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1874.0796055793762 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:44:35 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 00:50:36 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 00:57:19 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 00:59:36 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 01:05:44 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:06:18 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 01:11:03 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1883.6091303825378 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:15:57 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 01:21:55 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 01:28:41 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 01:30:52 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 01:37:08 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:37:42 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 01:42:40 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1895.8404157161713 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:47:34 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 01:53:50 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 02:00:18 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 02:02:32 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 02:08:50 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:09:25 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 02:14:03 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1882.643367767334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:18:56 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 02:24:54 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 02:31:33 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 02:33:46 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 02:39:54 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:40:29 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 02:45:05 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1861.3214373588562 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:49:57 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 02:55:55 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 03:02:26 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 03:04:40 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 03:10:49 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:11:24 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 03:16:02 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1857.5597851276398 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:20:55 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 03:26:59 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 03:33:33 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 03:35:56 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 03:42:04 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:42:40 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 03:47:24 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1884.647240638733 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:52:20 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 03:58:14 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 04:04:51 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 04:07:03 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 04:13:24 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:13:59 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 04:18:39 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1879.4411220550537 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 04:23:39 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 04:30:10 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 04:36:50 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 04:39:03 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 04:45:37 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:46:11 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 04:50:53 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1927.745151758194 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:55:48 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 05:01:46 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 05:08:18 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 05:10:30 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 05:16:37 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:17:11 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 05:21:52 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1858.1780195236206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 05:26:45 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 05:32:42 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 05:39:13 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 05:41:27 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 05:47:35 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:48:10 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 05:52:48 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1854.8581960201263 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:57:40 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 06:03:37 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 06:10:08 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 06:12:23 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 06:18:32 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:19:07 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 06:23:45 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1856.9001171588898 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 06:28:36 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 06:34:32 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 06:41:03 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 06:43:15 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 06:49:26 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:50:01 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 06:54:41 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1856.094143152237 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 06:59:34 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 07:05:28 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 07:12:04 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 07:14:17 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 07:20:27 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:21:02 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 07:25:46 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1867.4592926502228 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 07:30:40 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 07:36:35 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 07:43:03 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 07:45:15 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 07:51:28 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:52:03 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 07:56:42 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1854.9132912158966 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 08:01:36 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 08:07:33 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 08:14:03 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 08:16:15 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 08:22:22 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:22:58 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 08:27:36 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1853.68887424469 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 08:32:30 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 08:38:29 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 08:45:00 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 08:47:17 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 08:53:41 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:54:15 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 08:58:52 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1877.3519513607025 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 09:03:46 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 09:09:41 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 09:16:12 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 09:18:24 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 09:24:35 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:25:10 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 09:29:48 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1861.3314411640167 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 09:34:47 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 09:40:44 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 09:47:24 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 09:49:39 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 09:55:49 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:56:24 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 10:01:05 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1870.6341092586517 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 10:05:58 2024]  Iteration number: 0 with current cost as 0.26741680605315943 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08765611  0.52376416 -2.78397976
  3.15053301  2.15060742  1.06645249 -1.05563233  0.60217427  1.15732695
  1.39600045 -1.80711595  0.68002276]. 
Working on 0.4 fold... 
[Fri Apr  5 10:11:51 2024]  Iteration number: 0 with current cost as 0.2213887198394992 and parameters 
[-2.90318345e+00  2.23743464e+00 -2.12427964e+00  3.06817053e-03
  4.14477030e-01 -2.85080588e+00  3.45191210e+00  2.02095857e+00
  6.20723954e-01 -1.01865494e+00  6.39939973e-01  1.21402106e+00
  1.70321547e+00 -1.56609503e+00  5.12450528e-01]. 
[Fri Apr  5 10:18:22 2024]  Iteration number: 50 with current cost as 0.11269404132660117 and parameters 
[-2.90318319  2.23743495 -2.12427975 -0.76124066 -0.07885442 -2.40927828
  3.52592254  3.07045452  0.4658127  -1.52595319  1.56675546  0.12946921
  3.07979034 -1.52160221 -0.02810458]. 
Working on 0.6 fold... 
[Fri Apr  5 10:20:36 2024]  Iteration number: 0 with current cost as 0.2764597654628346 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09357138  0.525767   -2.7877553
  3.14044923  2.16911665  1.07329548 -1.05652861  0.61923646  1.16157358
  1.3825468  -1.81740132  0.68832589]. 
[Fri Apr  5 10:27:00 2024]  Iteration number: 50 with current cost as 0.11207494318295738 and parameters 
[-2.90318395  2.2374348  -2.12428    -1.26930969 -0.00638488 -1.89667696
  3.13101833  1.85294427 -0.00947434 -1.68608833  1.03429712  0.2694047
  3.12828295 -0.68672246 -0.0154847 ]. 
Working on 0.8 fold... 
[Fri Apr  5 10:27:36 2024]  Iteration number: 0 with current cost as 0.2656615087846413 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.08423805  0.52847841 -2.77247668
  3.1604495   2.15396211  1.04744644 -1.05143437  0.60427864  1.16308076
  1.40773067 -1.80032579  0.66498743]. 
Working on 1.0 fold... 
[Fri Apr  5 10:32:17 2024]  Iteration number: 0 with current cost as 0.2648620755010902 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09156468  0.52000145 -2.79454896
  3.14929058  2.13942919  1.07496038 -1.06037118  0.59430148  1.14911304
  1.392986   -1.80750527  0.68873965]. 
Training complete taking 1870.4770331382751 seconds. 
Discarding model... 

Training complete taking 46762.96593403816 total seconds. 
Now scoring model... 
Scoring complete taking 1.042907953262329 seconds. 
Saved predicted values as M-M-CZ_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.2402195244649568,), 'R2_train': 0.5216663748330825, 'MAE_train': 0.4113994767762694, 'MSE_test': 0.20164137448549352, 'R2_test': 0.6239459040386335, 'MAE_test': 0.4189439237513451}. 
Saved model results as M-M-CZ_HWE-CNOT_results.json. 
