/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:45 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:24 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:40:21 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 21:42:14 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 21:44:25 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 21:46:08 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 549.5071053504944 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:47:38 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:49:44 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 21:51:49 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 21:53:58 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 21:55:47 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 575.5807521343231 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:57:10 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:58:57 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 22:00:49 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:58 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 22:04:40 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 533.1791298389435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:06:07 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:08:04 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 22:09:57 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 22:12:09 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:58 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 558.5303707122803 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:15:34 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:17:24 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 22:19:10 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 22:21:08 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 22:22:46 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 528.1727640628815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:24:10 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:25:56 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 22:27:45 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 22:29:44 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 22:31:21 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 511.4611737728119 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:32:42 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:34:33 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 22:36:19 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 22:38:20 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 22:39:54 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 513.10364818573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:41:15 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:43:03 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 22:44:49 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 22:46:50 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 22:48:28 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 517.0667140483856 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:50:00 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:51:53 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 22:53:38 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 22:55:48 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 22:57:37 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 554.9431598186493 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:59:17 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:01:36 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 23:03:47 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 23:06:13 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 23:08:02 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 614.89608335495 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:09:28 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:11:25 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 23:13:41 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 23:15:59 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 23:17:40 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 581.7609896659851 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:19:07 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:21:06 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 23:23:11 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 23:25:41 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 23:27:31 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 597.6736297607422 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:29:07 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:31:33 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 23:33:32 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 23:36:08 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 23:38:00 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 629.3751800060272 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:39:46 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:41:59 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 23:44:15 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 23:46:49 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 23:49:04 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 657.2553081512451 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:50:27 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:52:27 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Thu Apr  4 23:54:35 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Thu Apr  4 23:57:07 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Thu Apr  4 23:59:00 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 605.866721868515 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:00:43 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:02:49 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 00:05:13 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 00:07:35 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 00:09:45 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 644.3158769607544 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:11:22 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:13:39 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 00:15:50 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 00:18:21 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 00:20:12 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 620.3110544681549 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:21:50 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:24:03 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 00:26:20 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 00:28:30 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 00:30:25 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 619.8038992881775 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:32:11 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:34:32 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 00:36:54 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 00:39:21 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 00:41:18 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 648.4579918384552 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:42:53 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:45:16 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 00:47:23 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 00:49:45 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 00:51:44 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 624.2699971199036 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:53:17 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:55:36 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 00:57:55 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 01:00:05 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 01:02:02 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 621.121912240982 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:03:49 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:06:15 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 01:08:43 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 01:11:15 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 01:13:14 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 670.930257320404 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:14:45 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:17:06 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 01:19:24 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 01:21:50 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 01:23:50 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 638.2998623847961 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:25:28 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:27:40 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 01:29:54 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 01:32:40 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 01:34:44 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 649.1578769683838 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:36:18 2024]  Iteration number: 0 with current cost as 0.2753173133465824 and parameters 
[-1.57780622  2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:38:24 2024]  Iteration number: 0 with current cost as 0.2947242381608678 and parameters 
[-1.48761974  2.23743453 -2.12427958 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 0.6 fold... 
[Fri Apr  5 01:40:31 2024]  Iteration number: 0 with current cost as 0.29737984226315084 and parameters 
[-1.65957806  2.23743459 -2.12427959 -0.11653103  0.55388703 -2.77010897
  3.06858494  2.18960145  1.18552003 -1.06648313]. 
Working on 0.8 fold... 
[Fri Apr  5 01:42:49 2024]  Iteration number: 0 with current cost as 0.2802710462932878 and parameters 
[-1.32359108  2.23743464 -2.12427958 -0.11653097  0.55388702 -2.77010903
  3.06858498  2.18960145  1.18551998 -1.06648314]. 
Working on 1.0 fold... 
[Fri Apr  5 01:44:43 2024]  Iteration number: 0 with current cost as 0.27258992474453053 and parameters 
[-1.47062269  2.23743456 -2.12427964 -0.11653103  0.553887   -2.77010901
  3.06858495  2.18960141  1.18551995 -1.06648316]. 
Training complete taking 602.432363986969 seconds. 
Discarding model... 

Training complete taking 14867.474501371384 total seconds. 
Now scoring model... 
Scoring complete taking 1.9355878829956055 seconds. 
Saved predicted values as A2-A2-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.4713847217603092,), 'R2_train': 0.061362046610827115, 'MAE_train': 0.5772383941053055, 'MSE_test': 0.4172604141749652, 'R2_test': 0.2218239523837382, 'MAE_test': 0.5738339478968546}. 
Saved model results as A2-A2-CZ_ESU2_results.json. 
