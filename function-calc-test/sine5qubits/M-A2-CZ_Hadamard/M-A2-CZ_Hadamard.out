/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:38 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:54 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:38:19 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:38:46 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:39:11 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:39:35 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.86907768249512 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:40:00 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:40:26 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:40:53 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:41:18 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:41:43 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 126.99327516555786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:42:08 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:42:33 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:43:00 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:43:26 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:43:53 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 129.2170090675354 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:44:18 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:44:43 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:45:10 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:45:34 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:46:00 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 128.95736050605774 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:46:25 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:46:51 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:47:18 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:47:44 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:48:07 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.1637134552002 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:48:33 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:48:58 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:49:26 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:51 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:16 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.38375282287598 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:50:41 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:51:08 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:51:36 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:52:02 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:52:27 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 131.0657389163971 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:53 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:53:18 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:53:46 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:54:12 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:54:36 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 130.0745189189911 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:55:01 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:55:27 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:55:55 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:56:20 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:56:45 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 128.1837866306305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:57:09 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:57:35 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:58:02 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:58:27 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:58:54 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 128.70471501350403 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:59:19 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:45 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:00:12 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:00:36 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:01:07 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 134.2572045326233 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:01:32 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:58 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:02:26 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:52 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:17 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 128.88404774665833 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:03:42 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:04:06 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:04:34 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:05:00 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:05:25 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.77212595939636 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:05:50 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:06:15 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:06:43 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:07:07 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:07:32 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 128.58528017997742 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:07:57 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:08:23 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:08:50 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:09:16 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:09:40 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 128.369952917099 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:10:06 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:31 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:10:59 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:11:24 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:11:50 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.66595983505249 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:15 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:12:39 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:13:07 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:13:32 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:58 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 128.05978345870972 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:14:24 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:50 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:15:18 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:15:43 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:16:07 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 130.51997184753418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:16:32 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:16:57 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:17:25 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:17:53 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:18:19 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 130.60298037528992 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:18:44 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:19:08 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:19:36 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:20:01 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:20:26 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.59384655952454 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:20:52 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:21:18 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:21:46 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:22:09 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:22:35 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 130.213219165802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:23:01 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:23:26 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:23:54 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:24:19 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:24:44 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.63244915008545 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:25:08 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:25:34 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:26:01 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:26:27 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:26:52 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.85125350952148 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:27:17 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:27:41 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:28:09 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:28:34 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:29:00 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 127.6696879863739 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:29:25 2024]  Iteration number: 0 with current cost as 0.20829066689676842 and parameters 
[-5.07417049  2.23743464 -2.12427941 -0.11653125  0.55388685]. 
Working on 0.4 fold... 
[Thu Apr  4 22:29:50 2024]  Iteration number: 0 with current cost as 0.21610279039727892 and parameters 
[-5.05023693  2.23743464 -2.1242794  -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:30:18 2024]  Iteration number: 0 with current cost as 0.2145117218519235 and parameters 
[-5.2714013   2.23743464 -2.124279   -0.11653134  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:30:43 2024]  Iteration number: 0 with current cost as 0.2113521811649005 and parameters 
[-4.93662306  2.23743485 -2.12427943 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:31:08 2024]  Iteration number: 0 with current cost as 0.20373365445456657 and parameters 
[-5.43765527  2.23743486 -2.12427941 -0.1165308   0.55388731]. 
Training complete taking 129.0862114429474 seconds. 
Discarding model... 

Training complete taking 3220.3777899742126 total seconds. 
Now scoring model... 
Scoring complete taking 1.01035475730896 seconds. 
Saved predicted values as M-A2-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (0.3551756786745446,), 'R2_train': 0.292761609074374, 'MAE_train': 0.5099501331498628, 'MSE_test': 0.38179650086442396, 'R2_test': 0.28796290771111965, 'MAE_test': 0.5562822844414818}. 
Saved model results as M-A2-CZ_Hadamard_results.json. 
