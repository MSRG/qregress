/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:31 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:36 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:37:49 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:38:01 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:38:13 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:38:25 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.44088959693909 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:37 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:38:50 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:39:02 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:39:14 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:39:26 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.3999342918396 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:39:38 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:39:54 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:40:06 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:40:18 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:40:30 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 63.522905588150024 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:40:42 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:40:55 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:41:07 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:41:19 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:41:31 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.71517014503479 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:41:44 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:41:57 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:42:09 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:42:21 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:42:33 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.44657349586487 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:42:46 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:43:00 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:43:12 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:43:24 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:43:36 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.27743482589722 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:43:50 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:44:02 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:44:14 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:44:26 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:44:38 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.39548015594482 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:44:54 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:45:06 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:45:18 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:45:31 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:45:43 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.82873320579529 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:45:58 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:46:10 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:46:23 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:46:35 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:46:48 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.917818546295166 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:47:00 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:47:12 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:47:24 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:47:36 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:47:50 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.44642376899719 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:48:02 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:48:14 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:48:26 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:48:38 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:48:51 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.68034791946411 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:49:03 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:49:16 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:49:28 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:40 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:49:53 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.718533992767334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:50:05 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:50:17 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:50:29 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:50:42 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:50:55 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.89486026763916 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:51:07 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:51:19 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:51:31 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:51:43 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:51:57 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.62184023857117 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:09 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:52:21 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:52:34 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:52:49 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:53:01 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 64.09672594070435 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:53:13 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:53:25 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:53:37 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:53:50 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:54:02 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.50918698310852 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:54:14 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:26 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:44 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:54:57 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:55:09 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 67.19841456413269 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:55:21 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:55:34 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:55:47 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:55:59 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:56:11 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.897934675216675 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 21:56:23 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:56:35 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:56:49 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:57:01 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:57:13 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.8391637802124 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 21:57:25 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:57:37 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:57:50 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:58:03 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:58:15 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.593260526657104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:58:27 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:58:39 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:58:52 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 21:59:04 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 21:59:17 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.88148260116577 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:59:29 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 21:59:41 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 21:59:54 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:00:06 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:00:27 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 70.2273633480072 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:00:39 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 22:00:52 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:01:05 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:01:17 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:01:29 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 62.60202169418335 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:01:41 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:55 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:02:07 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:02:19 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:02:31 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.6373336315155 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:02:43 2024]  Iteration number: 0 with current cost as 0.09776503662201233 and parameters 
[-2.93643994  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Apr  4 22:02:56 2024]  Iteration number: 0 with current cost as 0.10398364476829763 and parameters 
[-2.94181171  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Apr  4 22:03:08 2024]  Iteration number: 0 with current cost as 0.09898922348582709 and parameters 
[-2.94117647  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Apr  4 22:03:21 2024]  Iteration number: 0 with current cost as 0.09456857784944839 and parameters 
[-2.93985887  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:33 2024]  Iteration number: 0 with current cost as 0.09701748073750949 and parameters 
[-2.93260823  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Training complete taking 61.830615758895874 seconds. 
Discarding model... 

Training complete taking 1569.6215734481812 total seconds. 
Now scoring model... 
Scoring complete taking 1.1836438179016113 seconds. 
Saved predicted values as M-M-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (0.1611921453809852,), 'R2_train': 0.6790284910427116, 'MAE_train': 0.34134046507909, 'MSE_test': 0.18572898575731572, 'R2_test': 0.6536219512934652, 'MAE_test': 0.3776111419686797}. 
Saved model results as M-M-CZ_Hadamard_results.json. 
