/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:04:29 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:05:08 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:12:00 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:17:29 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:22:44 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:28:26 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1744.821453332901 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:34:11 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:40:31 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:46:00 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:51:14 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:56:55 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1710.4694502353668 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:02:40 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:08:58 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:14:32 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:19:49 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:25:32 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1712.2931594848633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:31:13 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:37:34 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:43:15 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:48:34 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:54:21 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1731.4729070663452 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:00:04 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:06:22 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:11:54 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:17:09 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:22:52 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1709.8755376338959 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:28:35 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:35:02 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:40:31 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:45:45 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:51:27 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1714.8116283416748 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:57:09 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:03:35 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:09:09 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:14:26 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:20:06 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1730.7689685821533 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:26:03 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:33:04 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:38:53 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:44:11 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:50:05 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1805.1211152076721 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:56:07 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:02:46 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:08:20 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:13:49 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:19:39 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1758.2513847351074 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:25:24 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:31:41 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:37:24 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:42:53 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:48:44 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1743.0674691200256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:54:31 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:01:03 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:06:51 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:12:25 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:18:12 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1779.3731105327606 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:24:06 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:30:24 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:35:54 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:41:08 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:46:48 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1701.601895570755 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:52:27 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:58:46 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:04:30 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:09:46 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:15:37 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1740.816735982895 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 04:21:34 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:27:54 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:33:35 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:38:53 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:44:43 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1750.3307857513428 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:50:38 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:56:55 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:03:04 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:08:29 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:14:11 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1753.0280816555023 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 05:19:55 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:26:33 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:32:08 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:37:32 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:43:16 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1746.406084060669 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:48:58 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:55:16 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:00:44 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:06:04 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:11:45 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1712.8645133972168 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 06:17:31 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:23:57 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:29:25 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:34:40 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:40:23 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1717.0521721839905 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 06:46:15 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:52:34 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:58:03 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:03:20 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:09:03 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1714.4853665828705 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 07:14:42 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:21:00 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:26:30 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:31:46 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:37:29 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1706.3501689434052 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 07:43:09 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:49:24 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:54:55 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:00:30 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:06:14 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1747.5940721035004 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 08:12:16 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:18:35 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:24:08 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:29:59 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:35:41 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1746.156993150711 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 08:41:23 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:47:40 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:53:08 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:58:23 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:04:06 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1717.034686088562 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 09:10:00 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:16:22 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:21:51 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:27:08 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:33:16 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1741.2682058811188 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 09:39:01 2024]  Iteration number: 0 with current cost as 0.5162264175247535 and parameters 
[-4.7353137   2.55483011 -2.56986802 -0.11653099  0.55388712 -2.77010901
  3.06858491  2.18960145  1.18551998 -1.06648312  3.00655001  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:45:22 2024]  Iteration number: 0 with current cost as 0.4342828274420397 and parameters 
[-4.49880918  2.5682444  -2.49421486 -0.11653099  0.55388708 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  2.60430755  1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:51:18 2024]  Iteration number: 0 with current cost as 0.4388895366698553 and parameters 
[-4.54095499  2.54880762 -2.50746747 -0.11653099  0.55388712 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648312  2.70892931  1.14432441
  1.31029895 -1.87354684  0.72965069  2.88578416 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:56:36 2024]  Iteration number: 0 with current cost as 0.45826359736475225 and parameters 
[-4.63541207  2.67206768 -2.49794227 -0.11653095  0.55388715 -2.77010901
  3.06858495  2.18960149  1.18551998 -1.06648308  2.70159667  1.14432445
  1.31029899 -1.87354676  0.72965077  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 10:02:16 2024]  Iteration number: 0 with current cost as 0.5103331919149621 and parameters 
[-4.73009122  2.52751997 -2.58823061 -0.11653103  0.55388715 -2.77010897
  3.06858491  2.18960149  1.18551998 -1.06648308  3.00253311  1.14432445
  1.31029899 -1.87354676  0.72965073  2.88578419 -0.54534324 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1734.1268820762634 seconds. 
Discarding model... 

Training complete taking 43369.44551324844 total seconds. 
Now scoring model... 
Scoring complete taking 1.348332405090332 seconds. 
Saved predicted values as M-A2-CZ_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.09132368916249392,), 'R2_train': 0.818153035653499, 'MAE_train': 0.248636898158769, 'MSE_test': 0.09112940865364696, 'R2_test': 0.8300468469123307, 'MAE_test': 0.26792767322297645}. 
Saved model results as M-A2-CZ_Modified-Pauli-CRX_results.json. 
