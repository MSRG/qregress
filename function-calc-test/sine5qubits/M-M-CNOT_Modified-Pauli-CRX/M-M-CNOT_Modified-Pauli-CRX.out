/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:31 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:03 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:43:42 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:50:12 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 21:56:10 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:03:46 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1847.6653943061829 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:08:50 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:14:28 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:21:01 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:26:59 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:32 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1848.5271577835083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:39:38 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:45:20 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:51:51 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:57:50 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:05:29 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1860.163407087326 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:10:39 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:16:20 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:22:51 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:28:52 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:36:25 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1851.3664410114288 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:41:31 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:47:11 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:53:51 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:00:04 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:07:54 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1895.630129814148 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:13:10 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:18:51 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:25:41 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:31:40 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:39:15 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1880.7683155536652 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:44:26 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:50:02 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:56:42 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:02:56 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:10:31 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1874.567652463913 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:15:41 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:21:17 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:27:56 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:34:00 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:41:31 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1854.6468827724457 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:46:36 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:52:25 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:59:00 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:05:00 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:12:35 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1864.9211785793304 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:17:41 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:23:25 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:29:57 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:35:56 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:43:31 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1856.8664774894714 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:48:37 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:54:15 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:00:46 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:06:49 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:14:22 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1847.751374721527 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:19:25 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:25:03 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:31:37 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:38:00 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:45:34 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1876.608834028244 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:50:42 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:56:42 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:03:36 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:09:34 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:17:06 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1892.4935059547424 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 04:22:15 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:27:51 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:34:21 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:40:28 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:48:11 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1862.834645986557 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:53:17 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:58:57 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:05:41 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:12:22 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:20:02 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1912.491281747818 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 05:25:10 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:30:56 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:37:28 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:43:33 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:51:06 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1868.0474145412445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:56:18 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:02:00 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:08:33 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:14:32 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:22:06 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1862.1537518501282 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 06:27:20 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:33:06 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:39:40 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:45:44 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:53:26 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1871.9087219238281 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 06:58:32 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:04:14 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:10:55 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:17:20 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:25:05 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1897.1468341350555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 07:30:09 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:35:48 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:42:19 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:48:35 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:56:09 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1868.5381999015808 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 08:01:19 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:07:02 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:13:32 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:19:49 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:27:24 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1879.741073846817 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 08:32:37 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:38:19 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:44:50 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:50:53 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:58:28 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1855.943335533142 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 09:03:33 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:09:08 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:15:37 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:21:35 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:29:08 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1840.5581030845642 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 09:34:14 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:39:51 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:46:22 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:52:19 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:59:48 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1840.7427861690521 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 10:04:54 2024]  Iteration number: 0 with current cost as 0.3194485452380824 and parameters 
[-3.31055776  1.85184913 -2.30923713 -0.11653103  0.55388704 -2.77010908
  3.06858495  2.18960141  1.18551995 -1.06648312  2.15134153  1.14432441
  1.31029895 -1.87354676  0.72965073  2.88578416 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 10:10:31 2024]  Iteration number: 0 with current cost as 0.31970236617204295 and parameters 
[-3.32030025  1.89174453 -2.32665216 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551995 -1.06648316  1.97842338  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:17:01 2024]  Iteration number: 0 with current cost as 0.3200537326919193 and parameters 
[-3.32416591  1.89782816 -2.32694683 -0.11653103  0.55388704 -2.77010905
  3.06858491  2.18960145  1.18551991 -1.06648316  1.94966422  1.14432445
  1.31029891 -1.8735468   0.72965073  2.88578412 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 10:23:01 2024]  Iteration number: 0 with current cost as 0.31818833543649483 and parameters 
[-3.21554196  1.89048427 -2.29101514 -0.11653103  0.55388708 -2.77010905
  3.06858491  2.18960145  1.18551998 -1.06648316  2.02523013  1.14432445
  1.31029895 -1.8735468   0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 10:30:34 2024]  Iteration number: 0 with current cost as 0.310617803101193 and parameters 
[-3.37313254  1.85360438 -2.31954978 -0.11653099  0.55388708 -2.77010905
  3.06858495  2.18960149  1.18552002 -1.06648308  2.14623467  1.14432445
  1.31029899 -1.87354673  0.72965073  2.88578419 -0.54534328 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1846.7960398197174 seconds. 
Discarding model... 

Training complete taking 46658.88064336777 total seconds. 
Now scoring model... 
Scoring complete taking 1.127164602279663 seconds. 
Saved predicted values as M-M-CNOT_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.36779686161993297,), 'R2_train': 0.2676298625787089, 'MAE_train': 0.5248935324381504, 'MSE_test': 0.3868630328745253, 'R2_test': 0.27851400309231555, 'MAE_test': 0.5540017053083074}. 
Saved model results as M-M-CNOT_Modified-Pauli-CRX_results.json. 
