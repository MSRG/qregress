/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 22:03:30 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:03:48 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:33 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 22:17:40 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:26:37 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Thu Apr  4 22:27:57 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Thu Apr  4 22:34:38 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Thu Apr  4 22:44:06 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2498.795585632324 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:45:27 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 22:52:15 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 22:59:24 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:08:10 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Thu Apr  4 23:09:31 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Thu Apr  4 23:16:15 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Thu Apr  4 23:25:35 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2487.973569869995 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:26:55 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Thu Apr  4 23:33:44 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 23:40:56 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:49:38 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Thu Apr  4 23:50:58 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Thu Apr  4 23:58:11 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 00:07:36 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2521.982752084732 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:08:56 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 00:15:50 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 00:23:00 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:31:44 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 00:33:07 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 00:40:05 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 00:49:24 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2507.288838148117 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:50:45 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 00:57:28 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 01:04:58 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:13:44 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 01:15:04 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 01:21:52 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 01:31:11 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2506.949654817581 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:32:30 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 01:39:14 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 01:46:18 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:55:10 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 01:56:38 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 02:03:37 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 02:13:02 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2513.9039330482483 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:14:24 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 02:21:18 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 02:28:37 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:37:49 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 02:39:14 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 02:47:34 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 02:56:54 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2628.821266412735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 02:58:14 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 03:04:52 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 03:12:06 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:20:56 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 03:22:38 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 03:29:35 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 03:38:51 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2517.4391441345215 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:40:11 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 03:46:49 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 03:53:53 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:02:38 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 04:03:59 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 04:11:01 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 04:20:18 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2488.8396713733673 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:21:39 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 04:28:36 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 04:35:48 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:44:32 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 04:45:52 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 04:52:31 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 05:01:54 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2493.7190487384796 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 05:03:13 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 05:09:51 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 05:17:24 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:26:05 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 05:27:25 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 05:34:11 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 05:43:31 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2497.723422765732 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:44:52 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 05:51:35 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 05:58:49 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:08:06 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 06:09:26 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 06:16:11 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 06:26:03 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2551.0959012508392 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 06:27:23 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 06:34:00 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 06:41:03 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:49:54 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 06:51:12 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 06:58:42 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 07:07:59 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2516.656198501587 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 07:09:18 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 07:16:08 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 07:23:17 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:32:00 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 07:33:19 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 07:40:13 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 07:49:35 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2495.904621362686 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 07:50:55 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 07:58:37 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 08:06:02 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:15:19 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 08:16:39 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 08:23:17 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 08:32:38 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2583.8885519504547 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 08:33:59 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 08:41:04 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 08:48:07 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:56:48 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 08:58:08 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 09:04:56 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 09:14:15 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2495.9600880146027 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 09:15:35 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 09:22:14 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 09:29:18 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:38:02 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 09:39:21 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 09:45:58 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 09:55:17 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2462.216543197632 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 09:56:44 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 10:03:35 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 10:10:49 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:19:42 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 10:21:01 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 10:27:41 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 10:37:08 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2511.7064747810364 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 10:38:28 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 10:45:18 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 10:52:22 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:01:04 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 11:02:24 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 11:09:21 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 11:18:51 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2502.2678718566895 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 11:20:12 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 11:26:55 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 11:34:00 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:42:44 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 11:44:04 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 11:50:43 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 12:00:00 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2469.42462348938 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 12:01:21 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 12:07:59 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 12:15:17 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:25:00 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 12:26:20 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 12:33:15 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 12:43:19 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2597.747759103775 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 12:44:37 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 12:51:35 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 12:59:10 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:07:57 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 13:09:18 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 13:15:58 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 13:25:19 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2520.064595937729 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 13:26:37 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 13:33:20 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 13:40:24 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:49:05 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 13:50:25 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 13:57:05 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 14:06:24 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2465.1491775512695 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 14:07:42 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 14:14:26 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 14:21:44 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 14:30:36 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 14:31:56 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 14:38:36 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 14:47:56 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2492.3473629951477 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 14:49:15 2024]  Iteration number: 0 with current cost as 0.20509684477356338 and parameters 
[-2.96002197  2.97095374 -2.16027051 -0.11653102  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551999 -1.06648309  0.92655239  1.14432445
  1.2416824  -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Fri Apr  5 14:56:21 2024]  Iteration number: 0 with current cost as 0.20753784946966047 and parameters 
[-2.95228676  2.98111831 -2.16490058 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648308  0.92208563  1.14432444
  1.23214818 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 15:03:32 2024]  Iteration number: 0 with current cost as 0.2088268720706215 and parameters 
[-2.95482447  3.02332806 -2.16692706 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.94090843  1.14432445
  1.22779064 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077106 -1.2645671  -0.25136105]. 
[Fri Apr  5 15:12:24 2024]  Iteration number: 50 with current cost as 0.07470124494161326 and parameters 
[-3.27201395  4.36105656 -1.57223949 -0.11653091  0.55388756 -2.77010936
  3.06858466  2.18960143  1.18551967 -1.06648332 -2.86455838  1.14432437
  1.52729459 -1.87354716  0.72965051  2.88578357 -0.54534364 -0.47522518
 -2.02654224  0.72897304  1.60512622  2.83077075 -1.26456698 -0.25136084]. 
Working on 0.8 fold... 
[Fri Apr  5 15:13:44 2024]  Iteration number: 0 with current cost as 0.19455718387432952 and parameters 
[-2.91905774  2.91792969 -2.15594417 -0.11653102  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  0.91999218  1.14432445
  1.2073918  -1.8735468   0.72965081  2.8857842  -0.54534334 -0.47522484
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Fri Apr  5 15:20:26 2024]  Iteration number: 0 with current cost as 0.20953583972739365 and parameters 
[-2.96953918  2.96608058 -2.16314399 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.91237062  1.14432446
  1.25294525 -1.8735468   0.72965081  2.8857842  -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136104]. 
[Fri Apr  5 15:29:44 2024]  Iteration number: 50 with current cost as 0.08331272333147187 and parameters 
[-3.37006666  4.68129338 -1.57777352 -0.11653057  0.55388675 -2.77010908
  3.06858568  2.18959891  1.18551943 -1.06648484 -2.95113662  1.14432524
  1.54267892 -1.87354696  0.72964953  2.88578506 -0.54534369 -0.47522437
 -2.02654279  0.72897258  1.60512577  2.83077297 -1.26456698 -0.25136035]. 
Training complete taking 2508.362888813019 seconds. 
Discarding model... 

Training complete taking 62836.231159448624 total seconds. 
Now scoring model... 
Scoring complete taking 1.1810534000396729 seconds. 
Saved predicted values as IQP_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.1423909060109866,), 'R2_train': 0.7164661847751973, 'MAE_train': 0.31762495017445225, 'MSE_test': 0.15397670001621314, 'R2_test': 0.7128388512949893, 'MAE_test': 0.33829267391994}. 
Saved model results as IQP_Full-Pauli-CRZ_results.json. 
