/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:32:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:32:44 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Thu Apr  4 21:36:23 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Thu Apr  4 21:40:13 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Thu Apr  4 21:44:09 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Thu Apr  4 21:48:15 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1181.606882572174 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:24 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Thu Apr  4 21:56:03 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Thu Apr  4 21:59:53 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Thu Apr  4 22:03:49 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Thu Apr  4 22:07:53 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1178.5007967948914 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:12:02 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Thu Apr  4 22:15:41 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Thu Apr  4 22:19:30 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Thu Apr  4 22:23:26 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Thu Apr  4 22:27:31 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1181.9588387012482 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:31:44 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Thu Apr  4 22:35:29 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Thu Apr  4 22:39:20 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Thu Apr  4 22:43:14 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Thu Apr  4 22:47:22 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1188.674566745758 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:51:33 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Thu Apr  4 22:55:15 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Thu Apr  4 22:59:07 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Thu Apr  4 23:03:05 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Thu Apr  4 23:07:10 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1187.4706571102142 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:11:22 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Thu Apr  4 23:15:04 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Thu Apr  4 23:18:55 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Thu Apr  4 23:22:52 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Thu Apr  4 23:26:57 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1186.0401737689972 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:31:07 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Thu Apr  4 23:34:47 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Thu Apr  4 23:38:40 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Thu Apr  4 23:42:36 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Thu Apr  4 23:46:41 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1183.0247797966003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:50:50 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Thu Apr  4 23:54:30 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Thu Apr  4 23:58:20 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 00:02:13 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 00:06:16 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1172.4157395362854 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:10:23 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 00:14:02 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 00:17:50 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 00:21:43 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 00:25:48 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1175.0171852111816 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:29:58 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 00:33:37 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 00:37:25 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 00:41:18 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 00:45:25 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1176.3201370239258 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:49:34 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 00:53:13 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 00:57:04 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 01:01:00 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 01:05:05 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1178.0135147571564 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:09:11 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 01:12:50 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 01:16:41 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 01:20:35 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 01:24:39 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1177.8284480571747 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:28:49 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 01:32:31 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 01:36:20 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 01:40:12 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 01:44:19 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1178.4123556613922 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:48:28 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 01:52:08 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 01:55:57 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 01:59:52 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 02:04:00 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1178.2342646121979 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:08:07 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 02:11:44 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 02:15:35 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 02:19:27 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 02:23:34 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1178.2124507427216 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:27:44 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 02:31:27 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 02:35:19 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 02:39:12 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 02:43:15 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1178.645350933075 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:47:23 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 02:51:03 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 02:54:51 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 02:58:45 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 03:02:49 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1174.3886942863464 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:06:57 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 03:10:36 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 03:14:23 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 03:18:17 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 03:22:21 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1172.7227256298065 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:26:30 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 03:30:10 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 03:33:59 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 03:37:53 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 03:41:56 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1172.1435387134552 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:46:02 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 03:49:42 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 03:53:31 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 03:57:27 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 04:01:31 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1178.8075060844421 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:05:42 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 04:09:20 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 04:13:11 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 04:17:02 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 04:21:05 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1172.8147037029266 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 04:25:15 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 04:28:54 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 04:32:43 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 04:36:36 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 04:40:40 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1173.5268375873566 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:44:48 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 04:48:25 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 04:52:16 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 04:56:14 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 05:00:16 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1177.954124212265 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:04:25 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 05:08:04 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 05:11:53 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 05:15:47 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 05:19:48 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1172.9757676124573 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:23:58 2024]  Iteration number: 0 with current cost as 0.28532510929031907 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.128667    0.56319328 -2.76960431
  3.18695218  2.00562269  1.08623617 -1.16573408  0.68896579  1.0508118
  1.27528465 -1.94489308  0.59167446]. 
Working on 0.4 fold... 
[Fri Apr  5 05:27:37 2024]  Iteration number: 0 with current cost as 0.2843843406402812 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.14148451  0.57345689 -2.76838103
  3.1796781   1.99405496  1.10536415 -1.17012432  0.69220121  1.04649411
  1.29224736 -1.93309663  0.57701136]. 
Working on 0.6 fold... 
[Fri Apr  5 05:31:27 2024]  Iteration number: 0 with current cost as 0.2739514789521984 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.15661228  0.58093417 -2.77429762
  3.17756584  1.98692129  1.11306819 -1.17410535  0.70393859  1.04533139
  1.29753639 -1.92839426  0.57610595]. 
Working on 0.8 fold... 
[Fri Apr  5 05:35:22 2024]  Iteration number: 0 with current cost as 0.2754247231250889 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764972  0.55663402 -2.77882138
  3.18937497  1.99632444  1.08735474 -1.16692944  0.66817181  1.04285938
  1.27211084 -1.95089346  0.58083852]. 
Working on 1.0 fold... 
[Fri Apr  5 05:39:26 2024]  Iteration number: 0 with current cost as 0.2913287272397056 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12247016  0.56331211 -2.76212942
  3.19588459  2.0005153   1.07374577 -1.16302151  0.70303231  1.05850256
  1.27659836 -1.94506623  0.58664835]. 
Training complete taking 1178.0931162834167 seconds. 
Discarding model... 

Training complete taking 29453.804987192154 total seconds. 
Now scoring model... 
Scoring complete taking 0.8224806785583496 seconds. 
Saved predicted values as M-A2-CNOT_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.16539058968350645,), 'R2_train': 0.6706684000477794, 'MAE_train': 0.3442449250842413, 'MSE_test': 0.20673814392324497, 'R2_test': 0.6144406076770723, 'MAE_test': 0.40485621535953387}. 
Saved model results as M-A2-CNOT_HWE-CNOT_results.json. 
