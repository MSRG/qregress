/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:37:41 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 21:39:55 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 21:43:12 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 21:46:02 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 21:47:51 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 738.1768324375153 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:49:59 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 21:52:11 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 21:55:32 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 21:58:20 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:00:10 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 739.5133628845215 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:02:19 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 22:04:34 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 22:07:55 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 22:10:46 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:12:38 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 747.90190076828 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:14:46 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 22:16:59 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 22:20:15 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 22:23:07 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:24:57 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 739.425140619278 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:27:06 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 22:29:18 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 22:32:37 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 22:35:26 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:37:18 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 740.1908051967621 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:39:26 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 22:41:42 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 22:44:59 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 22:47:50 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:49:42 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 745.2095091342926 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:51:51 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 22:54:21 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 22:57:36 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 23:00:25 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:02:14 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 755.4108331203461 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:04:27 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 23:06:39 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 23:09:53 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 23:12:48 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:14:41 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 742.6234886646271 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:16:49 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 23:19:06 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 23:22:21 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 23:25:11 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:27:00 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 738.2178626060486 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:29:08 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 23:31:19 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 23:34:35 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 23:37:22 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:39:11 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 731.266443490982 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:41:19 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 23:43:31 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 23:47:04 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Thu Apr  4 23:49:53 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:51:42 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 756.1577053070068 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:53:55 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Thu Apr  4 23:56:07 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Thu Apr  4 23:59:22 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 00:02:11 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:04:00 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 732.1830413341522 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:06:08 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 00:08:19 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 00:11:34 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 00:14:24 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:16:13 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 733.9906787872314 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:18:21 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 00:20:33 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 00:23:52 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 00:26:42 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:28:30 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 735.6815052032471 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:30:38 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 00:32:49 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 00:36:05 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 00:38:55 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:40:45 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 738.0465598106384 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:42:55 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 00:45:07 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 00:48:23 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 00:51:22 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:53:11 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 744.3976864814758 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:55:19 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 00:57:32 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 01:00:48 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 01:03:36 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:05:27 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 735.9615898132324 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:07:35 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 01:09:51 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 01:13:09 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 01:15:58 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:17:57 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 749.4686026573181 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:20:05 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 01:22:16 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 01:25:32 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 01:28:24 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:30:12 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 734.6971361637115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:32:19 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 01:34:31 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 01:37:47 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 01:40:35 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:43:00 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 768.0262801647186 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:45:08 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 01:47:19 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 01:50:35 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 01:53:26 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:55:15 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 735.7292244434357 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:57:23 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 01:59:34 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 02:02:50 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 02:05:38 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:07:27 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 731.5664050579071 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 02:09:35 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 02:11:47 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 02:15:07 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 02:18:13 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:20:17 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 770.0716080665588 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:22:25 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 02:24:37 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 02:27:53 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 02:30:41 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:32:36 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 739.2092046737671 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:34:45 2024]  Iteration number: 0 with current cost as 0.34997452058953327 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12592372  0.5680285  -2.75870257
  3.0304083   2.25124204  1.21623054 -1.10376304  0.70441039  1.13086654
  1.40259062 -1.77765186  0.76339904]. 
Working on 0.4 fold... 
[Fri Apr  5 02:36:57 2024]  Iteration number: 0 with current cost as 0.35730990576044097 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12764329  0.56992057 -2.75772068
  3.01921571  2.25777768  1.231804   -1.10772636  0.71526168  1.12944825
  1.40593249 -1.7743656   0.76395487]. 
Working on 0.6 fold... 
[Fri Apr  5 02:40:11 2024]  Iteration number: 0 with current cost as 0.35864528102728227 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.12917497  0.5709966  -2.75781336
  3.01783614  2.26162481  1.23199138 -1.11038258  0.72085377  1.12797231
  1.40292416 -1.77692783  0.76487232]. 
Working on 0.8 fold... 
[Fri Apr  5 02:43:01 2024]  Iteration number: 0 with current cost as 0.2400458877049476 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.16367662  0.61894322 -2.72226235
  2.91569208  2.45913533  1.29560097 -1.24604476  1.08816889  1.07813737
  1.81125157 -1.3408504   0.9564567 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:44:50 2024]  Iteration number: 0 with current cost as 0.347101208562248 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.12442898  0.56862515 -2.75599785
  3.02471163  2.25649751  1.22305837 -1.10291083  0.70680592  1.13265
  1.39973489 -1.78331857  0.75269074]. 
Training complete taking 733.7772126197815 seconds. 
Discarding model... 

Training complete taking 18556.90226817131 total seconds. 
Now scoring model... 
Scoring complete taking 1.0074739456176758 seconds. 
Saved predicted values as A2_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.1858261674319608,), 'R2_train': 0.6299763538514074, 'MAE_train': 0.3616153365862478, 'MSE_test': 0.21987390616004668, 'R2_test': 0.5899428715089463, 'MAE_test': 0.4230187430318028}. 
Saved model results as A2_HWE-CNOT_results.json. 
