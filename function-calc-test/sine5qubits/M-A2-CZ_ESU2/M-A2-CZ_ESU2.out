/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:39:06 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 21:41:33 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 21:43:44 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 21:46:46 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 21:48:51 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 780.1411099433899 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:52:11 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 21:54:38 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 21:56:46 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 21:59:40 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:01:35 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 757.9563059806824 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:04:58 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 22:07:34 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:09:41 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 22:12:34 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:14:26 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 775.9199781417847 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:17:42 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 22:20:07 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:22:16 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 22:25:20 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:27:11 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 762.667635679245 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:30:25 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 22:32:49 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:34:54 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 22:37:57 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:39:54 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 763.1262786388397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:43:09 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 22:45:40 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 22:47:47 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 22:50:42 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 22:52:37 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 764.9220705032349 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:56:01 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 22:58:28 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:00:41 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:03:43 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:05:40 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 786.9886410236359 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:09:05 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 23:11:40 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:13:49 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:16:42 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:18:38 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 782.3889243602753 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:22:07 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 23:24:34 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:26:51 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:30:00 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:31:55 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 793.1397783756256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:35:22 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 23:37:57 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:40:07 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:43:10 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:45:09 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 791.6811096668243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:48:27 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Thu Apr  4 23:50:49 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Thu Apr  4 23:53:06 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Thu Apr  4 23:56:04 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Thu Apr  4 23:57:58 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 766.6620888710022 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:01:15 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 00:03:40 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:05:46 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:08:50 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:10:47 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 765.5595262050629 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:14:05 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 00:16:26 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:18:40 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:21:40 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:23:42 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 774.5108108520508 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:26:52 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 00:29:14 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:31:23 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:34:23 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:36:13 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 749.330135345459 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:39:25 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 00:41:56 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:44:04 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 00:47:09 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 00:49:03 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 770.1837646961212 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:52:12 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 00:54:51 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 00:57:08 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:00:09 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:02:13 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 789.3429982662201 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:05:22 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 01:07:49 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:10:12 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:13:18 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:15:10 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 789.2848477363586 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:18:33 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 01:20:58 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:23:09 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:26:04 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:27:56 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 754.159182548523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:31:07 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 01:33:31 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:35:41 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:38:42 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:40:38 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 766.0590589046478 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:43:53 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 01:46:16 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 01:48:22 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 01:51:20 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 01:53:09 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 750.9874539375305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:56:23 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 01:58:48 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 02:00:56 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:03:59 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 02:05:54 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 766.5893602371216 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:09:08 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 02:11:35 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 02:13:48 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:16:48 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 02:18:40 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 761.0188510417938 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 02:21:51 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 02:24:13 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 02:26:22 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:29:19 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 02:31:16 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 762.9237928390503 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 02:34:33 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 02:37:08 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 02:39:26 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:42:36 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 02:44:30 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 786.2773444652557 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:47:38 2024]  Iteration number: 0 with current cost as 0.2644362680704638 and parameters 
[-1.45242586  2.23743464 -2.1242795  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552005 -1.06648315]. 
Working on 0.4 fold... 
[Fri Apr  5 02:50:03 2024]  Iteration number: 0 with current cost as 0.2706493773402697 and parameters 
[-1.41123272  2.23743464 -2.12427943 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960156  1.18552019 -1.06648308]. 
Working on 0.6 fold... 
[Fri Apr  5 02:52:27 2024]  Iteration number: 0 with current cost as 0.2757499642725535 and parameters 
[-1.55733742  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010906
  3.0685849   2.18960145  1.18551998 -1.06648325]. 
Working on 0.8 fold... 
[Fri Apr  5 02:55:34 2024]  Iteration number: 0 with current cost as 0.2843993524719194 and parameters 
[-1.39075208  2.23743492 -2.12427935 -0.11653074  0.55388722 -2.77010883
  3.06858498  2.18960174  1.18552027 -1.06648308]. 
Working on 1.0 fold... 
[Fri Apr  5 02:57:32 2024]  Iteration number: 0 with current cost as 0.2577575781921281 and parameters 
[-1.57609709  2.23743475 -2.12427952 -0.11653097  0.55388714 -2.77010897
  3.06858498  2.18960157  1.1855201  -1.06648308]. 
Training complete taking 784.3798830509186 seconds. 
Discarding model... 

Training complete taking 19296.201606988907 total seconds. 
Now scoring model... 
Scoring complete taking 2.3215978145599365 seconds. 
Saved predicted values as M-A2-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.4513467087777401,), 'R2_train': 0.10126244776449056, 'MAE_train': 0.5734909662050018, 'MSE_test': 0.4295603984667243, 'R2_test': 0.198884912789415, 'MAE_test': 0.5755259413922986}. 
Saved model results as M-A2-CZ_ESU2_results.json. 
