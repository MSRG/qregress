/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:41:12 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:41:59 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:43:55 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 21:45:35 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 21:47:11 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 21:48:46 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 518.4590873718262 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:50:42 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 21:52:32 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 21:54:13 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 21:55:58 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 21:57:46 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 544.3747062683105 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 21:59:43 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:41 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 22:03:20 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 22:04:54 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 22:06:35 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 526.1372489929199 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:08:35 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:10:33 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 22:12:17 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 22:14:05 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 22:15:47 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 555.6565957069397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:17:54 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:19:50 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 22:21:33 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 22:23:12 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 22:24:54 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 546.6656730175018 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 22:26:53 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:28:48 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 22:30:27 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 22:32:11 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 22:33:56 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 539.1838638782501 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:35:51 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:37:50 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 22:39:29 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 22:41:07 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 22:42:45 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 532.2327814102173 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:44:50 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:46:55 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 22:48:38 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 22:50:25 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 22:52:05 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 563.8580324649811 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:54:17 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 22:56:26 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 22:58:09 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 22:59:45 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 23:01:19 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 546.6355338096619 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:03:13 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:05:10 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 23:06:46 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 23:08:22 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 23:10:05 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 521.7935392856598 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:11:58 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:13:52 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 23:15:25 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 23:17:05 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 23:18:42 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 520.8758239746094 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:20:39 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:22:38 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 23:24:16 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 23:26:00 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 23:27:35 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 532.603910446167 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:29:28 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:31:17 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 23:32:55 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 23:34:31 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 23:36:07 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 511.5620753765106 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:38:05 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:40:06 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 23:41:47 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 23:43:26 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 23:45:04 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 536.9402203559875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 23:46:59 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:48:57 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 23:50:43 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Thu Apr  4 23:52:27 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Thu Apr  4 23:54:08 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 544.1519746780396 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:56:04 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Thu Apr  4 23:58:00 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Thu Apr  4 23:59:44 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 00:01:34 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 00:03:16 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 550.0901160240173 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:05:23 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:07:26 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 00:09:09 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 00:10:47 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 00:12:28 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 552.0497448444366 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:14:23 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:16:21 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 00:18:01 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 00:19:42 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 00:21:24 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 541.9587109088898 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:23:28 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:25:27 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 00:27:07 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 00:28:48 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 00:30:34 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 545.2971038818359 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:32:32 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:34:27 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 00:36:06 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 00:37:47 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 00:39:22 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 526.3488488197327 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:41:21 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:43:16 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 00:44:55 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 00:46:38 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 00:48:20 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 535.9399747848511 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 00:50:13 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 00:52:08 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 00:53:51 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 00:55:33 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 00:57:24 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 549.9428906440735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 00:59:29 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:01:23 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 01:03:02 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 01:04:52 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 01:06:42 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 559.1113471984863 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:08:51 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:10:50 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 01:12:30 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 01:14:06 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 01:15:48 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 540.4069993495941 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:17:47 2024]  Iteration number: 0 with current cost as 0.25748899660563185 and parameters 
[-1.30749443  2.23743467 -2.12427956 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552006 -1.06648308]. 
Working on 0.4 fold... 
[Fri Apr  5 01:19:44 2024]  Iteration number: 0 with current cost as 0.2281213009873403 and parameters 
[-1.58833285  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010901
  3.06858498  2.18960145  1.18551998 -1.06648316]. 
Working on 0.6 fold... 
[Fri Apr  5 01:21:32 2024]  Iteration number: 0 with current cost as 0.23915273051790542 and parameters 
[-1.53411963  2.2374346  -2.12427964 -0.11653103  0.553887   -2.77010905
  3.06858491  2.18960138  1.18551995 -1.06648316]. 
Working on 0.8 fold... 
[Fri Apr  5 01:23:15 2024]  Iteration number: 0 with current cost as 0.2141117122093396 and parameters 
[-1.52900097  2.23743464 -2.12427964 -0.11653103  0.55388704 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648316]. 
Working on 1.0 fold... 
[Fri Apr  5 01:24:54 2024]  Iteration number: 0 with current cost as 0.26006318005931967 and parameters 
[-1.29760013  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960141  1.18552002 -1.06648312]. 
Training complete taking 545.083028793335 seconds. 
Discarding model... 

Training complete taking 13487.36071062088 total seconds. 
Now scoring model... 
Scoring complete taking 2.3174030780792236 seconds. 
Saved predicted values as M-A1-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (0.37801547807515606,), 'R2_train': 0.24728219157193265, 'MAE_train': 0.524297977333182, 'MSE_test': 0.4121631898422355, 'R2_test': 0.23133009710848973, 'MAE_test': 0.5771248222377874}. 
Saved model results as M-A1-CZ_ESU2_results.json. 
