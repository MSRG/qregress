/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:45 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:04 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:41:38 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Thu Apr  4 21:45:21 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Thu Apr  4 21:49:03 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Thu Apr  4 21:53:59 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1168.7533633708954 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 21:57:32 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:01:04 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Thu Apr  4 22:04:43 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Thu Apr  4 22:08:28 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Thu Apr  4 22:13:24 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1163.6885797977448 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 22:16:56 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:20:29 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Thu Apr  4 22:24:08 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Thu Apr  4 22:27:53 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Thu Apr  4 22:32:48 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1167.0780982971191 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 22:36:23 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:40:05 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Thu Apr  4 22:43:44 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Thu Apr  4 22:47:35 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Thu Apr  4 22:52:30 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1181.220003604889 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Apr  4 22:56:04 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:59:38 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Thu Apr  4 23:03:29 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Thu Apr  4 23:07:31 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Thu Apr  4 23:12:24 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1194.4614441394806 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 23:15:59 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:19:30 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Thu Apr  4 23:23:09 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Thu Apr  4 23:27:03 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Thu Apr  4 23:31:57 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1169.5479147434235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 23:35:28 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:38:58 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Thu Apr  4 23:42:35 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Thu Apr  4 23:46:18 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Thu Apr  4 23:51:16 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1163.4790921211243 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:54:50 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:58:21 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 00:02:01 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 00:05:44 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 00:10:37 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1156.4512605667114 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:14:08 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:17:39 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 00:21:16 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 00:25:01 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 00:29:59 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1163.750718832016 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:33:32 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:37:04 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 00:40:41 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 00:44:24 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 00:49:18 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1166.0217607021332 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 00:52:58 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:56:33 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 01:00:39 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 01:04:24 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 01:09:19 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1197.9671530723572 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:12:54 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:16:25 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 01:20:06 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 01:23:50 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 01:28:45 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1166.0783681869507 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 01:32:20 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:36:08 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 01:39:48 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 01:43:33 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 01:48:25 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1182.6744878292084 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 01:52:05 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:55:42 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 01:59:27 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 02:03:32 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 02:08:27 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1195.2836935520172 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 02:11:58 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:15:30 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 02:19:08 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 02:22:51 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 02:27:51 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1166.051425933838 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:31:24 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:34:57 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 02:38:41 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 02:42:31 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 02:47:27 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1172.9180946350098 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 02:50:57 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:54:47 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 02:58:30 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 03:02:25 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 03:07:21 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1194.1604297161102 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 03:10:53 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:14:27 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 03:18:05 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 03:21:48 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 03:26:45 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1164.2087700366974 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:30:17 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:33:50 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 03:37:27 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 03:41:12 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 03:46:06 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1162.0495626926422 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 03:49:38 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:53:11 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 03:56:49 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 04:00:32 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 04:05:26 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1159.0126028060913 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:08:58 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:12:31 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 04:16:09 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 04:19:53 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 04:24:47 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1160.552276134491 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 04:28:19 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:31:51 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 04:35:30 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 04:39:15 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 04:44:15 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1186.299622297287 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:48:04 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:51:41 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 04:55:29 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 04:59:26 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 05:04:23 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1189.6849465370178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:07:55 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:11:27 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 05:15:06 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 05:18:52 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 05:23:48 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1163.8821682929993 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 05:27:19 2024]  Iteration number: 0 with current cost as 0.19491428414505896 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.02453547  0.58692366 -2.60949336
  3.10736384  2.21053518  1.10674533 -0.81244822  0.88141737  1.53983249
  1.006856   -2.12306315  0.8541582 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:30:52 2024]  Iteration number: 0 with current cost as 0.2052731748624902 and parameters 
[-2.90318343  2.23743464 -2.12427964 -0.060583    0.5851355  -2.65471678
  3.11064129  2.16567863  1.1266409  -0.7815586   0.85527874  1.56915661
  1.03376782 -2.10733933  0.82018499]. 
Working on 0.6 fold... 
[Fri Apr  5 05:34:31 2024]  Iteration number: 0 with current cost as 0.20232717953667967 and parameters 
[-2.90318345  2.23743464 -2.12427965 -0.06218012  0.56432914 -2.68962596
  3.15159559  2.08055399  1.10451597 -0.74773432  0.80680858  1.59506094
  1.04389465 -2.11928954  0.74343792]. 
Working on 0.8 fold... 
[Fri Apr  5 05:38:14 2024]  Iteration number: 0 with current cost as 0.1935373374721871 and parameters 
[-2.90318345  2.23743465 -2.12427964 -0.06115397  0.60261162 -2.62764378
  3.10055187  2.21727268  1.11465185 -0.8332465   0.87761025  1.51339539
  1.0036641  -2.1228156   0.86575024]. 
Working on 1.0 fold... 
[Fri Apr  5 05:43:10 2024]  Iteration number: 0 with current cost as 0.19068607437081553 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.0250416   0.59371501 -2.5993068
  3.09729665  2.24485906  1.1045533  -0.79785229  0.90423943  1.5646858
  1.00670509 -2.11745065  0.87475693]. 
Training complete taking 1165.2112748622894 seconds. 
Discarding model... 

Training complete taking 29320.488998413086 total seconds. 
Now scoring model... 
Scoring complete taking 2.6859254837036133 seconds. 
Saved predicted values as M-M-CNOT_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (0.11050663458119074,), 'R2_train': 0.7799552753176485, 'MAE_train': 0.28192284989920974, 'MSE_test': 0.12265210386295869, 'R2_test': 0.7712581252055352, 'MAE_test': 0.3226515616523474}. 
Saved model results as M-M-CNOT_HWE-CNOT_results.json. 
