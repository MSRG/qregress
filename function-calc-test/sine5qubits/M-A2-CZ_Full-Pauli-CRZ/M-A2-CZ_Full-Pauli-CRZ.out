/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:26 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:02 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 21:48:42 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Thu Apr  4 21:50:44 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 22:00:13 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Apr  4 22:10:32 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Apr  4 22:19:35 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:32:15 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3325.005052804947 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:33:28 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 22:43:53 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Thu Apr  4 22:45:56 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 22:55:22 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Thu Apr  4 23:05:40 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Thu Apr  4 23:14:44 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:27:29 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3313.359623670578 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:28:40 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Thu Apr  4 23:39:15 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Thu Apr  4 23:41:15 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Thu Apr  4 23:50:52 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 00:01:11 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 00:10:15 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:22:54 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3326.440710067749 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 00:24:07 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 00:34:29 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 00:36:34 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 00:46:02 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 00:56:17 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 01:05:27 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:18:37 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3347.087543964386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 01:20:01 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 01:30:48 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 01:32:49 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 01:42:25 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 01:52:49 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 02:01:52 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:14:49 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3366.8533549308777 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 02:16:08 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 02:26:32 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 02:28:47 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 02:38:17 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 02:48:53 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 02:57:56 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:10:36 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3348.5642352104187 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 03:11:49 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 03:22:32 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 03:24:50 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 03:34:48 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 03:45:10 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 03:54:10 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:07:05 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3387.4839425086975 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 04:08:18 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 04:18:52 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 04:20:52 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 04:30:44 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 04:40:59 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 04:50:15 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:03:30 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3384.6865668296814 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 05:05:02 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:15:29 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 05:17:30 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 05:26:56 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 05:37:11 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 05:46:41 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 05:59:19 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3350.050822019577 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 06:00:32 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:10:58 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 06:12:59 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 06:22:24 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 06:32:41 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 06:41:58 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 06:54:37 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3316.8851952552795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 06:56:14 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:06:40 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 07:08:40 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 07:18:07 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 07:28:22 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 07:37:25 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 07:50:17 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3339.8962354660034 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 07:51:30 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:02:11 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 08:04:13 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 08:13:44 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 08:24:02 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 08:33:36 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:46:13 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3356.51251912117 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 08:47:25 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 08:58:14 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 09:00:14 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 09:09:39 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 09:19:53 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 09:28:54 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:41:33 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3321.135344028473 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 09:42:46 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 09:53:15 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 09:55:15 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 10:04:41 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 10:15:01 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 10:24:26 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:37:04 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3330.662523984909 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 10:38:17 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 10:48:41 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 10:50:41 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 11:00:05 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 11:10:22 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 11:19:23 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:32:05 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3299.7021605968475 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 11:33:23 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 11:44:14 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 11:46:15 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 11:55:47 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 12:06:18 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 12:15:21 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:28:03 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3358.6210050582886 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 12:29:16 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 12:39:44 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 12:41:45 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 12:51:12 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 13:01:24 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 13:10:51 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:24:27 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3383.316852092743 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 13:25:38 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 13:36:06 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 13:38:06 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 13:47:29 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 13:57:42 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 14:06:47 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 14:19:27 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3299.9122626781464 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 14:20:38 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 14:31:03 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 14:33:03 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 14:42:29 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 14:52:43 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 15:02:01 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 15:14:37 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3310.4984002113342 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 15:15:49 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 15:26:14 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 15:28:14 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 15:37:48 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 15:48:00 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 15:57:09 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 16:10:25 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3348.976068496704 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 16:11:44 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 16:22:11 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 16:24:20 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 16:33:49 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 16:44:04 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 16:53:12 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 17:06:14 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3348.395535469055 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 17:07:26 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 17:17:57 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 17:19:57 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 17:29:58 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 17:40:15 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 17:49:32 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 18:02:09 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3355.158789396286 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 18:03:22 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 18:13:48 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 18:15:48 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 18:25:21 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 18:36:15 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 18:45:16 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 18:58:27 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3377.8081679344177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 18:59:40 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 19:10:05 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 19:12:05 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 19:21:34 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 19:31:49 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 19:40:52 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 19:53:44 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3316.126389980316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 19:54:55 2024]  Iteration number: 0 with current cost as 0.09872825187812158 and parameters 
[-3.13840603  2.27066034 -2.12483397 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63149097  1.14432445
  1.56309002 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 20:05:31 2024]  Iteration number: 50 with current cost as 0.04255097920102403 and parameters 
[-1.95533051  2.51836723 -0.96084833 -0.11653798  0.55388171 -2.77011531
  3.06858192  2.1896011   1.18552352 -1.06648336  3.39710486  1.14432452
  2.23487105 -1.87354826  0.7296531   2.88578418 -0.54533302 -0.47521987
 -2.02654338  0.72897344  1.60513005  2.83077058 -1.26456776 -0.25136265]. 
Working on 0.4 fold... 
[Fri Apr  5 20:07:31 2024]  Iteration number: 0 with current cost as 0.16588228192528803 and parameters 
[-3.28900869  2.30560299 -2.12774543 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.65937654  1.14432445
  1.72218934 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.26456709 -0.25136105]. 
Working on 0.6 fold... 
[Fri Apr  5 20:17:18 2024]  Iteration number: 0 with current cost as 0.1811766126314745 and parameters 
[-3.31246191  2.3043609  -2.127162   -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.65707757  1.14432445
  1.74822646 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512663  2.83077107 -1.2645671  -0.25136105]. 
Working on 0.8 fold... 
[Fri Apr  5 20:27:37 2024]  Iteration number: 0 with current cost as 0.1740978572763324 and parameters 
[-3.32209633  2.32602042 -2.13217665 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.68192777  1.14432445
  1.75606786 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Fri Apr  5 20:36:38 2024]  Iteration number: 0 with current cost as 0.09860417670788854 and parameters 
[-3.1362922   2.26730914 -2.12464064 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.62851066  1.14432445
  1.56091057 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Fri Apr  5 20:49:39 2024]  Iteration number: 50 with current cost as 0.04161366244832264 and parameters 
[-5.09674043  0.65099252 -0.98193668 -0.11652945  0.55388851 -2.77010816
  3.06858657  2.18960161  1.18552032 -1.06648149  2.84272233  1.14432345
  0.93909422 -1.87354517  0.72965026  2.88578443 -0.54534284 -0.47522472
 -2.02654309  0.72897437  1.60512544  2.83077008 -1.26456689 -0.25136124]. 
Training complete taking 3355.705904006958 seconds. 
Discarding model... 

Training complete taking 83568.8469479084 total seconds. 
Now scoring model... 
Scoring complete taking 2.0283544063568115 seconds. 
Saved predicted values as M-A2-CZ_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (0.07269195029717009,), 'R2_train': 0.8552532139777376, 'MAE_train': 0.22290804063268438, 'MSE_test': 0.07484234449374887, 'R2_test': 0.8604216507150884, 'MAE_test': 0.23762562626815353}. 
Saved model results as M-A2-CZ_Full-Pauli-CRZ_results.json. 
