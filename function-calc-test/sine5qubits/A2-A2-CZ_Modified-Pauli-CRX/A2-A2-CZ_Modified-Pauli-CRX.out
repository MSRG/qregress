/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/sine5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/sine5qubits/sine_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/sine5qubits/sine_train.bin 
 at time Thu Apr  4 21:37:45 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Apr  4 21:38:08 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 21:45:56 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 21:55:14 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:03:10 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:14:16 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2563.292832136154 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Apr  4 22:20:51 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 22:28:42 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 22:38:07 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 22:46:04 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 22:57:24 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2615.4552211761475 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Apr  4 23:04:28 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:12:12 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Thu Apr  4 23:21:34 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Thu Apr  4 23:29:31 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Thu Apr  4 23:41:01 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2617.089838027954 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Apr  4 23:48:03 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Thu Apr  4 23:55:53 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:05:15 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:13:22 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 00:24:28 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2578.68585562706 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 00:31:02 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 00:38:45 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 00:48:06 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 00:56:03 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:07:08 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2576.109819173813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 01:13:58 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 01:21:42 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 01:31:00 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 01:39:00 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 01:50:14 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2583.923570871353 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 01:57:03 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:04:59 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:14:24 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 02:22:24 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 02:33:26 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2578.83673787117 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 02:40:01 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 02:47:53 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 02:57:35 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:05:36 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:16:44 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2596.6051046848297 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 03:23:18 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 03:31:09 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 03:40:29 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 03:48:32 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 03:59:36 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2583.0586562156677 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 04:06:21 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:14:15 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 04:23:53 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 04:32:18 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 04:43:45 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2654.346846342087 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 04:50:36 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 04:58:22 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:08:06 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:16:05 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 05:27:11 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2592.8146550655365 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 05:33:49 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 05:41:36 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 05:50:55 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 05:59:36 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:11:00 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2630.219297885895 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 06:17:38 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 06:25:26 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 06:34:46 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 06:42:42 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 06:53:49 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2569.193130016327 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 07:00:27 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:08:15 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 07:17:34 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 07:25:31 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 07:36:32 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2557.6583185195923 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 07:43:06 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 07:50:53 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:00:17 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:08:17 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 08:19:20 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2569.8829021453857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 08:25:55 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 08:33:48 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 08:43:07 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 08:51:05 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:02:08 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2575.974709033966 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 09:08:51 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:16:36 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 09:26:01 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 09:33:59 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 09:45:06 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2571.4311277866364 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 09:51:43 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 09:59:31 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:08:54 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 10:16:52 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 10:28:22 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2599.2884328365326 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 10:35:03 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 10:42:49 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 10:52:10 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 11:00:08 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 11:11:10 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2564.232088327408 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 11:17:46 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 11:25:34 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 11:34:54 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 11:42:51 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 11:53:52 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2558.515221118927 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Fri Apr  5 12:00:25 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 12:08:11 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 12:17:37 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 12:25:35 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 12:36:40 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2570.188405275345 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Fri Apr  5 12:43:15 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 12:50:59 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 13:00:18 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 13:08:17 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 13:19:24 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2565.2440650463104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Fri Apr  5 13:26:00 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 13:33:47 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 13:43:05 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 13:51:19 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 14:02:43 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2604.029759168625 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Fri Apr  5 14:09:25 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 14:17:11 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 14:26:48 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 14:34:53 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 14:46:01 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2594.128518104553 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Fri Apr  5 14:52:38 2024]  Iteration number: 0 with current cost as 0.34391998998599793 and parameters 
[-3.15759471  2.25651847 -2.20037522 -0.11653101  0.55388709 -2.77010897
  3.06858498  2.18960146  1.18551999 -1.06648308  1.05946361  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Fri Apr  5 15:00:50 2024]  Iteration number: 0 with current cost as 0.357464895423097 and parameters 
[-3.12611267  2.26607114 -2.18706194 -0.11653101  0.55388709 -2.77010898
  3.06858499  2.18960146  1.18551999 -1.06648308  0.97687266  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Fri Apr  5 15:10:14 2024]  Iteration number: 0 with current cost as 0.3781276464207967 and parameters 
[-3.12064566  2.25818793 -2.18968562 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960147  1.18551999 -1.06648308  0.98839682  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Fri Apr  5 15:18:13 2024]  Iteration number: 0 with current cost as 0.30593497212237886 and parameters 
[-3.18239992  2.28682771 -2.19384043 -0.11653101  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18551998 -1.06648308  1.03396953  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Fri Apr  5 15:29:27 2024]  Iteration number: 0 with current cost as 0.33366413212020424 and parameters 
[-3.14940217  2.25016558 -2.20148213 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  1.05373112  1.14432445
  1.31029899 -1.8735468   0.72965079  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2608.122974395752 seconds. 
Discarding model... 

Training complete taking 64678.33013176918 total seconds. 
Now scoring model... 
Scoring complete taking 1.5274746417999268 seconds. 
Saved predicted values as A2-A2-CZ_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (0.3649474066596818,), 'R2_train': 0.27330379821704887, 'MAE_train': 0.5128569005655483, 'MSE_test': 0.31185324992228075, 'R2_test': 0.4184046192336668, 'MAE_test': 0.5048059654732606}. 
Saved model results as A2-A2-CZ_Modified-Pauli-CRX_results.json. 
