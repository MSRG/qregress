/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:14 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:44:26 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 15:46:24 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:48:12 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:49:57 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 15:51:30 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 526.2507498264313 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:53:14 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 15:55:14 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:56:59 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:58:46 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:00:20 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 529.5874695777893 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:01 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:04:01 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:05:48 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:07:34 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:09:08 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 526.8016285896301 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:10:50 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:12:50 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:14:36 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:16:29 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:18:03 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 534.4461073875427 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:19:44 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:21:49 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:23:36 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:26 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:00 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 537.9281594753265 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:41 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:30:41 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:32:29 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:34:19 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:35:54 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 537.2024536132812 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:38 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:39:40 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:27 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:43:18 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:44:54 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 540.8963942527771 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:46:39 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:48:39 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:50:27 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:12 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:53:49 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 530.2777881622314 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:29 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:31 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:19 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:05 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:02:39 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 530.405880689621 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:04:22 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:06:33 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:22 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:10:09 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:11:43 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 543.9050714969635 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:13:25 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:15:25 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:17:11 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:19:04 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:20:39 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 551.9742956161499 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:22:37 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:24:38 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:26:26 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:28:14 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:29:54 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 540.2985548973083 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:31:36 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:33:37 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:35:24 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:37:12 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:38:47 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 531.4613626003265 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:40:29 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:42:29 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:44:15 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:46:03 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:47:38 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 533.1471612453461 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:49:22 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:23 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:53:11 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:55:03 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:56:39 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 552.5023889541626 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:58:33 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:00:32 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:02:18 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:04:08 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:05:43 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 533.2176897525787 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:07:27 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:09:27 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:11:16 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:13:10 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:14:43 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 540.9220380783081 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:28 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:18:26 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:20:30 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:22:16 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:59 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 553.3126873970032 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:25:40 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:27:40 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:29:40 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:31:33 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:33:18 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 557.9079747200012 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:35:00 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:37:00 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:38:46 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:40:33 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:42:06 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 539.7740886211395 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:43:59 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:45:59 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:47:45 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:49:32 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:51:05 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 527.6428482532501 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:52:45 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:54:45 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:56:32 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:58:18 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 18:59:56 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 531.3264901638031 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:01:37 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 19:03:40 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:05:41 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:07:43 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:09:30 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 580.3219153881073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:11:17 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 19:13:15 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:15:03 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:16:49 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:18:25 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 526.1720552444458 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:20:05 2024]  Iteration number: 0 with current cost as 0.2491349928176429 and parameters 
[-3.30180798  2.02763974 -1.31485698 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 19:22:04 2024]  Iteration number: 0 with current cost as 0.28377682159001094 and parameters 
[-3.25476767  2.05115842 -1.40940151 -0.11653103  0.55388706 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:23:49 2024]  Iteration number: 0 with current cost as 0.254143293154467 and parameters 
[-3.31974383  2.01918145 -1.27920819 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:25:37 2024]  Iteration number: 0 with current cost as 0.21617096010348247 and parameters 
[-3.31509589  2.00930632 -1.27896948 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 19:27:11 2024]  Iteration number: 0 with current cost as 0.27685010220490386 and parameters 
[-3.23478475  2.04695974 -1.43842072 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 527.2396266460419 seconds. 
Discarding model... 

Training complete taking 13464.924020767212 total seconds. 
Now scoring model... 
Scoring complete taking 0.9040720462799072 seconds. 
Saved predicted values as A2-A2-CNOT_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (3.936775401728667,), 'R2_train': 0.4594511021280746, 'MAE_train': 1.2488777431532045, 'MSE_test': 3.9345790648101344, 'R2_test': 0.6077592230590231, 'MAE_test': 1.5565555284450627}. 
Saved model results as A2-A2-CNOT_HWE-CZ_results.json. 
