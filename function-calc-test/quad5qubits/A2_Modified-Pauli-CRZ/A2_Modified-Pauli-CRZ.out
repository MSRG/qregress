/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:46:31 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:47:00 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:47:38 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:48:33 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:49:16 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:49:56 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 220.30992817878723 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:50:39 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:51:18 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:52:08 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:52:52 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:53:32 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.20333123207092 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 15:54:17 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:54:57 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:55:46 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:56:32 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:57:10 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 219.46544814109802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 15:57:55 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:58:34 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:59:25 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:00:09 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:00:48 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 217.49018096923828 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:01:34 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:02:12 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:03:03 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:03:56 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:04:41 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 235.02972412109375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:05:28 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:06:07 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:06:58 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:07:41 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:08:20 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 217.254816532135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:09:05 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:09:44 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:34 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:18 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:11:59 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 217.25029063224792 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:12:42 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:13:21 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:14:12 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:59 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:15:38 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 219.2914755344391 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:16:23 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:17:04 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:17:53 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:18:41 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:19:19 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 223.22676515579224 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:20:05 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:20:43 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:21:35 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:22:19 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:22:59 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 218.07417702674866 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:23:43 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:24:22 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:25:13 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:58 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:26:36 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 217.00037670135498 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:27:20 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:28:00 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:28:49 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:29:39 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:30:18 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 223.43182802200317 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:31:04 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:31:42 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:32:33 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:33:16 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:55 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.53811144828796 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:34:40 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:35:18 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:36:09 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:52 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:37:32 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 215.5480318069458 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:38:18 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:39:02 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:40:00 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:40:43 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:41:22 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 231.5063762664795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:42:07 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:42:55 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:00 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:44:44 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:45:22 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 239.8336250782013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:46:09 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:46:48 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:38 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:48:26 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:49:06 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 222.40164995193481 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:49:49 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:50:36 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:43 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:37 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:53:24 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 260.2456023693085 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:54:11 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:54:49 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:55:39 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:56:23 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:57:03 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.73670291900635 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:57:46 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:58:25 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:16 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:00:02 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:00:40 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 217.1657304763794 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:01:24 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:02:04 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:02:52 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:03:38 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:04:16 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 218.0585389137268 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:02 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:05:40 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:06:31 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:07:14 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:07:53 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.41642379760742 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:08:38 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:16 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:10:07 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:10:50 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:11:30 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 215.91510653495789 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:12:14 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:12:52 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:13:43 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:14:26 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:15:07 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 216.46680974960327 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:50 2024]  Iteration number: 0 with current cost as 0.10169638679730778 and parameters 
[-4.08085322  2.23743458 -2.12427964 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648314  0.6027151   1.14432445
  1.31029896 -1.87354675  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:16:37 2024]  Iteration number: 0 with current cost as 0.09915977592556374 and parameters 
[-4.0819364   2.23743461 -2.12427961 -0.116531    0.55388706 -2.77010897
  3.06858496  2.18960145  1.18551996 -1.06648311  0.6027151   1.14432443
  1.31029896 -1.87354678  0.72965076  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:17:26 2024]  Iteration number: 0 with current cost as 0.10581478332861781 and parameters 
[-4.07412584  2.23743461 -2.12427961 -0.11653103  0.55388705 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313  0.6027151   1.14432445
  1.31029899 -1.87354678  0.72965075  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:18:11 2024]  Iteration number: 0 with current cost as 0.08752176144788248 and parameters 
[-4.05783283  2.23743464 -2.12427958 -0.116531    0.55388711 -2.77010894
  3.06858501  2.18960148  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.87354677  0.72965077  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:18:50 2024]  Iteration number: 0 with current cost as 0.08855552958447326 and parameters 
[-4.09013748  2.23743464 -2.12427959 -0.116531    0.55388708 -2.77010895
  3.06858498  2.18960148  1.18552001 -1.06648311  0.6027151   1.14432448
  1.31029899 -1.87354678  0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 224.75619983673096 seconds. 
Discarding model... 

Training complete taking 5555.619256019592 total seconds. 
Now scoring model... 
Scoring complete taking 0.7779598236083984 seconds. 
Saved predicted values as A2_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (2.1224792392424154,), 'R2_train': 0.7085676228761385, 'MAE_train': 1.2181502325575155, 'MSE_test': 3.0395138430704787, 'R2_test': 0.6969888641985262, 'MAE_test': 1.5096786806251923}. 
Saved model results as A2_Modified-Pauli-CRZ_results.json. 
