/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:18:57 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:20:12 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 16:22:28 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:23:59 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:59 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:28:30 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 621.3237330913544 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:30:34 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 16:32:54 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:34:26 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:27 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:39:01 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 628.8986597061157 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:03 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:21 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:51 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:46:54 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:49:27 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 627.7530090808868 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:51:30 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 16:53:49 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 16:55:20 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:19 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:59:53 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 623.9585916996002 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:02:01 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 17:04:17 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:05:51 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:07:51 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:10:26 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 635.5626578330994 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:12:33 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:56 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:16:28 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:18:33 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:21:03 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 635.6721506118774 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:23:06 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 17:25:23 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:26:54 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:28:59 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:31:34 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 630.7427883148193 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:33:40 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 17:35:59 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:37:31 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:33 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:42:04 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 630.9654376506805 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:44:07 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 17:46:24 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:47:59 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 17:50:03 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:52:32 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 626.5762400627136 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:54:34 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 17:56:52 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 17:58:23 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:00:22 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:02:54 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 621.0282559394836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:04:54 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 18:07:07 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:08:36 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:10:35 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:13:09 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 615.6883318424225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:15:10 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 18:17:27 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:18:59 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:21:01 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:32 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 622.1546800136566 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:25:31 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 18:27:46 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:29:21 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:31:29 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:34:07 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 637.6259496212006 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:36:15 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 18:38:35 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:40:09 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:42:16 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:44:53 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 644.6935501098633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:46:59 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 18:49:20 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 18:50:54 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 18:53:03 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:55:45 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 655.9143996238708 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:57:55 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 19:00:19 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 19:01:57 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 19:04:05 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:06:44 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 655.4549248218536 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:08:48 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 19:11:10 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 19:12:46 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 19:14:55 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:17:35 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 654.545060634613 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:19:43 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 19:22:11 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 19:23:48 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 19:26:01 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:28:40 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 666.3008749485016 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:30:50 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 19:33:18 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 19:34:56 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 19:37:04 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:39:44 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 661.8987486362457 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:41:53 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 19:44:17 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 19:45:53 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 19:48:00 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:50:48 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 665.7714741230011 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:53:04 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 19:55:30 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 19:57:07 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 19:59:16 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 20:01:56 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 664.0823969841003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:04:12 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 20:06:46 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 20:08:22 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 20:10:30 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 20:13:10 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 677.9982686042786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:15:21 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 20:17:43 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 20:19:18 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 20:21:28 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 20:24:07 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 653.0869810581207 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:26:14 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 20:28:38 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 20:30:13 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 20:32:16 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 20:34:53 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 647.1316883563995 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:37:02 2024]  Iteration number: 0 with current cost as 0.24488622505421126 and parameters 
[-2.60259664  2.23743468 -2.12427964 -0.11653103  0.55388712 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648313]. 
Working on 0.4 fold... 
[Mon Apr  1 20:39:23 2024]  Iteration number: 0 with current cost as 0.23393273864024344 and parameters 
[-2.4679476   2.23743464 -2.12427964 -0.11653107  0.55388708 -2.77010901
  3.06858498  2.18960141  1.18551998 -1.06648312]. 
Working on 0.6 fold... 
[Mon Apr  1 20:40:59 2024]  Iteration number: 0 with current cost as 0.22062559455730932 and parameters 
[-2.52780561  2.23743467 -2.12427964 -0.11653103  0.55388708 -2.77010889
  3.06858502  2.18960145  1.18551998 -1.06648308]. 
Working on 0.8 fold... 
[Mon Apr  1 20:43:03 2024]  Iteration number: 0 with current cost as 0.17129351773906284 and parameters 
[-2.8390573   2.23743479 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 20:45:38 2024]  Iteration number: 0 with current cost as 0.1791868823220228 and parameters 
[-2.78689956  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648326]. 
Training complete taking 642.2760424613953 seconds. 
Discarding model... 

Training complete taking 16047.105800151825 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 2.910841226577759 seconds. 
Saved predicted values as M-A2-CNOT_ESU2_predicted_values.csv
Model scores: {'MSE_train': (4.6698243301709805,), 'R2_train': 0.35879796601528213, 'MAE_train': 1.3499021614331208, 'MSE_test': 6.23028207923948, 'R2_test': 0.37889907838457315, 'MAE_test': 1.8185683160518002}. 
Saved model results as M-A2-CNOT_ESU2_results.json. 
