/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:46:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:47:12 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:48:40 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:50:01 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:51:31 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:52:43 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 389.9499087333679 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:53:41 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:55:02 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:56:22 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:57:54 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:59:00 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 374.2215495109558 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 15:59:56 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:01:17 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:02:38 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:04:07 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:05:12 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 371.41877245903015 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:08 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:32 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:08:52 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:10:21 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:11:26 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 375.8705542087555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:12:23 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:13:45 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:15:07 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:16:39 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:44 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 377.7867896556854 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:18:42 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:20:03 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:21:23 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:22:54 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:23:59 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 374.92060351371765 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:24:56 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:26:17 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:27:39 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:29:09 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:30:13 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 372.8532989025116 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:31:16 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:32:40 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:34:02 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:35:30 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:36:36 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 382.81585454940796 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:35 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:38:55 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:40:21 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:41:53 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:42:58 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 384.08898997306824 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:43:56 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:45:17 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:46:40 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:48:09 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:49:15 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 376.0124018192291 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:50:12 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:51:39 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:52:59 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:54:29 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:55:35 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 378.81597447395325 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:56:36 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:58:00 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:23 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:00:53 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:58 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 384.85220432281494 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:02:57 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:04:18 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:05:41 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:07:11 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:08:31 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 392.6159963607788 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:28 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:10:49 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:11 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:42 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:47 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 376.5785231590271 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:45 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:07 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:28 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:19:57 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:21:02 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 374.6908700466156 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:21:59 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:23:21 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:24:43 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:26:12 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:17 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 373.6533932685852 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:28:14 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:29:36 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:30:57 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:32:26 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:33:32 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 375.92084670066833 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:34:29 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:35:51 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:37:13 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:38:42 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:39:47 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 374.1514346599579 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:40:47 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:42:20 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:43:41 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:45:10 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:46:16 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 393.03520154953003 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:47:22 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:48:45 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:50:07 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:51:35 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:52:40 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 379.9203779697418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:53:38 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:54:59 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:56:20 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:57:49 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:58:54 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 375.15062165260315 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:59:51 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:01:30 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:02:51 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:04:21 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:05:25 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 391.14912939071655 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:06:22 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:07:45 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:09:06 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:10:39 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:11:43 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 376.27439165115356 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:12:40 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:14:00 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:15:21 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:16:50 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:17:55 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 373.48357701301575 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:18:52 2024]  Iteration number: 0 with current cost as 0.2827689602808695 and parameters 
[-2.3053075   2.23743467 -2.1242796  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029899 -1.87354677  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:20:13 2024]  Iteration number: 0 with current cost as 0.2639135086379711 and parameters 
[-2.28729064  2.23743467 -2.1242796  -0.11653099  0.55388708 -2.77010894
  3.06858502  2.18960149  1.18552006 -1.06648312  0.60271518  1.14432449
  1.31029899 -1.87354676  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:21:34 2024]  Iteration number: 0 with current cost as 0.2531625413049228 and parameters 
[-2.37353658  2.23743464 -2.1242796  -0.11653103  0.55388704 -2.77010897
  3.06858498  2.18960149  1.18552002 -1.06648312  0.60271514  1.14432449
  1.31029895 -1.87354677  0.7296508   2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:23:03 2024]  Iteration number: 0 with current cost as 0.19339387390904514 and parameters 
[-2.44440212  2.23743466 -2.12427961 -0.116531    0.55388711 -2.77010897
  3.06858498  2.18960154  1.18552001 -1.06648308  0.60271516  1.14432448
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534332 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:24:09 2024]  Iteration number: 0 with current cost as 0.20577283546084446 and parameters 
[-2.36037789  2.23743466 -2.12427958 -0.11653097  0.55388708 -2.77010894
  3.06858504  2.18960151  1.18552001 -1.06648317  0.60271513  1.14432448
  1.31029896 -1.87354677  0.72965077  2.88578416 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 372.44217824935913 seconds. 
Discarding model... 

Training complete taking 9472.674337863922 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 0.9733414649963379 seconds. 
Saved predicted values as M-M-CNOT_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (5.300948236210035,), 'R2_train': 0.2721399027485202, 'MAE_train': 1.5546260739172664, 'MSE_test': 14.149148460365225, 'R2_test': -0.41053792381084, 'MAE_test': 2.5902186472688618}. 
Saved model results as M-M-CNOT_Modified-Pauli-CRZ_results.json. 
