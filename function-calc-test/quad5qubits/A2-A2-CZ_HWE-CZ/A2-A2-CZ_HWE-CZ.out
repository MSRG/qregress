/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:51 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:07 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:03:50 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:05:31 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:07:14 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:09:15 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 544.346607208252 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:11:11 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:12:52 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:14:35 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:16:17 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:18:14 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 538.8761010169983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:20:10 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:21:51 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:23:34 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:17 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:12 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 538.2190339565277 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:29:08 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:30:49 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:32:33 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:34:16 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:36:12 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 540.8005945682526 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:38:09 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:39:53 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:34 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:43:17 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:45:13 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 540.1498458385468 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:47:09 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:48:51 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:50:32 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:15 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:19 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 546.7260899543762 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:56:16 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:59 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:43 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:24 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:03:35 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 557.5114130973816 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:32 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:07:16 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:58 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:10:49 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:12:46 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 549.4316473007202 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:14:43 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:16:32 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:15 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:19:58 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:01 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 557.1028125286102 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:23:59 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:25:42 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:27:22 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:29:03 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:30:58 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 536.7756218910217 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:32:55 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:34:38 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:36:21 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:38:03 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:39:58 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 536.6242225170135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:41:53 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:43:35 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:45:18 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:46:59 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:48:56 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 539.3715193271637 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:50:53 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:52:35 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:54:19 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:56:01 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:57:57 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 541.6083815097809 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:59:54 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:01:36 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:03:19 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:05:01 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:06:58 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 540.5765552520752 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:08:55 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:10:37 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:12:19 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:14:00 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:15:55 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 536.8806781768799 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:17:52 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:19:34 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:21:16 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:22:57 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:24:53 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 536.4483406543732 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:26:48 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:29 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:30:10 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:31:51 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:33:47 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 535.0183854103088 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:35:42 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:37:24 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:39:05 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:40:47 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:42:43 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 536.9450614452362 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:44:39 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:46:20 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:48:01 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:49:42 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:51:38 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 535.6446135044098 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:53:35 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:55:17 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:56:59 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:58:40 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:00:38 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 538.9111433029175 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:02:33 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:04:15 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:05:58 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:07:39 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:09:35 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 536.0892691612244 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:11:31 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:13:12 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:14:54 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:16:35 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:18:32 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 537.7080454826355 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:20:28 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:22:10 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:23:53 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:25:35 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:27:31 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 543.7203280925751 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:29:32 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:31:17 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:33:01 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:34:42 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:36:38 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 550.6693968772888 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:38:42 2024]  Iteration number: 0 with current cost as 0.2536900971393721 and parameters 
[-3.43456322  2.2379942  -1.26536449 -0.11653101  0.55388708 -2.77010898
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:40:28 2024]  Iteration number: 0 with current cost as 0.28684449897524256 and parameters 
[-3.40252169  2.25052787 -1.32702576 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:42:13 2024]  Iteration number: 0 with current cost as 0.2742237214890909 and parameters 
[-3.43283537  2.23309178 -1.26430872 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960146  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:44:00 2024]  Iteration number: 0 with current cost as 0.244505778877712 and parameters 
[-3.44317694  2.26308457 -1.2711389  -0.11653102  0.55388708 -2.77010898
  3.06858499  2.18960147  1.18552    -1.06648308  0.60271511  1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:45:56 2024]  Iteration number: 0 with current cost as 0.2723624947387163 and parameters 
[-3.40979637  2.27742235 -1.33638249 -0.11653101  0.55388709 -2.77010897
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.31029899 -1.87354679  0.7296508 ]. 
Training complete taking 554.1890256404877 seconds. 
Discarding model... 

Training complete taking 13550.346658468246 total seconds. 
Now scoring model... 
Scoring complete taking 1.0736536979675293 seconds. 
Saved predicted values as A2-A2-CZ_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (3.4141128344932326,), 'R2_train': 0.5312166071030261, 'MAE_train': 1.251676900692673, 'MSE_test': 6.577122722571841, 'R2_test': 0.3443223063399736, 'MAE_test': 1.861268008254974}. 
Saved model results as A2-A2-CZ_HWE-CZ_results.json. 
