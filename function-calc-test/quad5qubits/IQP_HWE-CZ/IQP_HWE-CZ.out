/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:06:04 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:13 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:06:53 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:07:27 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:08:01 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:08:40 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.82720160484314 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:09:19 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:09:57 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:32 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:06 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:11:45 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.59396886825562 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:12:24 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:13:03 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:13:37 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:11 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:14:50 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 185.9845519065857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:15:29 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:16:07 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:16:41 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:17:15 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:54 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 183.403737783432 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:18:32 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:19:10 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:19:44 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:20:19 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:20:58 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.76501870155334 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:37 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:22:17 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:22:51 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:23:24 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:24:03 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.46099710464478 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:24:41 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:25:21 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:25:55 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:26:29 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:07 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.29367399215698 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:27:47 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:28:26 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:28:59 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:29:33 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:30:11 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 185.4009017944336 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:30:52 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:31:31 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:32:05 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:40 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:20 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 188.61679410934448 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:34:00 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:34:38 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:35:12 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:35:47 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:36:26 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 185.23763251304626 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:05 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:44 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:38:19 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:38:53 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:39:32 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 185.68882131576538 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:40:10 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:40:50 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:25 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:41:58 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:42:38 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 186.6457278728485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:43:18 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:56 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:30 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:45:04 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:45:43 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.82301688194275 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:46:23 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:02 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:35 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:48:09 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:48:49 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 185.77170777320862 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:49:28 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:50:06 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:50:40 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:51:15 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:51:54 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.7845652103424 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:52:32 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:53:11 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:53:45 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:54:21 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:55:01 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 186.7696225643158 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:39 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:56:19 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:56:53 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:28 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:58:06 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 185.7490222454071 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:58:45 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:24 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:58 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:00:34 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:12 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 185.52397537231445 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:01:52 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:02:32 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:03:06 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:03:40 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:04:20 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 188.85123896598816 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:00 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:05:38 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:06:12 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:06:47 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:07:26 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.66585898399353 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:08:04 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:08:43 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:09:16 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:09:51 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:10:30 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.1219780445099 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:11:08 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:11:47 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:23 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:12:58 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:13:36 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 186.60826230049133 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:14:15 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:54 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:15:28 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:16:03 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:16:41 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 185.26362442970276 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:17:21 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:59 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:33 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:19:07 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:19:46 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 184.15946054458618 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:20:25 2024]  Iteration number: 0 with current cost as 0.28690259672972107 and parameters 
[-2.66945125  2.18944505 -2.46458607 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:21:04 2024]  Iteration number: 0 with current cost as 0.30283154232620774 and parameters 
[-2.70191561  2.25004914 -2.45967949 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029898 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:21:38 2024]  Iteration number: 0 with current cost as 0.30510171935783337 and parameters 
[-2.71751632  2.22753417 -2.41676776 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029898 -1.8735468   0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:22:12 2024]  Iteration number: 0 with current cost as 0.25812235933583777 and parameters 
[-2.76020133  2.23996607 -2.35750032 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:52 2024]  Iteration number: 0 with current cost as 0.27332026367751977 and parameters 
[-2.78496381  2.31049689 -2.37284523 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029898 -1.8735468   0.7296508 ]. 
Training complete taking 186.34492206573486 seconds. 
Discarding model... 

Training complete taking 4637.357705354691 total seconds. 
Now scoring model... 
Scoring complete taking 0.8013913631439209 seconds. 
Saved predicted values as IQP_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (6.101623298417271,), 'R2_train': 0.16220118939453776, 'MAE_train': 2.028056232274995, 'MSE_test': 9.547707294341118, 'R2_test': 0.04818277496779444, 'MAE_test': 2.734125256201824}. 
Saved model results as IQP_HWE-CZ_results.json. 
