/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:13:23 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:14:27 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:15:45 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:17:25 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:18:26 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:19:28 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.16323685646057 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:13 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:22:34 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:24:12 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:13 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:26:15 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.76654171943665 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:01 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:29:22 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:30:59 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:02 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:03 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.6491606235504 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:34:50 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:36:09 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:37:45 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:38:49 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:39:51 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 406.0842695236206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:37 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:42:57 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:43 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:45:44 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:46:46 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 416.2084126472473 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:48:33 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:49:53 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:32 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:35 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:53:37 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 410.7907350063324 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:23 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:56:42 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:58:22 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:59:24 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:00:26 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.2257113456726 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:02:11 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:03:31 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:05:11 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:06:13 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:07:16 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 411.2748644351959 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:03 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:10:24 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:02 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:06 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:19 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 423.2935311794281 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:16:07 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:27 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:19:03 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:20:05 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:21:07 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.0976605415344 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:22:55 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:24:14 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:25:54 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:26:56 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:58 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 409.08919763565063 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:29:44 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:31:08 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:32:46 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:33:49 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:52 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 414.315279006958 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:36:41 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:38:01 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:39:38 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:40:40 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:41:43 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 411.92947578430176 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:43:30 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:44:48 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:46:27 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:47:30 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:48:32 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 408.0380780696869 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:50:18 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:38 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:53:16 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:54:18 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:55:20 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 409.01383447647095 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:57:07 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:58:27 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:03 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:01:06 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:02:08 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 406.35666680336 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:03:55 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:05:15 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:06:54 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:08:01 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:09:02 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 414.5263092517853 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:10:56 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:12:28 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:14:05 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:15:06 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:16:08 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 425.6894006729126 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:17:56 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:19:15 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:20:55 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:21:58 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:00 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 411.6354522705078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:24:44 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:26:04 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:27:41 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:28:43 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:29:45 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 407.3179967403412 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:31:32 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:32:52 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:34:32 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:35:35 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:36:37 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 409.8993020057678 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:38:22 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:39:41 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:41:18 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:42:20 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:43:23 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 407.3897988796234 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:45:09 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:46:30 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:48:08 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:49:11 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:50:13 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 411.8126347064972 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:52:02 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:53:22 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:55:01 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:56:02 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:57:04 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 407.5959846973419 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:58:50 2024]  Iteration number: 0 with current cost as 0.18039407725769707 and parameters 
[-3.7774903   2.23743475 -2.12427952 -0.11653103  0.55388708 -2.77010903
  3.06858498  2.18960145  1.1855201  -1.06648314  0.6027151   1.14432445
  1.31029899 -1.87354674  0.72965069  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:00:10 2024]  Iteration number: 0 with current cost as 0.20244007862256067 and parameters 
[-3.79579124  2.23743484 -2.12427943 -0.11653082  0.55388729 -2.77010918
  3.06858509  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432435
  1.31029899 -1.8735467   0.7296507   2.88578409 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:01:49 2024]  Iteration number: 0 with current cost as 0.18506972243018086 and parameters 
[-3.74431288  2.23743477 -2.1242795  -0.11653096  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552018 -1.06648302  0.6027151   1.14432452
  1.31029905 -1.87354667  0.72965087  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:02:51 2024]  Iteration number: 0 with current cost as 0.17922244057680004 and parameters 
[-2.87751892  2.23743471 -2.12427956 -0.11653095  0.55388712 -2.77010897
  3.06858502  2.18960149  1.1855201  -1.06648308  0.60271514  1.14432449
  1.31029902 -1.87354672  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:03:53 2024]  Iteration number: 0 with current cost as 0.19754162003151962 and parameters 
[-2.8142967   2.23743465 -2.12427962 -0.116531    0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648308  0.6027151   1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 410.5079872608185 seconds. 
Discarding model... 

Training complete taking 10274.673077106476 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.0908753871917725 seconds. 
Saved predicted values as M-A1-CZ_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (4.623524785143897,), 'R2_train': 0.3651552420807067, 'MAE_train': 1.517788159100522, 'MSE_test': 11.98163908636899, 'R2_test': -0.19445748753571857, 'MAE_test': 2.47062094561366}. 
Saved model results as M-A1-CZ_Modified-Pauli-CRZ_results.json. 
