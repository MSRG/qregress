/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:35 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:01:44 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:02:43 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:03:33 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:04:14 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:04:53 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 243.05650210380554 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:05:47 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:06:45 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:07:35 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:08:16 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:08:55 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 242.6003544330597 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:09:49 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:10:48 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:38 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:12:18 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:12:57 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 244.12252187728882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:13:54 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:14:52 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:15:41 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:16:22 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:01 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 241.43353748321533 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:17:55 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:18:53 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:19:43 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:20:23 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:21:03 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 241.82824993133545 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:57 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:22:55 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:23:44 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:24:27 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:25:06 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 243.51356673240662 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:26:00 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:27:00 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:27:49 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:28:30 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:29:10 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 243.368549823761 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:30:04 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:31:03 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:52 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:36 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:20 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 248.32166004180908 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:34:13 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:35:16 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:36:05 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:46 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:37:27 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 247.46347856521606 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:38:21 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:39:20 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:40:08 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:40:49 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:41:39 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 253.58733320236206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:42:33 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:31 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:21 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:45:00 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:45:41 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 242.44641518592834 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:46:36 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:34 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:48:24 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:49:03 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:49:45 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 243.0810785293579 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:50:39 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:51:38 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:52:28 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:53:08 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:53:49 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 244.47869753837585 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:54:43 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:55:42 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 16:56:31 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:11 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 16:57:54 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 244.85803747177124 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:58:48 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:46 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:00:36 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:18 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:58 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 243.35495281219482 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:02:51 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:03:50 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:04:39 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:05:20 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:06:00 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 242.73250603675842 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:06:54 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:07:53 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:42 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:09:27 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:10:07 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 246.7634048461914 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:11:01 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:12:00 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:50 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:31 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:10 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 243.33471059799194 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:04 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:16:03 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:16:52 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:34 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:18:14 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 243.64597034454346 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:19:08 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:20:06 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:20:57 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:21:38 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:19 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 244.88107109069824 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:23:13 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:24:11 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:25:01 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:25:41 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:26:22 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 242.30067896842957 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:27:16 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:28:13 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:29:03 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:29:44 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:30:25 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 242.91244316101074 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:31:19 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:32:17 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:33:06 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:33:48 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:28 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 243.12167978286743 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:35:22 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:36:21 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:37:09 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:37:50 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:38:31 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 242.82942533493042 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:39:25 2024]  Iteration number: 0 with current cost as 0.6622647966310733 and parameters 
[-3.23240863  1.95566941 -1.37056887 -0.11653101  0.55388711 -2.77010897
  3.068585    2.18960147  1.18552001 -1.06648308  0.60271512  1.14432447
  1.310299   -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:40:24 2024]  Iteration number: 0 with current cost as 0.6797466680674026 and parameters 
[-3.17731954  1.96204632 -1.46466777 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552001 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.6 fold... 
[Mon Apr  1 17:41:12 2024]  Iteration number: 0 with current cost as 0.547154040434425 and parameters 
[-3.29054474  1.96429388 -1.28332359 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:41:53 2024]  Iteration number: 0 with current cost as 0.4297834541819764 and parameters 
[-3.28612468  1.91094455 -1.24857407 -0.11653103  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18552    -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 1.0 fold... 
[Mon Apr  1 17:42:35 2024]  Iteration number: 0 with current cost as 0.4729386501611117 and parameters 
[-3.23526001  1.94300107 -1.35600856 -0.11653101  0.55388708 -2.77010899
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Training complete taking 246.78911519050598 seconds. 
Discarding model... 

Training complete taking 6106.827312231064 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 0.8372876644134521 seconds. 
Saved predicted values as M_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (6.08886218427759,), 'R2_train': 0.16395338642889057, 'MAE_train': 1.877313273982122, 'MSE_test': 13.035755537542391, 'R2_test': -0.2995430504342931, 'MAE_test': 2.805007931795841}. 
Saved model results as M_HWE-CZ_results.json. 
