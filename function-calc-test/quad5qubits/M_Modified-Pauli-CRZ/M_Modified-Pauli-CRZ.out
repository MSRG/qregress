/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:35 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:15 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:03:10 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:04:19 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:05:05 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:05:52 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 279.9383108615875 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:56 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:41 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:08:51 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:09:38 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:10:19 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 267.74993801116943 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:11:28 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:12:13 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:13:27 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:12 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:14:52 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 272.705139875412 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:15:57 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:16:42 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:17:50 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:18:37 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:19:17 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 265.46978878974915 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:20:20 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:21:08 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:22:19 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:23:07 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:23:46 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 269.24284529685974 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:24:50 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:25:38 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:26:47 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:27:34 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:28:14 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 266.93294739723206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:29:17 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:30:05 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:13 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:00 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:32:40 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 267.4191083908081 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:33:44 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:34:31 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:35:40 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:25 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:37:07 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 271.009006023407 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:38:15 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:39:02 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:40:10 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:40:56 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:41:39 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 266.9085853099823 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:42:42 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:32 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:40 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:45:26 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:46:07 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 268.6208143234253 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:47:11 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:56 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:49:11 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:49:56 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:50:38 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 271.02069091796875 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:51:42 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:52:28 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:53:38 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:54:23 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:55:10 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 271.5972406864166 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:56:13 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:00 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:58:09 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:58:54 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:59:44 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 274.1984226703644 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:00:48 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:01:35 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:02:46 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:03:34 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:04:14 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 269.2094295024872 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:17 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:06:04 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:07:13 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:08:00 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:08:40 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 266.60273027420044 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:43 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:10:31 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:11:40 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:12:26 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:13:07 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 267.4240093231201 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:14:11 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:55 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:16:06 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:16:51 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:17:32 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 263.178587436676 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:18:37 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:19:23 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:20:39 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:21:25 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:06 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 273.9357080459595 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:23:10 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:23:56 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:25:06 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:25:51 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:26:33 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 266.59232449531555 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:27:36 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:28:24 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:29:37 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:30:22 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:31:04 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 271.3169083595276 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:32:08 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:32:54 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:34:04 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:34:50 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:35:31 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 267.65136337280273 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:36:35 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:37:20 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:38:29 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:16 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:39:56 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 266.04495120048523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:41:00 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:41:50 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:42:59 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:43:48 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:44:28 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 278.1038393974304 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:45:39 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:46:25 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:47:35 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:48:20 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:49:00 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 265.4812240600586 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:50:05 2024]  Iteration number: 0 with current cost as 0.29438880661658484 and parameters 
[-3.99694936  2.23743464 -2.12427899 -0.11653038  0.5538874  -2.77010865
  3.06858531  2.18960145  1.18552031 -1.06648276  0.6027151   1.14432413
  1.31029931 -1.87354648  0.72965015  2.88578387 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:03 2024]  Iteration number: 0 with current cost as 0.40005312869952536 and parameters 
[-2.51067535  2.23743464 -2.12427932 -0.11653087  0.55388724 -2.77010882
  3.06858498  2.18960161  1.18552022 -1.06648301  0.60271518  1.14432445
  1.31029899 -1.87354664  0.72965073  2.88578411 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:52:12 2024]  Iteration number: 0 with current cost as 0.29988609509249403 and parameters 
[-3.943871    2.2374356  -2.12427867 -0.11653006  0.55388804 -2.77010801
  3.06858594  2.18960241  1.18552191 -1.06648212  0.60271606  1.14432349
  1.31029995 -1.87354488  0.72964888  2.88578323 -0.54534431 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:52:58 2024]  Iteration number: 0 with current cost as 0.3197770841271673 and parameters 
[-2.52613687  2.2374346  -2.12427954 -0.116531    0.55388705 -2.77010894
  3.06858501  2.18960145  1.18552002 -1.06648312  0.6027151   1.14432442
  1.31029899 -1.87354677  0.72965071  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:53:39 2024]  Iteration number: 0 with current cost as 0.32566694687493647 and parameters 
[-2.44927931  2.23743464 -2.12427958 -0.11653101  0.55388708 -2.77010895
  3.06858496  2.18960147  1.18552    -1.06648308  0.6027151   1.14432443
  1.31029897 -1.87354678  0.72965077  2.88578417 -0.54534337 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 279.46840810775757 seconds. 
Discarding model... 

Training complete taking 6747.823565006256 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 0.9073753356933594 seconds. 
Saved predicted values as M_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (8.006882263910587,), 'R2_train': -0.09940520895518423, 'MAE_train': 2.0870079212610313, 'MSE_test': 18.82194298054329, 'R2_test': -0.8763718854340332, 'MAE_test': 3.118975146945906}. 
Saved model results as M_Modified-Pauli-CRZ_results.json. 
