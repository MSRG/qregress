/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:18:57 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:19:58 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:24:33 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:29:57 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:35:31 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:42:42 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1690.071380853653 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:47:58 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:52:19 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:57:33 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:42 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:09:28 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1601.307831287384 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:14:42 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:18:59 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:24:21 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:29:36 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:36:28 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1619.9530899524689 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:41:39 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:45:59 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:51:14 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:56:37 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:03:27 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1622.3570833206177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:08:42 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:13:09 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:18:27 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:23:39 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:30:34 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1629.2350871562958 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:35:53 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:40:17 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:45:32 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:50:44 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:57:38 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1624.0824582576752 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:02:58 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:07:22 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:12:42 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:17:59 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:24:46 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1629.8775758743286 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:30:07 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:34:38 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:39:52 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:45:18 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:52:11 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1639.5638501644135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:57:28 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:01:59 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:07:28 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:13:05 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:20:14 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1704.5343744754791 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:25:51 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:30:29 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:35:59 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:41:36 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:49:00 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1700.3695178031921 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:54:10 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:58:26 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:03:35 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:08:47 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:15:34 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1593.9228234291077 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:20:44 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:25:03 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:30:12 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:35:22 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:42:10 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1600.530196905136 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:47:25 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:51:48 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:57:01 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:02:10 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:08:51 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1598.0683777332306 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:14:03 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:18:27 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:23:42 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:28:55 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:35:40 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1600.9963352680206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:40:43 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:45:01 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:50:12 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:55:24 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:02:12 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1598.483115196228 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 23:07:21 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:11:35 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:16:46 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:22:06 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:28:55 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1606.0782651901245 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:34:11 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:38:31 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:43:37 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:48:49 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:55:36 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1599.2794511318207 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 00:00:47 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:05:07 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:10:14 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:15:17 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:22:04 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1590.4714906215668 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 00:27:17 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:31:36 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:36:47 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:41:54 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:48:31 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1580.061930656433 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 00:53:38 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:57:55 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 01:03:10 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 01:08:22 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 01:15:02 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1589.5797715187073 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 01:20:07 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 01:24:29 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 01:29:47 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 01:35:03 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 01:41:49 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1610.7383699417114 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 01:46:56 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 01:51:11 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 01:56:22 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:01:34 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 02:08:27 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1598.5321872234344 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 02:13:40 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 02:18:05 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:23:40 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:29:08 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 02:36:37 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1706.1797893047333 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 02:42:05 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 02:46:40 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:52:14 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:57:52 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 03:05:05 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1719.8106245994568 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 03:10:46 2024]  Iteration number: 0 with current cost as 0.14716549067358756 and parameters 
[-3.10379635  2.79888525 -1.88752869 -0.116531    0.55388709 -2.77010896
  3.06858503  2.18960148  1.18552002 -1.06648307  0.97256192  1.14432447
  1.310299   -1.87354677  0.7296508   2.88578419 -0.54534329 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 03:15:44 2024]  Iteration number: 0 with current cost as 0.2097559811335053 and parameters 
[-3.33390783  3.71477671 -1.48155196 -0.11653099  0.55388716 -2.77010889
  3.0685851   2.18960153  1.18552006 -1.06648305  1.58487382  1.14432449
  1.31029899 -1.87354672  0.7296508   2.88578423 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 03:21:41 2024]  Iteration number: 0 with current cost as 0.16729369222416388 and parameters 
[-3.04473558  2.56548599 -1.99347459 -0.11653102  0.55388708 -2.77010896
  3.06858499  2.18960147  1.18552    -1.06648308  0.83743413  1.14432444
  1.31029899 -1.87354679  0.7296508   2.88578418 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 03:27:21 2024]  Iteration number: 0 with current cost as 0.09275960918097917 and parameters 
[-2.95923356  3.41236478 -1.52605552 -0.11653095  0.55388708 -2.77010893
  3.06858506  2.18960149  1.18552006 -1.06648308  1.28520303  1.14432445
  1.31029899 -1.87354672  0.72965073  2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 03:34:42 2024]  Iteration number: 0 with current cost as 0.08796482496813622 and parameters 
[-2.7808872   3.45961996 -1.43355988 -0.11653099  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648312  1.35849301  1.14432441
  1.31029902 -1.87354668  0.72965076  2.88578415 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1770.7655084133148 seconds. 
Discarding model... 

Training complete taking 40824.85161089897 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.0961129665374756 seconds. 
Saved predicted values as M-A2-CZ_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (1.3213418441323803,), 'R2_train': 0.8185698180180198, 'MAE_train': 0.7112235910228493, 'MSE_test': 6.8679284506476765, 'R2_test': 0.31533169188275556, 'MAE_test': 1.5326737088299107}. 
Saved model results as M-A2-CZ_Modified-Pauli-CRX_results.json. 
