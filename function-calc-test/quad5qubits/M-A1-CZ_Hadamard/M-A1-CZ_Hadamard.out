/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/home/gjones/scratch/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_train.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /home/gjones/scratch/quad5qubits/quadratic_test.bin... 
Successfully loaded /home/gjones/scratch/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /home/gjones/scratch/quad5qubits/quadratic_train.bin 
 at time Thu Mar 28 03:24:10 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:24:18 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:24:29 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:24:43 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:24:56 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:25:08 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.491947889328 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 03:25:23 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:25:34 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:25:48 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:26:01 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:26:12 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 64.68807482719421 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 03:26:28 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:26:39 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:26:52 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:27:05 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:27:17 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 64.66310358047485 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 03:27:32 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:27:44 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:27:57 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:28:10 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:28:22 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 64.70306777954102 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 03:28:37 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:28:48 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:29:02 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:29:15 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:29:27 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.06408500671387 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:29:42 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:29:53 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:30:08 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:30:21 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:30:33 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.88775038719177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 03:30:48 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:30:59 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:31:13 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:31:26 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:31:37 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 64.919926404953 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 03:31:53 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:32:04 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:32:18 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:32:31 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:32:42 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 64.8746190071106 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 03:32:58 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:33:09 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:33:23 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:33:36 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:33:47 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.1343674659729 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 03:34:03 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:34:14 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:34:28 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:34:41 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:34:53 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.10192155838013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:35:08 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:35:19 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:35:33 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:35:46 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:35:58 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.26967358589172 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 03:36:13 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:36:25 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:36:38 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:36:52 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:37:03 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.53877258300781 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 03:37:19 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:37:30 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:37:44 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:37:57 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:38:09 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.3221230506897 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 03:38:24 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:38:35 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:38:49 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:39:02 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:39:14 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.05111980438232 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 03:39:29 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:39:41 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:39:54 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:40:07 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:40:19 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.14841365814209 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:40:34 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:40:46 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:40:59 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:41:13 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:41:24 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.07918429374695 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 03:41:39 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:41:51 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:42:04 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:42:18 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:42:29 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.17000675201416 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 03:42:44 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:42:56 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:43:10 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:43:23 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:43:35 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.41046524047852 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 03:43:50 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:44:01 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:44:15 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:44:28 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:44:40 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.42320942878723 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 03:44:55 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:45:07 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:45:20 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:45:34 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:45:45 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 65.29651737213135 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Thu Mar 28 03:46:01 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:46:12 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:46:26 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:46:40 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:46:51 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 66.34014439582825 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Thu Mar 28 03:47:07 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:47:20 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:47:34 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:47:48 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:48:00 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 69.18277359008789 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Thu Mar 28 03:48:17 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:48:29 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:48:43 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:48:57 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:49:10 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 69.2812328338623 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Thu Mar 28 03:49:26 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:49:38 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:49:52 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:50:06 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:50:21 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 72.03144478797913 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Thu Mar 28 03:50:40 2024]  Iteration number: 0 with current cost as 0.35984134474609636 and parameters 
[-1.48312015  2.23743464 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.4 fold... 
[Thu Mar 28 03:50:52 2024]  Iteration number: 0 with current cost as 0.33447912387189255 and parameters 
[-1.60465709  2.23743479 -2.12427956 -0.11653103  0.55388708]. 
Working on 0.6 fold... 
[Thu Mar 28 03:51:05 2024]  Iteration number: 0 with current cost as 0.3773615000034777 and parameters 
[-1.54216875  2.23743471 -2.12427964 -0.11653103  0.55388708]. 
Working on 0.8 fold... 
[Thu Mar 28 03:51:19 2024]  Iteration number: 0 with current cost as 0.34209971599227773 and parameters 
[-1.35639587  2.23743464 -2.12427964 -0.11653103  0.55388716]. 
Working on 1.0 fold... 
[Thu Mar 28 03:51:30 2024]  Iteration number: 0 with current cost as 0.33630576858816885 and parameters 
[-2.5667322   2.23743465 -2.12427962 -0.11653101  0.5538871 ]. 
Training complete taking 68.03735780715942 seconds. 
Discarding model... 

Training complete taking 1648.1122801303864 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 0.95068359375 seconds. 
Saved predicted values as M-A1-CZ_Hadamard_predicted_values.csv
Model scores: {'MSE_train': (7.548475749204191,), 'R2_train': -0.03646254369847535, 'MAE_train': 2.375206108765073, 'MSE_test': 9.413170379628049, 'R2_test': 0.06159484855560582, 'MAE_test': 2.7519990874101716}. 
Saved model results as M-A1-CZ_Hadamard_results.json. 
