/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:11 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:44:38 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 15:52:28 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 15:58:53 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 16:05:33 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 16:12:39 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 16:24:58 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2597.092708826065 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:27:55 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 16:35:52 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 16:42:18 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 16:49:00 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 16:56:06 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 17:08:27 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2616.062009572983 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:11:30 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 17:19:00 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 17:25:27 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 17:32:16 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 17:39:18 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 17:51:48 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2588.7626514434814 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:54:39 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 18:02:08 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 18:08:28 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 18:15:29 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 18:22:27 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 18:34:53 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2588.5127744674683 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:37:47 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 18:45:19 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 18:52:01 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 18:58:39 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 19:05:52 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 19:18:32 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2614.968096256256 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:21:22 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 19:28:52 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 19:35:13 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 19:41:47 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 19:48:52 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 20:01:16 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2563.2152605056763 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:04:06 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 20:11:40 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 20:18:16 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 20:24:53 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 20:32:01 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 20:44:20 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2583.798319339752 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:47:10 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 20:54:36 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 21:00:56 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 21:07:32 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 21:14:40 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 21:27:08 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2570.2025310993195 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:30:00 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 21:37:41 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 21:44:04 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 21:50:38 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 21:57:35 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 22:10:01 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2574.2317595481873 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:12:55 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 22:20:23 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 22:26:44 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 22:33:19 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 22:40:19 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 22:52:37 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2553.8889303207397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 22:55:28 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 23:03:05 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 23:09:47 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 23:16:29 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Mon Apr  1 23:23:29 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Mon Apr  1 23:35:53 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2595.9343631267548 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:38:44 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Mon Apr  1 23:46:09 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Mon Apr  1 23:52:33 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Mon Apr  1 23:59:08 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 00:06:11 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 00:18:27 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2557.249960422516 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 00:21:24 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 00:28:52 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 00:35:12 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 00:41:47 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 00:48:58 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 01:01:32 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2581.0923159122467 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 01:04:23 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 01:11:53 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 01:18:18 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 01:24:58 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 01:32:00 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 01:44:21 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2570.5022699832916 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 01:47:13 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 01:54:47 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 02:01:10 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 02:07:43 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 02:14:51 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 02:27:11 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2569.229656934738 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 02:30:03 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 02:37:35 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 02:44:02 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 02:50:43 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 02:57:51 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 03:10:03 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2570.9562129974365 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 03:12:53 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 03:20:24 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 03:26:47 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 03:33:22 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 03:40:30 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 03:52:57 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2575.416722536087 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 03:55:49 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 04:03:16 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 04:09:59 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 04:16:50 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 04:24:18 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 04:36:37 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2620.528695344925 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 04:39:29 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 04:46:57 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 04:53:18 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 04:59:54 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 05:06:59 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 05:19:18 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2560.3713676929474 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 05:22:10 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 05:29:39 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 05:35:59 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 05:42:32 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 05:49:34 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 06:01:55 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2556.523349046707 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 06:04:45 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 06:12:14 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 06:18:37 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 06:25:11 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 06:32:09 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 06:44:29 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2556.212890625 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 06:47:23 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 06:54:54 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 07:01:15 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 07:07:51 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 07:15:13 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 07:27:28 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2577.065131664276 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 07:30:19 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 07:37:49 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 07:44:13 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 07:50:47 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 07:57:52 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 08:10:15 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2567.4529836177826 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 08:13:07 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 08:20:35 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 08:27:01 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 08:33:38 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 08:40:41 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 08:53:32 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2597.048737049103 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 08:56:24 2024]  Iteration number: 0 with current cost as 0.17136194594785575 and parameters 
[-2.50195986  2.41106806 -1.95213937 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.12817006  1.14432446
  0.70662215 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512663  2.83077106 -1.2645671  -0.25136105]. 
Working on 0.4 fold... 
[Tue Apr  2 09:03:51 2024]  Iteration number: 0 with current cost as 0.18144744451945288 and parameters 
[-2.55254324  2.38630627 -1.96830858 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.18828055  1.14432445
  0.78873544 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 0.6 fold... 
[Tue Apr  2 09:10:10 2024]  Iteration number: 0 with current cost as 0.17595772285617844 and parameters 
[-2.47448475  2.43271512 -1.94315948 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648309  0.10043515  1.14432445
  0.66609449 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
Working on 0.8 fold... 
[Tue Apr  2 09:16:45 2024]  Iteration number: 0 with current cost as 0.14522568274533593 and parameters 
[-2.48717428  2.43320963 -1.95380763 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309  0.11576115  1.14432445
  0.67978259 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136104]. 
Working on 1.0 fold... 
[Tue Apr  2 09:23:47 2024]  Iteration number: 0 with current cost as 0.17206543484898618 and parameters 
[-2.55511595  2.4272544  -1.97696739 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.20388032  1.14432445
  0.79481533 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.72897369  1.60512664  2.83077106 -1.2645671  -0.25136104]. 
[Tue Apr  2 09:36:06 2024]  Iteration number: 50 with current cost as 0.04713500265056419 and parameters 
[-3.19174534e+00  3.98703060e+00  3.38557541e-03 -1.16530646e-01
  5.53887957e-01 -2.77010849e+00  3.06858514e+00  2.18960260e+00
  1.18552068e+00 -1.06648191e+00  2.85083389e+00  1.14432641e+00
 -7.51753839e-02 -1.87354575e+00  7.29651513e-01  2.88578504e+00
 -5.45342480e-01 -4.75225424e-01 -2.02654203e+00  7.28974027e-01
  1.60512640e+00  2.83077062e+00 -1.26456733e+00 -2.51361087e-01]. 
Training complete taking 2552.8747279644012 seconds. 
Discarding model... 

Training complete taking 64459.19622015953 total seconds. 
Now scoring model... 
Scoring complete taking 2.125783681869507 seconds. 
Saved predicted values as A1-A1-CZ_Full-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (1.0413412047924715,), 'R2_train': 0.857016013585123, 'MAE_train': 0.7759199340638876, 'MSE_test': 1.9604793238739167, 'R2_test': 0.8045585257008595, 'MAE_test': 0.8393122568067598}. 
Saved model results as A1-A1-CZ_Full-Pauli-CRX_results.json. 
