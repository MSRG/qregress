/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:46:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:46:44 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 15:50:21 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 15:53:43 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 15:56:53 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 16:00:22 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1048.1212179660797 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:04:12 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:32 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:55 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:07 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:36 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1038.2148892879486 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:29 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 16:24:51 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 16:28:11 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 16:31:21 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 16:34:48 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1031.5815253257751 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:38:42 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 16:42:02 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 16:45:29 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 16:48:37 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 16:52:04 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1037.2926700115204 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:57 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:22 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 17:02:51 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 17:06:15 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 17:09:42 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1054.735434770584 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:13:32 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 17:16:56 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 17:20:31 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 17:24:21 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:53 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1093.1483557224274 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:31:47 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 17:35:06 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 17:38:41 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 17:41:54 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 17:45:26 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1067.2047324180603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:49:33 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 17:52:56 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 17:56:18 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 17:59:27 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 18:03:01 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1048.7758383750916 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:07:01 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 18:10:43 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 18:14:08 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 18:17:20 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 18:20:48 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1074.243412733078 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:25:10 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:43 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 18:32:07 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 18:35:27 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 18:38:57 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1076.0902779102325 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:42:53 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 18:46:15 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 18:49:37 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 18:52:48 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 18:56:14 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1032.0335810184479 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:00:04 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 19:03:28 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 19:06:47 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 19:10:00 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 19:13:45 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1051.5688762664795 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:17:35 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 19:20:57 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 19:24:20 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 19:27:30 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 19:30:57 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1030.6567537784576 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:34:46 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 19:38:09 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 19:41:31 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 19:44:42 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 19:48:10 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1033.5277218818665 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:52:01 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 19:55:24 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 19:58:43 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 20:01:55 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 20:05:24 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1033.8332493305206 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:09:13 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 20:12:37 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 20:16:00 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 20:19:10 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 20:22:41 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1036.5551872253418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:26:32 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 20:29:53 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 20:33:15 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 20:36:26 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 20:39:53 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1034.349286556244 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:43:44 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 20:47:06 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 20:50:28 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 20:53:39 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 20:57:06 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1031.3692061901093 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:00:57 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 21:04:18 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 21:07:41 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 21:10:52 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 21:14:30 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1042.7381720542908 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:18:18 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 21:21:40 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 21:25:04 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 21:28:14 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 21:31:42 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1032.1441683769226 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:35:32 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 21:38:53 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 21:42:16 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 21:45:27 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 21:48:53 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1032.8435819149017 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:52:43 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 21:56:07 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 21:59:28 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 22:02:39 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 22:06:08 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1034.188080072403 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 22:09:58 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 22:13:20 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 22:16:42 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 22:19:52 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 22:23:21 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1033.052314043045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:27:12 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 22:30:35 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 22:33:57 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 22:37:09 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 22:40:37 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1042.2557721138 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:44:34 2024]  Iteration number: 0 with current cost as 0.36538067690997067 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.21181445  0.57798675 -2.84388341
  3.01377635  2.05770871  1.35512021 -1.06714946  0.65565102  1.16006634
  1.42994012 -1.80264196  0.58220398]. 
Working on 0.4 fold... 
[Mon Apr  1 22:47:56 2024]  Iteration number: 0 with current cost as 0.3655775735248199 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.19188442  0.57649898 -2.82281164
  3.03785211  2.07189076  1.30553809 -1.05539786  0.65669946  1.17465926
  1.41583364 -1.81289785  0.59280229]. 
Working on 0.6 fold... 
[Mon Apr  1 22:51:20 2024]  Iteration number: 0 with current cost as 0.3856979941920881 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.21275898  0.58226623 -2.83820008
  3.01263642  2.06064691  1.35541209 -1.05920352  0.65868165  1.17065937
  1.44157611 -1.7933663   0.57638266]. 
Working on 0.8 fold... 
[Mon Apr  1 22:54:31 2024]  Iteration number: 0 with current cost as 0.3573271378734533 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.22400659  0.58609752 -2.8453426
  3.01124507  2.04961838  1.36409145 -1.06288226  0.67011291  1.16976785
  1.44651455 -1.79286019  0.56163068]. 
Working on 1.0 fold... 
[Mon Apr  1 22:58:08 2024]  Iteration number: 0 with current cost as 0.3457975192867604 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.2103564   0.58281225 -2.83450829
  3.0456425   2.06354351  1.29686157 -1.04815626  0.67234254  1.18834067
  1.41815971 -1.81554071  0.57553915]. 
Training complete taking 1045.1218180656433 seconds. 
Discarding model... 

Training complete taking 26115.64778161049 total seconds. 
Now scoring model... 
Scoring complete taking 0.9034292697906494 seconds. 
Saved predicted values as A2-A2-CNOT_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (2.117157257602576,), 'R2_train': 0.7092983710180434, 'MAE_train': 1.0552837994337019, 'MSE_test': 2.9978130354066423, 'R2_test': 0.7011460451644446, 'MAE_test': 1.3294412016933563}. 
Saved model results as A2-A2-CNOT_HWE-CNOT_results.json. 
