/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:20 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:44:33 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:48:27 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:54:25 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 15:57:52 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 16:00:58 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1216.7818472385406 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:04:51 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:23 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:14:22 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 16:17:49 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 16:20:53 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1195.3286073207855 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:24:45 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:28:17 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:34:14 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 16:37:38 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 16:40:44 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1193.4564571380615 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:44:38 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:48:11 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:54:07 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:33 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 17:00:42 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1197.6985912322998 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:04:36 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:08:08 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:14:10 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:33 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 17:20:40 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1196.7172272205353 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:24:33 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:28:03 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:34:03 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 17:37:36 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 17:40:40 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1198.0778737068176 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:44:31 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:48:02 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:54:04 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 17:57:28 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 18:00:33 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1194.9645555019379 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:04:26 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:07:58 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:13:52 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 18:17:16 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 18:20:37 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1202.043479681015 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:24:28 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:00 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:33:55 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 18:37:19 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 18:40:39 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1215.4564554691315 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:44:43 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:48:15 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:54:15 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 18:57:39 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 19:00:42 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1189.4152159690857 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:04:33 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:08:06 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:14:13 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 19:17:40 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 19:20:44 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1204.926501750946 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:24:41 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:28:12 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:34:08 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 19:37:34 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 19:40:40 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1193.5931689739227 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:44:31 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:48:02 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:54:04 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 19:57:30 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 20:00:41 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1200.9707226753235 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:04:32 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:08:02 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:13:52 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 20:17:16 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 20:20:22 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1180.3408432006836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:24:14 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:27:43 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:33:54 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 20:37:30 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 20:40:52 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1230.4058010578156 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:44:43 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:48:32 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:54:28 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 20:57:55 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 21:01:02 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1208.3247427940369 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:04:51 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:08:22 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:14:26 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 21:17:55 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 21:21:00 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1200.0873143672943 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:24:51 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:28:39 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:34:36 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 21:38:01 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 21:41:07 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1206.0672585964203 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:44:57 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:48:47 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:54:41 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 21:58:26 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 22:01:31 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1224.8094766139984 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:05:22 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:08:56 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:15:00 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 22:18:24 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 22:21:41 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1213.0722963809967 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 22:25:35 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:29:26 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:35:31 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 22:38:54 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 22:42:02 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1220.2852470874786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 22:45:56 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:49:30 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:55:27 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 22:58:51 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 23:01:57 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1192.1175048351288 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 23:05:48 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:09:22 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:15:32 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 23:18:56 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 23:22:01 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1226.3094370365143 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 23:26:15 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:29:44 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:35:40 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 23:39:05 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Mon Apr  1 23:42:10 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1189.052549123764 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 23:46:03 2024]  Iteration number: 0 with current cost as 0.4198505580007338 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.03785292  0.56347511 -2.6623779
  2.96021451  2.31849218  1.29894249 -1.07389895  0.69075876  1.16284992
  1.43419185 -1.78091174  0.6457366 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:49:34 2024]  Iteration number: 0 with current cost as 0.38275072974388114 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04226954  0.56179907 -2.67023176
  2.97256393  2.31229196  1.28118368 -1.08264416  0.67515525  1.14735566
  1.43494518 -1.77514679  0.6638481 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:55:28 2024]  Iteration number: 0 with current cost as 0.4282372841770953 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.0393645   0.56205664 -2.66640709
  2.951852    2.31141633  1.31738874 -1.08130093  0.67907785  1.15021262
  1.43583181 -1.7780842   0.65035854]. 
Working on 0.8 fold... 
[Mon Apr  1 23:58:53 2024]  Iteration number: 0 with current cost as 0.39136022332411874 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.04265878  0.56407977 -2.66706867
  2.94569571  2.31640774  1.32515929 -1.0834826   0.67824724  1.14730462
  1.41449157 -1.79405672  0.66475401]. 
Working on 1.0 fold... 
[Tue Apr  2 00:01:59 2024]  Iteration number: 0 with current cost as 0.3402301393013857 and parameters 
[-2.90318344  2.23743464 -2.12427963 -0.04415542  0.55878545 -2.67723346
  2.97561448  2.30788962  1.27843182 -1.09092298  0.65304559  1.13039336
  1.39402191 -1.80851553  0.68164846]. 
Training complete taking 1188.7326505184174 seconds. 
Discarding model... 

Training complete taking 30079.037557840347 total seconds. 
Now scoring model... 
Scoring complete taking 0.9543254375457764 seconds. 
Saved predicted values as A2-A2-CZ_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (3.091782137206793,), 'R2_train': 0.5754750382779328, 'MAE_train': 1.4582180007101855, 'MSE_test': 4.813517356663742, 'R2_test': 0.5201372861755484, 'MAE_test': 1.8403756545255905}. 
Saved model results as A2-A2-CZ_HWE-CNOT_results.json. 
