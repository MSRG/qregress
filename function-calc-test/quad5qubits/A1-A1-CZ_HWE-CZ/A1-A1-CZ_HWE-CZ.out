/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:02:33 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:44 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:04:14 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:05:38 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:07:07 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:08:31 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 420.83287715911865 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:09:44 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:11:13 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:12:37 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:05 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:15:29 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 419.02154898643494 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:16:44 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:18:12 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:19:41 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:21:14 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:22:37 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 428.86012959480286 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:23:53 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:25:28 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:26:56 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:28:26 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:29:58 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 443.226948261261 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:31:16 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:32:48 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:34:18 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:35:49 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:37:16 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 439.71201729774475 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:38:34 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:40:05 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:38 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:43:15 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:44:45 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 445.7112829685211 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:46:01 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:33 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:48:58 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:50:32 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:51:57 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 432.85094714164734 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:53:15 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:54:47 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:56:11 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:47 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:59:14 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 436.56858110427856 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:00:31 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:02:06 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:03:34 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:05:12 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:06:53 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 461.4602859020233 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:08:12 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:47 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:11:13 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:12:47 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:14 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 436.4190547466278 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:27 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:02 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:31 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:20:04 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:21:33 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 445.85414361953735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:22:55 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:24:33 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:26:00 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:27:30 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:29:01 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 443.0936348438263 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:30:17 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:31:53 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:33:20 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:34:52 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:36:17 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 434.51717019081116 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:37:31 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:39:01 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:40:25 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:41:53 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:43:18 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 423.00570273399353 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:44:34 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:46:05 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:47:32 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:49:01 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:50:24 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 423.5681002140045 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:51:37 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:53:07 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:54:33 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 17:56:04 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:57:28 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 422.5490448474884 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:58:40 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:00:09 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:01:37 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 18:03:09 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:04:33 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 430.09384274482727 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:05:51 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:07:20 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:08:43 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 18:10:12 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:11:37 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 422.74083971977234 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:12:54 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:14:23 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:15:46 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 18:17:15 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:18:38 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 419.7157130241394 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:19:54 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:21:24 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:22:57 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 18:24:25 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:25:48 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 429.6377396583557 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:27:03 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:36 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:30:08 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 18:31:41 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:33:05 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 440.05605483055115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:34:23 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:35:52 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:37:22 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 18:38:58 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:40:24 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 434.52756929397583 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:41:37 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:43:07 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:44:31 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 18:46:02 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:47:26 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 422.3864691257477 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:48:39 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:50:08 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:51:35 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 18:53:05 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:54:31 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 425.027948141098 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:55:44 2024]  Iteration number: 0 with current cost as 0.3118657665183502 and parameters 
[-3.37640901  2.1461213  -1.28726025 -0.11653103  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:57:14 2024]  Iteration number: 0 with current cost as 0.33944364399629395 and parameters 
[-3.32601641  2.16384604 -1.38267592 -0.11653104  0.55388707 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432444
  1.31029899 -1.87354682  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:58:37 2024]  Iteration number: 0 with current cost as 0.30079450550608655 and parameters 
[-3.38764137  2.12255735 -1.2505893  -0.11653104  0.55388706 -2.770109
  3.06858495  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029897 -1.8735468   0.72965077]. 
Working on 0.8 fold... 
[Mon Apr  1 19:00:05 2024]  Iteration number: 0 with current cost as 0.2708492732304676 and parameters 
[-3.3970287   2.13949358 -1.24870873 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:01:32 2024]  Iteration number: 0 with current cost as 0.31574966703685964 and parameters 
[-3.31143011  2.15186791 -1.39685809 -0.11653103  0.55388708 -2.77010898
  3.06858497  2.18960145  1.18551998 -1.06648309  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 421.3424389362335 seconds. 
Discarding model... 

Training complete taking 10802.781497478485 total seconds. 
Now scoring model... 
Scoring complete taking 0.825782299041748 seconds. 
Saved predicted values as A1-A1-CZ_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (3.3700592296121883,), 'R2_train': 0.5372654986794358, 'MAE_train': 1.2898154254735616, 'MSE_test': 6.438837104881509, 'R2_test': 0.358108090595204, 'MAE_test': 1.9311417195509724}. 
Saved model results as A1-A1-CZ_HWE-CZ_results.json. 
