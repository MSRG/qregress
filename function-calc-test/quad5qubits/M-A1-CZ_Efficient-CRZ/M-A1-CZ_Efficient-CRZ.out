/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:07 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:46:45 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:50:11 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:54:23 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 15:57:02 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:59:43 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 1047.4925372600555 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:04:13 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:41 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:53 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:25 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:04 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 1036.1908400058746 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:21 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:24:35 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:28:24 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 16:31:01 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:31 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 986.7859244346619 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:50 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:41:05 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:58 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 16:47:23 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:49:50 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 982.3314671516418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:54:09 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:29 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:01:23 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 17:03:53 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:06:31 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 998.0123496055603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:10:51 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:09 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:01 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 17:20:29 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:54 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 983.1716747283936 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:27:14 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:30:28 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:34:25 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 17:36:56 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:39:35 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 997.3890380859375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:43:50 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:47:10 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:51:06 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 17:53:43 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:56:13 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 1001.0084207057953 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:00:32 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:03:47 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:07:45 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 18:10:16 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:12:49 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 992.2675437927246 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:58 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:20:07 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:24:02 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 18:26:35 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:29:00 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 975.6743593215942 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:33:30 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:36:37 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:40:30 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 18:42:59 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:45:23 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 983.3518080711365 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:49:38 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:52:47 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:56:43 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 18:59:11 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:01:57 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 995.8861541748047 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:06:16 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:09:33 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:13:30 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 19:16:01 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:18:32 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 989.4169855117798 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:22:42 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:25:50 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:29:36 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 19:32:09 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:34:38 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 968.4990439414978 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:38:57 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:42:12 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:46:06 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 19:48:33 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:51:14 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 1001.7248589992523 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:55:41 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:58:51 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:02:48 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 20:05:24 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:07:54 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 993.1799488067627 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:12:04 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:15:22 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:19:24 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 20:21:54 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:24:29 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 994.0681574344635 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:28:40 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:31:58 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:35:55 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 20:38:23 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:40:51 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 983.4140436649323 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:45:05 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:48:12 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:52:05 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 20:54:44 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:57:18 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 988.0865006446838 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:01:31 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:04:38 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:08:31 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 21:11:00 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:13:29 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 965.6926424503326 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:17:44 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:21:04 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:24:58 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 21:27:28 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:29:57 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 991.0240421295166 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:34:10 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:37:25 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:41:15 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 21:43:50 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:46:21 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 983.7496900558472 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:50:34 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:53:46 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:57:39 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 22:00:08 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:02:42 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 980.4466834068298 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:06:53 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:10:03 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:13:57 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 22:16:23 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:18:48 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 967.5127489566803 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:23:04 2024]  Iteration number: 0 with current cost as 0.1803940779280078 and parameters 
[-3.7774906   2.23743452 -2.12427964 -0.11653108  0.55388697 -2.77010909
  3.06858487  2.18960134  1.18551998 -1.0664832   0.60271499  1.14432439
  1.31029893 -1.8735468 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:26:14 2024]  Iteration number: 0 with current cost as 0.2024400785497275 and parameters 
[-3.79579123  2.23743474 -2.12427953 -0.11653103  0.55388718 -2.77010908
  3.06858488  2.18960145  1.18552009 -1.06648319  0.60271521  1.14432445
  1.31029909 -1.8735468 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:30:08 2024]  Iteration number: 0 with current cost as 0.185069722485929 and parameters 
[-3.74431289  2.23743477 -2.1242795  -0.11653103  0.55388715 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029905 -1.87354673]. 
Working on 0.8 fold... 
[Mon Apr  1 22:32:37 2024]  Iteration number: 0 with current cost as 0.1792224406704768 and parameters 
[-2.87751903  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010905
  3.0685849   2.18960141  1.18551998 -1.06648316  0.60271502  1.14432445
  1.31029899 -1.8735468 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:35:09 2024]  Iteration number: 0 with current cost as 0.19754162030443595 and parameters 
[-2.81429672  2.23743464 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858496  2.18960145  1.18551999 -1.06648308  0.60271509  1.14432445
  1.31029899 -1.8735468 ]. 
Training complete taking 983.7744388580322 seconds. 
Discarding model... 

Training complete taking 24770.15268969536 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 2.2904562950134277 seconds. 
Saved predicted values as M-A1-CZ_Efficient-CRZ_predicted_values.csv
Model scores: {'MSE_train': (4.623524775367714,), 'R2_train': 0.3651552434230503, 'MAE_train': 1.51778815906196, 'MSE_test': 11.9816391317684, 'R2_test': -0.19445749206161556, 'MAE_test': 2.4706209575619313}. 
Saved model results as M-A1-CZ_Efficient-CRZ_results.json. 
