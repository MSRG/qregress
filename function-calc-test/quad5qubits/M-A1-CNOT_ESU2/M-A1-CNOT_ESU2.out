/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:18 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:45:04 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 15:47:08 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 15:49:13 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:51:22 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 15:53:13 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 601.2596714496613 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:55:05 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 15:57:15 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 15:59:24 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:01:32 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:03:23 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 608.097437620163 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:05:14 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:19 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:24 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:31 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:13:21 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 598.5751497745514 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:15:15 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:17:29 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:19:36 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:21:45 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:23:35 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 611.9962208271027 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:25:26 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:27:32 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:29:36 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:31:43 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:34 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 600.6268572807312 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:35:26 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:32 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:39:38 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:41:46 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:43:35 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 600.2268223762512 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:27 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:36 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:49:41 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:51:49 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:53:40 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 605.0182983875275 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:32 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:41 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:49 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:58 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:03:50 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 609.5665934085846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:42 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:07:52 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:10:00 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:12:10 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:02 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 613.8329203128815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:53 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:59 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:20:07 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:22:15 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:24:10 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 607.3039979934692 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:26:03 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:28:11 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:30:21 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:32:28 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:19 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 609.6672682762146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:36:11 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:38:19 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:40:25 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:42:35 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:44:30 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 610.3899838924408 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:46:24 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:48:33 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:50:42 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:52:49 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:54:43 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 614.3647012710571 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:56:36 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:58:41 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:48 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:02:53 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:04:40 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 595.972934961319 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:06:32 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:08:41 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:10:48 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:12:58 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:14:49 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 608.3060739040375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:41 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:18:49 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:20:58 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:23:04 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:24:56 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 608.261892080307 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:26:48 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:56 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:31:05 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:33:10 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:35:03 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 604.1438591480255 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:36:52 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:38:57 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:41:06 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:43:13 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:45:04 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 603.5630443096161 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:46:56 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:49:05 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:51:13 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:53:21 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:55:14 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 611.650454044342 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:57:09 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:59:16 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:01:24 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:03:32 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:05:23 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 605.0366322994232 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:07:14 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:09:20 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:11:28 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:13:33 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:15:22 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 600.2995135784149 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:17:13 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:19:22 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:21:27 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:23:35 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:25:25 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 602.1526062488556 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:27:16 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:29:24 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:31:33 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:33:40 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:35:31 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 608.4681403636932 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:37:25 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:39:33 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:41:38 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:43:45 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:45:37 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 604.1011710166931 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:47:29 2024]  Iteration number: 0 with current cost as 0.22301749393421846 and parameters 
[-2.57484037  2.23743461 -2.12427965 -0.11653103  0.55388706 -2.77010898
  3.06858497  2.18960144  1.18551998 -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:49:38 2024]  Iteration number: 0 with current cost as 0.21436227311239422 and parameters 
[-2.60044628  2.23743461 -2.12427965 -0.11653104  0.55388707 -2.77010898
  3.06858496  2.18960144  1.18551999 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:51:43 2024]  Iteration number: 0 with current cost as 0.20135896742673015 and parameters 
[-2.62273707  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010899
  3.06858497  2.18960143  1.18551998 -1.0664831 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:53:47 2024]  Iteration number: 0 with current cost as 0.160704643805321 and parameters 
[-2.76729022  2.23743463 -2.12427964 -0.11653103  0.55388708 -2.77010896
  3.06858499  2.18960145  1.18551999 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:55:40 2024]  Iteration number: 0 with current cost as 0.1666403164725875 and parameters 
[-2.74262599  2.23743462 -2.12427964 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308]. 
Training complete taking 604.1763803958893 seconds. 
Discarding model... 

Training complete taking 15147.059929609299 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 2.3615622520446777 seconds. 
Saved predicted values as M-A1-CNOT_ESU2_predicted_values.csv
Model scores: {'MSE_train': (4.252166231919906,), 'R2_train': 0.41614556694719407, 'MAE_train': 1.3738974872167815, 'MSE_test': 4.0032036274657905, 'R2_test': 0.60091799523518, 'MAE_test': 1.5418301001205685}. 
Saved model results as M-A1-CNOT_ESU2_results.json. 
