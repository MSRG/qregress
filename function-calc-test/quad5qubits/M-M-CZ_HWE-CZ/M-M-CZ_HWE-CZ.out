/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:59 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:14 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:03:36 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:04:49 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:06:10 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:07:32 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 403.30989837646484 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:08:56 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:10:17 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:33 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:12:54 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:14:15 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 399.69137740135193 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:15:37 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:16:58 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:18:12 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:19:37 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:20:58 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 402.9800181388855 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:22:19 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:23:41 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:24:55 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:26:16 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:38 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 399.4701325893402 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:59 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:30:19 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:34 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:55 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:34:16 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 398.4809875488281 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:35:38 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:00 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:38:14 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:39:36 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:40:58 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 402.2632169723511 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:42:19 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:42 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:56 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:46:17 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:47:39 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 400.61096358299255 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:49:00 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:50:21 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:37 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:58 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:19 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 400.04842472076416 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:41 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:02 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:58:16 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:59:37 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:00:59 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 400.02692556381226 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:02:20 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:03:42 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:04:57 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:06:19 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:07:41 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 401.79837441444397 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:02 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:10:23 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:11:40 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:02 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:23 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 402.4423189163208 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:49 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:10 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:24 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:19:46 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:21:07 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 404.51134514808655 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:22:29 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:23:51 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:25:05 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:26:26 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:27:48 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 400.4124767780304 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:29:09 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:30:30 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:31:45 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:33:07 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:34:28 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 401.21793484687805 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:35:50 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:37:12 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:38:25 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:47 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:41:08 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 399.16446685791016 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:42:30 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:43:53 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:45:07 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:46:28 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:47:50 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 401.64661264419556 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:49:11 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:50:41 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:52:00 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:53:20 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:54:44 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 414.404333114624 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:56:06 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:57:27 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:58:45 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:00:13 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:01:37 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 411.9434471130371 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:02:57 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:04:18 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:05:31 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:06:53 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:08:13 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 395.7586419582367 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:09:33 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:10:55 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:12:08 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:13:29 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:14:51 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 408.45149183273315 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:22 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:17:43 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:18:55 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:20:15 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:21:37 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 395.0421941280365 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:22:57 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:24:16 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:25:29 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:26:50 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:28:10 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 393.7953853607178 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:29:30 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:30:52 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:32:05 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:33:25 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:34:47 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 396.7673397064209 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:36:07 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:37:28 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:38:42 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:40:02 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:41:23 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 396.49556589126587 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:42:45 2024]  Iteration number: 0 with current cost as 0.21046892013997942 and parameters 
[-3.35904911  2.05288022 -1.24210835 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:44:05 2024]  Iteration number: 0 with current cost as 0.20894073928796847 and parameters 
[-3.36005615  2.05504426 -1.24217925 -0.11653102  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18552    -1.06648309  0.6027151   1.14432445
  1.31029897 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:45:18 2024]  Iteration number: 0 with current cost as 0.2155352627090334 and parameters 
[-3.36865298  2.07378903 -1.24299749 -0.11653103  0.55388707 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:46:40 2024]  Iteration number: 0 with current cost as 0.18921550863768594 and parameters 
[-3.36410546  2.06381222 -1.24251654 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:48:00 2024]  Iteration number: 0 with current cost as 0.19545071190069796 and parameters 
[-3.3791165   2.09729503 -1.24453614 -0.11653104  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.60271509  1.14432444
  1.31029899 -1.8735468   0.7296508 ]. 
Training complete taking 396.9123661518097 seconds. 
Discarding model... 

Training complete taking 10027.648788928986 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.0463521480560303 seconds. 
Saved predicted values as M-M-CZ_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (3.0872680327467448,), 'R2_train': 0.5760948588015233, 'MAE_train': 1.3144957754299718, 'MSE_test': 14.075701558567522, 'R2_test': -0.40321595382358066, 'MAE_test': 2.486165713585518}. 
Saved model results as M-M-CZ_HWE-CZ_results.json. 
