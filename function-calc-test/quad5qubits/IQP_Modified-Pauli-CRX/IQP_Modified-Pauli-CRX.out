/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:49 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:10 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:06:16 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:52 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:14:57 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:19:08 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1276.5512142181396 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:23:23 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:27:32 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:46 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:00 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:40:04 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1262.5761301517487 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:44:25 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:49:04 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:53:19 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:24 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:01:21 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1271.9426736831665 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:39 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:45 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:13:59 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:18:05 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:16 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1252.9907348155975 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:26:31 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:30:38 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:34:52 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:38:57 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:42:54 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1239.3312845230103 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:47:11 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:51:17 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:55:38 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:59:54 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:04:11 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1297.395302772522 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:08:55 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:13:01 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:17:15 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:21:21 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:25:21 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1247.6216475963593 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:29:36 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:33:44 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:38:27 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:42:45 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:46:48 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1292.136602640152 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:51:09 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:55:14 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:59:53 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:03:58 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:07:53 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1259.7061100006104 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:12:08 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:16:23 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:20:52 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:25:30 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:29:28 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1295.892944574356 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:33:44 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:37:48 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:42:06 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:46:14 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:50:08 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1238.8898606300354 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:54:23 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:58:27 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:03:00 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:07:04 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:10:58 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1261.9849479198456 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:15:25 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:19:30 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:23:47 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:27:51 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:31:56 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1245.1081938743591 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:36:09 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:40:13 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:44:33 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:48:41 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:52:39 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1243.1699512004852 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:56:53 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:00:55 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:05:17 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:09:21 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:13:19 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1250.2279510498047 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 21:17:42 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:21:47 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:26:23 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:30:28 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:34:34 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1287.6157643795013 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 21:39:10 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:43:30 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:47:45 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:51:53 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:56:15 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1280.5151736736298 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 22:00:32 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:04:37 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:08:51 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:12:56 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:16:53 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1233.666251897812 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:21:06 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:25:12 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:29:26 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:33:53 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:38:10 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1302.7826800346375 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:42:49 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:47:06 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:51:19 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:55:25 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:59:19 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1246.9592907428741 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 23:03:35 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:07:40 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:11:56 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:16:08 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:20:21 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1290.3462691307068 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:25:23 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:29:30 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:33:45 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:37:50 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:41:50 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1265.1244299411774 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 23:46:10 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:50:15 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:54:30 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:58:34 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:02:29 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1231.4907336235046 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 00:06:42 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:10:47 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:15:01 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:19:05 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:23:00 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1249.1288290023804 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 00:27:31 2024]  Iteration number: 0 with current cost as 0.4755849032281403 and parameters 
[-2.97189735  2.41829727 -2.1199154  -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960144  1.18551998 -1.06648308  0.31421135  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:31:45 2024]  Iteration number: 0 with current cost as 0.43897320162339093 and parameters 
[-2.94489261  2.39691702 -2.12059623 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.33961889  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:36:04 2024]  Iteration number: 0 with current cost as 0.49471031571319346 and parameters 
[-2.91213085  2.41805186 -2.12407404 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.27470112  1.14432445
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:40:08 2024]  Iteration number: 0 with current cost as 0.46694591509450484 and parameters 
[-2.91963288  2.41784923 -2.12747975 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.06648308  0.25162072  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:44:05 2024]  Iteration number: 0 with current cost as 0.41870022431407605 and parameters 
[-2.89250873  2.39011768 -2.12878137 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.29120975  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 1249.092875957489 seconds. 
Discarding model... 

Training complete taking 31572.24927020073 total seconds. 
Now scoring model... 
Scoring complete taking 0.9997413158416748 seconds. 
Saved predicted values as IQP_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (4.064063792394711,), 'R2_train': 0.44197344788947923, 'MAE_train': 1.7614494592470504, 'MSE_test': 4.593572147301449, 'R2_test': 0.5420637688776757, 'MAE_test': 1.9609972816338008}. 
Saved model results as IQP_Modified-Pauli-CRX_results.json. 
