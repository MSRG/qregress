/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:20:24 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:20:30 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:21:05 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:21:35 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:22:15 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:22:52 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 175.81748366355896 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:23:26 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:23:59 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:24:30 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:25:03 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:25:42 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 169.84172797203064 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:26:16 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:26:50 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:27:20 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:27:53 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:28:30 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 168.20456171035767 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:29:04 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:29:37 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:30:08 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:30:44 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:31:22 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 172.04794478416443 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:31:56 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:32:29 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:33:00 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:33:35 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:34:13 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 171.08433747291565 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:34:47 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:35:21 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:35:51 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:25 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:37:01 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 167.9951786994934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:35 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:38:09 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:38:40 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:39:14 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:39:50 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 168.84291577339172 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:40:24 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:40:58 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:28 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:42:02 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:42:43 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 171.23892974853516 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:43:16 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:51 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:44:21 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:44:54 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:45:31 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 169.8150839805603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:46:05 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:46:39 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:10 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:47:46 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:48:23 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 171.28099179267883 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:48:56 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:49:30 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:50:01 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:50:34 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:51:13 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 169.2089285850525 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:51:47 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:52:21 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:52:53 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:53:26 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:03 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 171.59459924697876 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:54:37 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:55:12 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:55:42 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:56:17 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:56:53 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 169.96079206466675 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:57:27 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:58:00 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:58:31 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 16:59:04 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 16:59:42 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 167.68063592910767 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:00:16 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:00:51 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:01:21 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:56 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:02:33 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 171.41517043113708 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:03:06 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:03:40 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:04:12 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:04:46 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:05:23 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 170.35006308555603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:57 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:06:30 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:07:01 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:07:34 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:08:12 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 168.12442660331726 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:08:46 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:20 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:09:50 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:10:23 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:11:01 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 170.72851300239563 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:11:35 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:12:09 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:40 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:18 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:13:55 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 172.72397017478943 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:14:28 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:15:02 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:15:32 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:16:05 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:16:44 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 168.42544984817505 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:17:18 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:51 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:22 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:18:55 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:19:32 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 169.42869091033936 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:20:06 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:20:39 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:21:10 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:21:45 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:22 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 169.67353439331055 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:22:56 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:23:30 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:24:01 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:24:35 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:25:13 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 169.57821035385132 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:25:47 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:26:20 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:26:51 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:27:24 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:28:01 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 169.78823733329773 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:28:35 2024]  Iteration number: 0 with current cost as 0.547470512160062 and parameters 
[-3.4419741   2.25951258 -1.27027893 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:29:09 2024]  Iteration number: 0 with current cost as 0.5167317697113731 and parameters 
[-3.44668032  2.28740847 -1.28457585 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:29:40 2024]  Iteration number: 0 with current cost as 0.5100774966385924 and parameters 
[-3.4273455   2.21778307 -1.26116437 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.72965078]. 
Working on 0.8 fold... 
[Mon Apr  1 17:30:16 2024]  Iteration number: 0 with current cost as 0.42065883134507376 and parameters 
[-3.42442929  2.20980904 -1.25961808 -0.11653101  0.55388709 -2.77010896
  3.06858499  2.18960146  1.18552    -1.06648308  0.60271511  1.14432446
  1.310299   -1.87354679  0.72965082]. 
Working on 1.0 fold... 
[Mon Apr  1 17:30:53 2024]  Iteration number: 0 with current cost as 0.4061262085700376 and parameters 
[-3.43734276  2.24596939 -1.26713263 -0.116531    0.55388709 -2.77010896
  3.068585    2.18960147  1.18552    -1.06648308  0.60271513  1.14432447
  1.310299   -1.87354679  0.7296508 ]. 
Training complete taking 172.55881786346436 seconds. 
Discarding model... 

Training complete taking 4257.410680770874 total seconds. 
Now scoring model... 
Scoring complete taking 0.7953112125396729 seconds. 
Saved predicted values as A1_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (6.101613268637543,), 'R2_train': 0.1622025665587965, 'MAE_train': 2.0280519268740065, 'MSE_test': 9.547753193938473, 'R2_test': 0.048178199206720174, 'MAE_test': 2.734127336906313}. 
Saved model results as A1_HWE-CZ_results.json. 
