/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:44 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:17 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:59 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:16:05 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:23:49 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:32:05 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2325.1159529685974 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:01 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:31 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:54:35 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:27 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:10:42 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2306.245075941086 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:19:27 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:25:57 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:33:08 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:41:15 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:49:35 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2348.230134487152 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:58:35 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:05:11 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:12:10 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:19:51 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:28:16 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2313.953599691391 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:37:10 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:43:44 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:51:05 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:58:54 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:07:12 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2338.6682844161987 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:16:08 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:22:44 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:29:47 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:37:45 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:46:01 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2333.607479095459 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:55:01 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:01:33 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:09:07 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:16:52 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:25:14 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2345.1639473438263 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:34:07 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:40:38 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:47:40 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:55:23 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:04:17 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2335.7971637248993 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:13:03 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:19:54 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:26:58 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:35:13 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:43:29 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2363.2157049179077 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:52:45 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:59:16 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:06:18 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:14:40 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:22:56 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2392.415652036667 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 22:32:18 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:38:48 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:45:58 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:53:58 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:02:15 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2350.255620956421 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:11:38 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:18:24 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:25:30 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:33:20 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:41:39 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2353.1102859973907 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 23:50:42 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:57:12 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:04:15 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:11:58 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:20:16 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2302.3537096977234 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 00:29:04 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:35:34 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:42:40 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:50:25 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:58:45 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2308.2753236293793 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 01:07:32 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 01:14:02 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 01:21:01 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 01:28:51 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 01:37:32 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2339.554703950882 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 01:46:39 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 01:53:15 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:00:16 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:08:30 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 02:17:06 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2358.671729326248 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 02:25:50 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 02:32:23 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:39:31 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:47:15 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 02:55:31 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2307.730900287628 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 03:04:20 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 03:10:58 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 03:17:59 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 03:25:45 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 03:34:00 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2310.1402418613434 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 03:42:49 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 03:49:19 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 03:56:46 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 04:04:49 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 04:13:49 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2388.9328787326813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 04:22:37 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 04:29:06 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 04:36:10 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 04:43:57 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 04:52:20 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2321.6476871967316 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 05:01:19 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 05:07:52 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 05:15:01 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 05:22:43 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 05:30:56 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2305.1738197803497 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 05:39:44 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 05:46:20 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 05:53:22 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 06:01:13 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 06:09:33 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2316.000827550888 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 06:18:20 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 06:24:51 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 06:32:06 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 06:40:04 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 06:48:20 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2327.646211385727 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 06:57:08 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 07:03:39 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 07:10:41 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 07:18:25 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 07:27:06 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2351.6056220531464 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 07:36:19 2024]  Iteration number: 0 with current cost as 0.3085363237703842 and parameters 
[-2.95117683  2.17594699 -2.2094651  -0.11653105  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.0664831   0.87374344  1.14432441
  1.31029897 -1.87354682  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 07:43:13 2024]  Iteration number: 0 with current cost as 0.2844998027789952 and parameters 
[-2.96857161  2.17244724 -2.2102872  -0.11653105  0.55388704 -2.77010901
  3.06858496  2.1896014   1.18551995 -1.06648312  0.88836097  1.1443244
  1.31029895 -1.87354684  0.72965077  2.88578416 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 07:50:18 2024]  Iteration number: 0 with current cost as 0.2726935819025421 and parameters 
[-2.95003154  2.18547829 -2.19854687 -0.11653103  0.55388706 -2.77010899
  3.06858498  2.18960141  1.18551998 -1.06648308  0.8202614   1.14432445
  1.31029899 -1.8735468   0.72965077  2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 07:58:01 2024]  Iteration number: 0 with current cost as 0.19766942293614026 and parameters 
[-3.0230734   2.19014648 -2.2768184  -0.11653105  0.55388708 -2.77010897
  3.06858498  2.18960143  1.18551998 -1.06648311  0.80936042  1.14432441
  1.31029899 -1.8735468   0.72965078  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 08:06:42 2024]  Iteration number: 0 with current cost as 0.2090091419866535 and parameters 
[-3.04475669  2.16937463 -2.25902792 -0.11653103  0.55388708 -2.77010904
  3.06858498  2.18960142  1.18552002 -1.06648313  0.87590223  1.14432439
  1.31029899 -1.87354682  0.72965077  2.88578416 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2348.389363527298 seconds. 
Discarding model... 

Training complete taking 58391.90397000313 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.1289453506469727 seconds. 
Saved predicted values as M-M-CNOT_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (3.1703691430896384,), 'R2_train': 0.5646844507838195, 'MAE_train': 1.2271191169602316, 'MSE_test': 12.779268339723886, 'R2_test': -0.27397367284889196, 'MAE_test': 2.3123900405262914}. 
Saved model results as M-M-CNOT_Modified-Pauli-CRX_results.json. 
