/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:50:03 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:50:17 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 15:51:31 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:52:42 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 15:54:06 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 15:55:17 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 377.49928402900696 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:56:33 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 15:57:50 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 15:59:00 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:00:09 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:01:21 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 368.6442859172821 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:42 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:03:56 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:05:06 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:06:23 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:07:33 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 367.2217197418213 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:08:50 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:10:00 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:10 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:12:25 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:13:38 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 364.91299057006836 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:14:55 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:16:05 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:17:15 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:18:27 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:19:37 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 359.99354457855225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:20:55 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:22:20 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:23:30 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:24:41 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:25:55 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 377.2009696960449 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:27:11 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:28:26 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:29:36 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:30:46 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:31:58 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 363.2590801715851 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:33:14 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:34:26 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:35:39 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:36:51 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:38:01 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 362.3544976711273 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:39:17 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:40:28 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:39 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:42:51 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:44:11 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 369.04425263404846 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:27 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:46:36 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:46 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:48:57 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:50:07 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 363.528715133667 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:51:30 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:52:39 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:53:51 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:55:01 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:56:13 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 359.0717980861664 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:57:30 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 16:58:39 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:48 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:04 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:02:26 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 373.9801125526428 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:03:42 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:04:53 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:06:03 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:07:12 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:08:23 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 356.22815346717834 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:38 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:10:48 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:12 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:24 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:14:33 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 370.78018403053284 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:49 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:00 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:10 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:19:26 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:20:36 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 361.5779130458832 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:21:51 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:23:02 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:24:13 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:25:24 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:26:34 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 381.3955545425415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:28:12 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:29:27 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:30:36 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:31:47 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:32:58 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 361.10309958457947 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:34:13 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:35:24 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:36:34 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:37:44 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:38:55 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 357.36475014686584 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:40:11 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:41:21 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:42:32 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:43:42 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:44:52 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 358.22360396385193 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:46:09 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:47:19 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:48:30 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:49:40 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:50:49 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 355.9056031703949 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:52:06 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:53:16 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:54:28 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:55:38 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:56:49 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 359.1806101799011 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:58:05 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 17:59:15 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:00:27 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:01:37 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:02:50 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 382.8215756416321 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:04:29 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:05:39 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:06:49 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:08:03 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:09:13 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 362.6730797290802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:10:31 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:11:41 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:12:51 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:14:03 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:15:13 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 360.31838154792786 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:31 2024]  Iteration number: 0 with current cost as 0.2474041102258953 and parameters 
[-3.33411166  2.0854022  -1.30797855 -0.11653103  0.55388708 -2.77010897
  3.06858497  2.18960144  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029897 -1.87354681  0.72965079]. 
Working on 0.4 fold... 
[Mon Apr  1 18:17:43 2024]  Iteration number: 0 with current cost as 0.2541939437837447 and parameters 
[-3.30197798  2.11310603 -1.38170264 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:18:54 2024]  Iteration number: 0 with current cost as 0.23154677438926302 and parameters 
[-3.36692254  2.07380535 -1.24580878 -0.11653102  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354679  0.7296508 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:20:05 2024]  Iteration number: 0 with current cost as 0.19480981213014859 and parameters 
[-3.3576698   2.07473215 -1.26150029 -0.11653101  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551999 -1.0664831   0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:21:29 2024]  Iteration number: 0 with current cost as 0.23334070976313026 and parameters 
[-3.29099517  2.11771984 -1.40308765 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.0664831   0.6027151   1.14432444
  1.31029899 -1.87354681  0.7296508 ]. 
Training complete taking 375.07925248146057 seconds. 
Discarding model... 

Training complete taking 9149.364225387573 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 0.9226298332214355 seconds. 
Saved predicted values as M-A2-CNOT_HWE-CZ_predicted_values.csv
Model scores: {'MSE_train': (3.7356843719991035,), 'R2_train': 0.4870624142807861, 'MAE_train': 1.3028591036742685, 'MSE_test': 6.473142677103022, 'R2_test': 0.35468814551850747, 'MAE_test': 1.8691995904708278}. 
Saved model results as M-A2-CNOT_HWE-CZ_results.json. 
