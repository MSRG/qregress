/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:47:09 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:48:23 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:59:01 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:34 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:21:22 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:29:24 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2901.070246696472 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:36:44 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:18 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:57:46 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:09:31 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:17:33 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2900.6781458854675 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:25:04 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:35:44 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:46:08 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:57:56 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:06:00 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2895.7034759521484 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:13:20 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:23:50 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:34:11 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:46:24 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:54:33 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2915.340702533722 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:01:56 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:12:34 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:23:02 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:34:46 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:42:56 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2903.583876132965 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:50:18 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:01:00 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:11:22 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:23:10 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:31:15 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2929.513247489929 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:39:09 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:49:58 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:00:17 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:12:03 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:20:09 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2908.4203145504 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:27:38 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:38:18 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:48:41 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:00:33 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:08:38 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2903.5655574798584 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 22:16:01 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:27:10 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:37:33 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:49:21 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:57:53 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2990.7442712783813 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 23:05:50 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:16:48 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:27:10 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:38:55 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:47:47 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2957.7384147644043 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 23:55:09 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:05:42 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:16:05 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:27:52 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:35:56 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2907.5039625167847 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 00:43:37 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:54:11 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 01:04:32 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 01:16:23 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 01:24:29 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2894.2885620594025 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 01:31:52 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 01:42:26 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 01:52:47 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:04:32 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 02:12:37 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2889.2287316322327 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 02:19:59 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 02:30:53 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:41:17 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:53:03 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 03:01:08 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2912.019187450409 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 03:08:31 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 03:19:00 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 03:29:21 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 03:41:33 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 03:49:50 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2934.7825191020966 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 03:57:27 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 04:08:05 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 04:18:30 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 04:30:32 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 04:38:34 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2909.198307991028 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 04:45:56 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 04:56:28 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 05:07:16 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 05:19:03 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 05:27:19 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2940.676265001297 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 05:34:57 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 05:45:36 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 05:55:55 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 06:07:38 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 06:15:43 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2887.3752760887146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 06:23:05 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 06:33:39 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 06:44:34 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 06:56:26 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 07:04:39 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2934.634001970291 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 07:11:59 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 07:23:12 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 07:33:34 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 07:45:28 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 07:53:35 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2938.49334526062 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 08:00:57 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 08:11:30 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 08:21:51 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 08:33:32 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 08:41:39 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2885.945566177368 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 08:49:02 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 08:59:37 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 09:10:02 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 09:21:47 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 09:30:06 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2905.9848985671997 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 09:37:28 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 09:48:08 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 09:58:41 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 10:10:28 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 10:18:33 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2908.8140144348145 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 10:25:57 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 10:36:29 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 10:46:52 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 10:58:34 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 11:06:36 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2881.5581862926483 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 11:13:59 2024]  Iteration number: 0 with current cost as 0.22685289611665624 and parameters 
[-2.21988322  2.09338884 -1.93367341 -0.11653091  0.5538872  -2.77010897
  3.06858498  2.18960157  1.1855201  -1.0664832   0.6963494   1.14432445
  1.3102991  -1.87354668  0.7296508   2.88578419 -0.54534323 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 11:24:31 2024]  Iteration number: 0 with current cost as 0.21792799216390257 and parameters 
[-2.20682678  2.10912359 -1.89021326 -0.11653103  0.55388715 -2.77010904
  3.06858498  2.18960152  1.18552006 -1.06648323  0.73428758  1.14432452
  1.31029913 -1.87354666  0.7296508   2.88578419 -0.54534306 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 11:35:14 2024]  Iteration number: 0 with current cost as 0.20068327195604457 and parameters 
[-2.25003188  2.15940063 -1.92136796 -0.1165309   0.55388708 -2.77010904
  3.06858492  2.18960152  1.18552005 -1.06648315  0.48048164  1.14432452
  1.31029905 -1.87354661  0.7296508   2.88578419 -0.54534316 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 11:47:23 2024]  Iteration number: 0 with current cost as 0.14877052130318852 and parameters 
[-2.35152226  2.22745783 -1.96284776 -0.11653103  0.55388721 -2.77010891
  3.06858498  2.18960145  1.18551998 -1.06648308  0.20089789  1.14432445
  1.31029905 -1.87354667  0.7296508   2.88578419 -0.54534322 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 11:55:29 2024]  Iteration number: 0 with current cost as 0.15704593766128572 and parameters 
[-2.31545609  2.24634768 -1.88616369 -0.11653086  0.55388708 -2.77010897
  3.06858498  2.18960161  1.1855199  -1.06648325  0.20811508  1.14432445
  1.31029907 -1.87354664  0.7296508   2.88578419 -0.54534319 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2932.4724831581116 seconds. 
Discarding model... 

Training complete taking 72869.33550000191 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 1.2392196655273438 seconds. 
Saved predicted values as M-A2-CNOT_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (3.5959492082634115,), 'R2_train': 0.5062491041585255, 'MAE_train': 1.2825018999007685, 'MSE_test': 4.972083041364769, 'R2_test': 0.5043297686904957, 'MAE_test': 1.7003141448505903}. 
Saved model results as M-A2-CNOT_Modified-Pauli-CRX_results.json. 
