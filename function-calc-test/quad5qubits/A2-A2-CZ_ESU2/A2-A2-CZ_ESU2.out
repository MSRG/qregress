/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:54:10 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:55:50 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 15:57:44 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 16:01:24 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:02:17 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:03:21 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 619.0722115039825 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:00 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 16:07:48 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 16:11:28 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:12:19 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:13:24 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 601.2553143501282 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:16:02 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 16:17:52 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 16:21:24 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:22:16 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:23:25 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 597.0440540313721 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:26:02 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 16:27:48 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:24 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:17 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:33:22 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 597.7667739391327 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:35:58 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:43 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:11 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:42:02 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:43:07 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 588.0811133384705 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:52 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 16:47:40 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:11 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:52:03 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 16:53:11 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 603.4820394515991 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:55:49 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 16:57:31 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 17:01:03 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:57 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:03:04 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 594.5276703834534 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:43 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 17:07:30 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 17:10:57 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:11:51 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:12:57 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 590.5161769390106 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:15:34 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 17:17:21 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 17:20:56 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:21:48 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:22:54 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 597.646782875061 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:25:34 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 17:27:23 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 17:31:00 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:31:55 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:33:02 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 611.4813098907471 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:35:47 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 17:37:40 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 17:41:17 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:42:10 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:43:18 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 613.8908643722534 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:46:04 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 17:47:52 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 17:51:31 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:52:25 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 17:53:35 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 616.349844455719 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:56:16 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 17:58:01 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 18:01:44 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:02:38 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:03:46 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 612.9367170333862 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:06:29 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 18:08:13 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 18:11:51 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:12:46 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:13:52 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 607.4051795005798 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:37 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 18:18:28 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 18:22:04 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:22:59 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:24:06 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 612.3736665248871 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:26:50 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 18:28:35 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 18:32:13 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:33:08 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:34:19 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 614.114593744278 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:37:01 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 18:38:48 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 18:42:25 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:43:20 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:44:29 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 606.4012041091919 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:47:10 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 18:49:00 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 18:52:38 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:53:31 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 18:54:41 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 614.6821136474609 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:57:26 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 18:59:13 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 19:02:53 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:03:47 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:04:58 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 620.597315788269 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:07:47 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 19:09:36 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 19:13:12 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:14:06 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:15:13 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 610.6704299449921 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:17:50 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 19:19:38 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 19:23:19 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:24:13 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:25:23 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 610.6611969470978 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:28:06 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 19:29:56 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 19:33:34 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:34:28 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:35:35 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 609.3534817695618 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:38:18 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 19:40:05 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 19:43:50 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:44:43 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:45:53 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 618.6141140460968 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:48:33 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 19:50:22 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 19:54:00 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:54:54 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 19:56:02 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 609.4873557090759 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:58:43 2024]  Iteration number: 0 with current cost as 0.19165957176125703 and parameters 
[-3.80176581  2.23743464 -2.1242795  -0.11653096  0.55388708 -2.7701089
  3.06858498  2.18960152  1.18552012 -1.06648302]. 
Working on 0.4 fold... 
[Mon Apr  1 20:00:37 2024]  Iteration number: 0 with current cost as 0.2400758135636011 and parameters 
[-2.55179989  2.23743464 -2.12427954 -0.11653093  0.55388708 -2.77010897
  3.06858498  2.18960155  1.18552018 -1.06648299]. 
Working on 0.6 fold... 
[Mon Apr  1 20:04:22 2024]  Iteration number: 0 with current cost as 0.2093575092991717 and parameters 
[-3.73985247  2.23743464 -2.12427964 -0.11652755  0.55388708 -2.77010549
  3.06858498  2.18960145  1.18552695 -1.0664796 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:05:16 2024]  Iteration number: 0 with current cost as 0.17993387491154908 and parameters 
[-2.59398411  2.23743464 -2.12427956 -0.11653099  0.55388712 -2.77010889
  3.06858498  2.18960149  1.18552006 -1.06648308]. 
Working on 1.0 fold... 
[Mon Apr  1 20:06:24 2024]  Iteration number: 0 with current cost as 0.19977313092034774 and parameters 
[-2.69651434  2.23743462 -2.12427965 -0.11653104  0.55388707 -2.77010899
  3.06858496  2.18960143  1.18551998 -1.0664831 ]. 
Training complete taking 625.0809855461121 seconds. 
Discarding model... 

Training complete taking 15203.493374347687 total seconds. 
Now scoring model... 
Scoring complete taking 2.101698398590088 seconds. 
Saved predicted values as A2-A2-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (4.812349701761835,), 'R2_train': 0.3392281595949329, 'MAE_train': 1.5338657333830779, 'MSE_test': 6.7606975756381775, 'R2_test': 0.3260216083980859, 'MAE_test': 2.2093186276009105}. 
Saved model results as A2-A2-CZ_ESU2_results.json. 
