/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:05:47 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:29 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:18 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:14 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:49 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 16:12:45 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 460.2011811733246 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:14:13 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:15:47 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:17:43 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:19:20 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 16:20:14 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 446.4663848876953 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:21:33 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:23:07 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:24:53 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:26:29 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 16:27:24 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 428.72127890586853 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:42 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:30:19 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:32:11 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:33:48 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 16:34:38 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 436.18548703193665 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:36:03 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:38 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:39:25 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:40:58 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 16:41:51 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 437.2823097705841 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:43:19 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:44:55 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:46:41 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:48:15 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 16:49:07 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 430.58121275901794 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:50:27 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:51:59 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 16:53:49 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 16:55:26 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 16:56:23 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 437.71140241622925 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:57:54 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:30 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:01:21 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:02:58 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 17:03:56 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 452.48912954330444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:19 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:06:54 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:08:49 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:10:22 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 17:11:13 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 437.0893003940582 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:12:33 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:14:08 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:16:00 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:17:33 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 17:18:26 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 431.8020713329315 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:19:49 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:21:25 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:23:18 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:25:00 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 17:25:54 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 447.69679141044617 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:27:15 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:28:47 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:30:36 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:32:09 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 17:33:04 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 432.0331492424011 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:34:25 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:36:00 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:37:46 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:16 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 17:40:08 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 423.0567481517792 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:41:26 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:43:02 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:44:49 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:46:24 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 17:47:19 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 434.5235278606415 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:48:42 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:50:16 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:52:09 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 17:53:46 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 17:54:38 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 433.54002833366394 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:55:56 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 17:57:29 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 17:59:22 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:00:58 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 18:01:51 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 432.6762328147888 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:03:07 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:04:33 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:06:20 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:07:56 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 18:08:49 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 423.5174026489258 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:10:11 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:11:50 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:13:41 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:15:10 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 18:16:03 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 435.2165539264679 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:17:30 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:19:10 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:21:04 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:22:40 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:41 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 456.49099373817444 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:25:09 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:26:50 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:28:46 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:30:24 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 18:31:24 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 468.29634380340576 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:32:54 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:34:36 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:36:27 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:38:10 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 18:39:04 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 450.4029133319855 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:40:24 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:41:59 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:43:47 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:45:20 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 18:46:17 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 434.7389702796936 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:47:38 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:49:13 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:51:04 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 18:52:44 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 18:53:43 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 446.2083058357239 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:55:05 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 18:56:41 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 18:58:36 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 19:00:11 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 19:01:07 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 442.95440554618835 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:02:29 2024]  Iteration number: 0 with current cost as 0.17617972684048308 and parameters 
[-2.82152765  2.23743465 -2.12427961 -0.11653102  0.55388709 -2.77010895
  3.06858498  2.18960146  1.18552    -1.06648308]. 
Working on 0.4 fold... 
[Mon Apr  1 19:04:04 2024]  Iteration number: 0 with current cost as 0.1891573986619902 and parameters 
[-2.80986893  2.23743464 -2.12427962 -0.11653104  0.55388708 -2.77010897
  3.06858496  2.18960145  1.18551998 -1.06648309]. 
Working on 0.6 fold... 
[Mon Apr  1 19:05:48 2024]  Iteration number: 0 with current cost as 0.18008870446880235 and parameters 
[-2.83664859  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010896
  3.06858498  2.18960145  1.18551999 -1.06648309]. 
Working on 0.8 fold... 
[Mon Apr  1 19:07:22 2024]  Iteration number: 0 with current cost as 0.14654325660554204 and parameters 
[-2.90504715  2.23743464 -2.12427963 -0.11653102  0.55388709 -2.77010897
  3.06858497  2.18960144  1.18551999 -1.06648309]. 
Working on 1.0 fold... 
[Mon Apr  1 19:08:12 2024]  Iteration number: 0 with current cost as 0.17240848123246655 and parameters 
[-2.91664848  2.23743464 -2.12427963 -0.11653103  0.55388709 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648309]. 
Training complete taking 423.3292598724365 seconds. 
Discarding model... 

Training complete taking 10983.212316989899 total seconds. 
Now scoring model... 
Scoring complete taking 2.0304157733917236 seconds. 
Saved predicted values as A1-A1-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (3.824768592333121,), 'R2_train': 0.47483048022171115, 'MAE_train': 1.4281079271257382, 'MSE_test': 7.1475756828909125, 'R2_test': 0.2874534752202639, 'MAE_test': 2.105792724482847}. 
Saved model results as A1-A1-CZ_ESU2_results.json. 
