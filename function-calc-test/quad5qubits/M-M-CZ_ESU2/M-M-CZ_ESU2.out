/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/circuits/Encoders.py:12: RuntimeWarning: invalid value encountered in arcsin
  if np.isnan(np.arcsin(features[feature_idx])) or np.isnan(np.arccos(features[feature_idx])):
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:51 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:03:17 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:05:49 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 16:09:14 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 16:11:31 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 16:13:34 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 754.0836215019226 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:15:51 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:18:23 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 16:21:49 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 16:24:10 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 16:26:11 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 756.4315133094788 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:28:26 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:31:18 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 16:34:53 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 16:37:08 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 16:39:09 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 781.1168625354767 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:41:26 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:43:57 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:18 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 16:49:29 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 16:51:23 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 731.8361010551453 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:53:38 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:56:10 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 16:59:33 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 17:01:44 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 17:03:39 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 735.0290312767029 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:05:52 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:08:24 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 17:11:42 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 17:14:00 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 17:15:57 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 735.785071849823 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:18:10 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:20:38 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 17:23:54 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 17:26:08 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 17:28:06 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 733.7588934898376 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:30:21 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:32:54 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 17:36:19 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 17:38:38 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 17:40:42 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 757.8918924331665 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:43:04 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:45:34 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 17:48:57 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 17:51:23 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 17:53:20 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 755.7273936271667 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:55:40 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:58:14 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 18:01:38 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 18:03:58 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 18:05:57 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 753.6536450386047 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:08:08 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:10:38 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 18:13:50 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 18:15:59 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 18:17:51 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 713.2901430130005 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:20:02 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:22:29 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 18:25:43 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 18:27:49 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 18:29:42 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 710.4606716632843 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:31:52 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:34:19 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 18:37:39 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 18:39:48 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 18:41:46 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 724.4328980445862 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:43:55 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:46:18 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 18:49:29 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 18:51:42 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 18:53:33 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 708.8105988502502 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:55:44 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:58:10 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 19:01:24 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 19:03:33 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 19:05:24 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 713.5336713790894 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:07:37 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:10:02 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 19:13:12 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 19:15:19 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 19:17:14 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 705.4316985607147 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:19:23 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:21:49 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 19:25:01 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 19:27:13 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 19:29:07 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 712.3610470294952 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:31:23 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:33:46 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 19:37:05 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 19:39:17 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 19:41:10 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 721.748854637146 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:43:17 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:45:41 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 19:49:01 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 19:51:15 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 19:53:08 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 718.4342319965363 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:55:18 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:57:49 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 20:01:06 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 20:03:13 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 20:05:05 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 717.9243106842041 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 20:07:13 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:09:42 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 20:13:04 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 20:15:13 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 20:17:11 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 730.8710894584656 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:19:27 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:21:55 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 20:25:17 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 20:27:30 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 20:29:30 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 736.9803240299225 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:31:42 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:34:08 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 20:37:33 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 20:39:48 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 20:41:45 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 733.8369326591492 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:43:56 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:46:32 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 20:50:02 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 20:52:22 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 20:54:20 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 753.6215505599976 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 20:56:28 2024]  Iteration number: 0 with current cost as 0.17432845376753683 and parameters 
[-2.81244226  2.23743464 -2.12427932 -0.11653118  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18552014 -1.0664834 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:58:55 2024]  Iteration number: 0 with current cost as 0.18518561737291037 and parameters 
[-2.7813574   2.23743464 -2.12427956 -0.11653103  0.55388708 -2.77010905
  3.06858483  2.18960145  1.18551998 -1.06648324]. 
Working on 0.6 fold... 
[Mon Apr  1 21:02:14 2024]  Iteration number: 0 with current cost as 0.15603565681060488 and parameters 
[-3.71197076  2.23743464 -2.12427926 -0.11653103  0.55388708 -2.77010935
  3.06858461  2.18960145  1.18551998 -1.06648346]. 
Working on 0.8 fold... 
[Mon Apr  1 21:04:34 2024]  Iteration number: 0 with current cost as 0.1435712728052057 and parameters 
[-2.69202415  2.2374346  -2.1242796  -0.11653103  0.55388712 -2.77010901
  3.06858494  2.18960149  1.18552002 -1.06648312]. 
Working on 1.0 fold... 
[Mon Apr  1 21:06:28 2024]  Iteration number: 0 with current cost as 0.1624023592831359 and parameters 
[-2.64597385  2.23743464 -2.12427961 -0.11653105  0.5538871  -2.770109
  3.06858496  2.18960145  1.18552001 -1.06648311]. 
Training complete taking 730.5383772850037 seconds. 
Discarding model... 

Training complete taking 18327.59131669998 total seconds. 
Now scoring model... 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0412371134020617. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Ignoring NaN found at index: 0. With feature: -1.0206185567010309. 
Scoring complete taking 2.518892526626587 seconds. 
Saved predicted values as M-M-CZ_ESU2_predicted_values.csv
Model scores: {'MSE_train': (3.7273656071029664,), 'R2_train': 0.48820464332293256, 'MAE_train': 1.3837007889299902, 'MSE_test': 17.329620405281077, 'R2_test': -0.7276012655721456, 'MAE_test': 2.750351354685595}. 
Saved model results as M-M-CZ_ESU2_results.json. 
