/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:46:32 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:46:38 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 15:48:33 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 15:50:26 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 15:52:31 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 15:54:49 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 618.6382355690002 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 15:56:57 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 15:58:43 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 16:00:28 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 16:02:34 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 16:04:50 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 602.118002653122 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:06:59 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 16:08:45 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 16:10:31 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 16:12:36 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 16:14:52 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 601.8792200088501 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:17:01 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 16:18:47 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 16:20:33 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 16:22:41 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 16:25:11 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 635.5082671642303 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:27:36 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 16:29:22 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:08 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 16:33:13 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 16:35:29 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 601.6021358966827 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:37:38 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 16:39:23 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 16:41:09 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 16:43:17 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 16:45:32 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 603.124365568161 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:47:41 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 16:49:29 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 16:51:15 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 16:53:21 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 16:55:36 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 605.6303825378418 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:57:47 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 16:59:32 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 17:01:18 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 17:03:26 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 17:05:41 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 603.6558086872101 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:07:50 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:37 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 17:11:37 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 17:13:44 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 17:15:59 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 619.2231204509735 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:18:11 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 17:19:55 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 17:21:42 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 17:23:48 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 17:26:02 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 600.9997687339783 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:28:12 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 17:29:57 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 17:31:57 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 17:34:04 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 17:36:20 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 618.2683346271515 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:38:29 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 17:40:15 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 17:42:09 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 17:44:14 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 17:46:27 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 613.2484817504883 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:48:42 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 17:50:33 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 17:52:18 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 17:54:23 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 17:56:37 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 602.2940227985382 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:58:44 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 18:00:30 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 18:02:15 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 18:04:19 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 18:06:34 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 597.2663960456848 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:08:41 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 18:10:27 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 18:12:12 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 18:14:16 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 18:16:40 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 605.3621683120728 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:18:47 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 18:20:32 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 18:22:18 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 18:24:22 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 18:26:36 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 626.0797810554504 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:29:17 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 18:31:00 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 18:32:45 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 18:34:50 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 18:37:03 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 597.1720407009125 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:39:10 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 18:40:54 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 18:42:39 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 18:44:44 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 18:46:57 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 594.4143908023834 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:49:04 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 18:50:50 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 18:52:35 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 18:54:39 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 18:56:53 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 596.0440964698792 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:59:00 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 19:00:46 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 19:02:30 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 19:04:35 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 19:06:48 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 595.0085020065308 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:08:55 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 19:10:40 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 19:12:25 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 19:14:30 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 19:16:44 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 596.0538656711578 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:18:52 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 19:20:37 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 19:22:22 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 19:24:27 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 19:26:40 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 595.7531988620758 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:28:47 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 19:30:32 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 19:32:17 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 19:34:23 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 19:36:37 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 596.863365650177 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:38:44 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 19:40:30 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 19:42:14 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 19:44:20 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 19:46:34 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 597.4662380218506 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:48:42 2024]  Iteration number: 0 with current cost as 0.39857761099421474 and parameters 
[-2.90318344  2.23743464 -2.12427964 -0.09706266  0.56859683 -2.72386554
  2.92145805  2.20327591  1.43137231 -1.06645235  0.68733517  1.17081883
  1.47023675 -1.72496283  0.72513448]. 
Working on 0.4 fold... 
[Mon Apr  1 19:50:27 2024]  Iteration number: 0 with current cost as 0.3727894634142119 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09897066  0.56721194 -2.72830754
  2.93735398  2.20239277  1.4044714  -1.06645625  0.67306259  1.16635168
  1.45369937 -1.74046125  0.72511812]. 
Working on 0.6 fold... 
[Mon Apr  1 19:52:10 2024]  Iteration number: 0 with current cost as 0.4232464439433793 and parameters 
[-2.90318345  2.23743464 -2.12427963 -0.09702597  0.56720568 -2.72603095
  2.92082422  2.20381018  1.43216074 -1.06645373  0.67640438  1.16739957
  1.46817904 -1.72754773  0.72278238]. 
Working on 0.8 fold... 
[Mon Apr  1 19:54:15 2024]  Iteration number: 0 with current cost as 0.404117868177968 and parameters 
[-2.90318345  2.23743464 -2.12427964 -0.09500391  0.56765631 -2.722938
  2.92206717  2.21109809  1.42586749 -1.06644991  0.68855335  1.17120267
  1.46591558 -1.73305223  0.71066824]. 
Working on 1.0 fold... 
[Mon Apr  1 19:56:30 2024]  Iteration number: 0 with current cost as 0.36523094110954146 and parameters 
[-2.90318345  2.23743463 -2.12427964 -0.09935381  0.56655737 -2.72979723
  2.94962903  2.20534574  1.38162808 -1.06645701  0.6700405   1.16540588
  1.43579524 -1.75966167  0.71643296]. 
Training complete taking 596.2492249011993 seconds. 
Discarding model... 

Training complete taking 15119.924768924713 total seconds. 
Now scoring model... 
Scoring complete taking 0.724890947341919 seconds. 
Saved predicted values as A1_HWE-CNOT_predicted_values.csv
Model scores: {'MSE_train': (2.793645665584088,), 'R2_train': 0.6164114201401829, 'MAE_train': 1.2343126887662141, 'MSE_test': 5.700169453109946, 'R2_test': 0.4317463550345606, 'MAE_test': 1.8429086471090728}. 
Saved model results as A1_HWE-CNOT_results.json. 
