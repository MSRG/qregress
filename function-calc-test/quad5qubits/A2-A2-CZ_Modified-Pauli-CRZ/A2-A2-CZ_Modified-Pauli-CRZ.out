/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:54 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:41 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:04:22 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:06:03 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:07:45 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:09:27 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 499.50902032852173 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:11:00 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:12:42 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:14:23 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:16:04 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:17:50 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 502.35193848609924 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 16:19:23 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:21:04 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:22:46 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:24:27 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:26:11 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 500.9406292438507 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 16:27:44 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:29:25 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:31:09 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:32:51 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:34:32 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 501.79275703430176 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 16:36:04 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:37:47 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:39:28 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:41:11 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:42:52 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 501.8152985572815 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:44:25 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:46:07 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:47:49 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:49:31 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:51:14 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 498.88303995132446 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:52:45 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:54:25 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:56:06 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:57:48 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:59:30 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 497.58780789375305 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:01:02 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:02:45 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:04:27 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:06:09 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:07:52 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 501.00751066207886 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:09:25 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:11:07 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:12:50 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:14:31 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:16:13 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 502.1174533367157 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 17:17:47 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:19:29 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:21:12 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:22:54 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:24:36 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 502.625905752182 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 17:26:09 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:27:52 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:29:34 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:31:17 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:33:00 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 504.7468030452728 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 17:34:53 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:36:34 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:38:17 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:39:58 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:41:42 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 521.2454223632812 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:43:16 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:44:57 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:46:38 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:48:22 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:50:07 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 506.04930353164673 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:51:40 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:53:27 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:55:08 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:56:51 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:58:33 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 505.5538556575775 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:00:06 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:01:50 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:03:33 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:05:15 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:07:01 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 507.3304777145386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:08:33 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:10:15 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:11:57 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:13:38 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:15:21 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 498.4832806587219 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:16:52 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:18:33 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:20:16 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:21:57 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:23:40 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 500.5573511123657 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 18:25:12 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:27:15 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:28:57 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:30:38 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:32:21 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 521.4424524307251 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:34:00 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:35:40 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:37:22 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:39:12 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:40:54 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 511.88308119773865 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:42:26 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:44:08 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:45:58 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:48:00 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:49:41 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 534.8426308631897 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:51:21 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:53:02 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:54:50 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:56:30 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:58:11 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 503.06220054626465 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 18:59:43 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:01:26 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:03:07 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:04:50 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:06:31 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 498.3909809589386 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 19:08:03 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:09:44 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:11:31 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:13:13 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:14:56 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 505.7451295852661 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 19:16:28 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:18:09 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:19:52 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:21:34 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:23:15 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 500.0882589817047 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 19:24:47 2024]  Iteration number: 0 with current cost as 0.163740896637035 and parameters 
[-3.60655912  2.23743464 -2.12427964 -0.11653105  0.55388702 -2.77010897
  3.06858495  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578417 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:26:29 2024]  Iteration number: 0 with current cost as 0.17276088307272558 and parameters 
[-3.63298138  2.23743461 -2.12427961 -0.116531    0.55388708 -2.77010897
  3.06858496  2.18960148  1.18551998 -1.06648311  0.60271513  1.14432445
  1.31029899 -1.87354677  0.72965078  2.88578417 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:28:10 2024]  Iteration number: 0 with current cost as 0.17140794825160102 and parameters 
[-3.5974462   2.23743461 -2.12427964 -0.11653103  0.55388708 -2.770109
  3.06858492  2.18960145  1.18551998 -1.06648311  0.6027151   1.14432442
  1.31029899 -1.8735468   0.72965074  2.88578413 -0.54534338 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:29:52 2024]  Iteration number: 0 with current cost as 0.1322503256381438 and parameters 
[-3.56751037  2.23743464 -2.12427962 -0.11653103  0.55388707 -2.77010897
  3.06858497  2.18960148  1.18551998 -1.06648311  0.60271512  1.14432445
  1.310299   -1.87354677  0.72965079  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:31:33 2024]  Iteration number: 0 with current cost as 0.15501992517888352 and parameters 
[-3.59277842  2.23743462 -2.12427962 -0.11653103  0.55388707 -2.77010899
  3.06858497  2.18960149  1.18551997 -1.0664831   0.60271513  1.14432446
  1.31029899 -1.87354679  0.72965079  2.88578418 -0.54534335 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 498.47705578804016 seconds. 
Discarding model... 

Training complete taking 12626.530752897263 total seconds. 
Now scoring model... 
Scoring complete taking 1.0267817974090576 seconds. 
Saved predicted values as A2-A2-CZ_Modified-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (3.38125696059227,), 'R2_train': 0.5357279659217145, 'MAE_train': 1.2525997823326485, 'MSE_test': 6.7767385776818205, 'R2_test': 0.3244224703452294, 'MAE_test': 1.880798365914719}. 
Saved model results as A2-A2-CZ_Modified-Pauli-CRZ_results.json. 
