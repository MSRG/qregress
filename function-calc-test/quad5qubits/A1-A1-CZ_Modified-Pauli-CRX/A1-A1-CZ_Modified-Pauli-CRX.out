/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 15:44:07 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 15:44:44 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 15:53:10 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:02:22 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:09:55 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:16:16 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2295.918981075287 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:22:59 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 16:31:25 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 16:40:43 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 16:48:14 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 16:54:32 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2289.815101146698 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:01:10 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:09:33 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:18:37 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 17:26:14 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 17:32:32 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2293.265780210495 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 17:39:23 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 17:47:50 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 17:56:53 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:04:09 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:10:22 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2260.3245232105255 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:17:03 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 18:25:17 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 18:34:21 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 18:41:37 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 18:47:43 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2239.1624460220337 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 18:54:23 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:02:38 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:11:47 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:19:09 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 19:25:20 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2252.4894847869873 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 19:31:55 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 19:40:09 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 19:49:01 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 19:56:18 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:02:30 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2239.060777902603 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 20:09:14 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:17:32 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 20:26:33 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 20:34:00 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 20:40:02 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2244.450037240982 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 20:46:37 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 20:54:50 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:03:43 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:11:06 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:17:10 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2219.8926577568054 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 21:23:37 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 21:31:48 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 21:40:51 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 21:48:07 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 21:54:13 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2227.335325241089 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 22:00:45 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:09:02 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:18:05 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 22:25:23 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 22:31:36 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2245.08758687973 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 22:38:09 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 22:46:33 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 22:55:39 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:03:10 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:09:31 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2281.3314406871796 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 23:16:12 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Mon Apr  1 23:24:30 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Mon Apr  1 23:33:36 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Mon Apr  1 23:40:57 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Mon Apr  1 23:47:10 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2259.1431572437286 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 23:53:50 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:02:14 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:11:22 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:18:51 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 00:25:04 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2277.355357646942 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 00:31:48 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 00:40:09 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 00:49:29 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 00:56:58 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 01:03:19 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2292.104897260666 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 01:10:04 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 01:18:42 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 01:28:03 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 01:35:42 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 01:42:09 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2346.788638114929 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 01:49:08 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 01:57:41 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:07:16 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:14:57 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 02:21:11 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2324.3028407096863 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 02:27:52 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 02:36:10 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 02:45:14 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 02:52:28 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 02:58:52 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2268.9507818222046 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 03:05:42 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 03:14:11 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 03:23:36 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 03:31:28 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 03:37:48 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2330.893006324768 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 03:44:30 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 03:52:41 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 04:01:47 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 04:09:17 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 04:15:31 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2263.9052402973175 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 04:22:17 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 04:31:12 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 04:40:31 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 04:48:12 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 04:54:38 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2357.1773397922516 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 05:01:35 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 05:10:17 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 05:19:23 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 05:26:57 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 05:33:19 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2307.2745013237 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 05:40:01 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 05:48:36 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 05:57:53 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 06:05:12 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 06:11:18 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2294.691929578781 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 06:18:15 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 06:26:54 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 06:36:05 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 06:43:54 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 06:50:01 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2303.670619726181 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 06:56:39 2024]  Iteration number: 0 with current cost as 0.12378263098451697 and parameters 
[-2.47096364  2.94244193 -1.52340685 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18551998 -1.06648308  0.84320125  1.14432441
  1.31029899 -1.87354684  0.7296508   2.88578415 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.4 fold... 
[Tue Apr  2 07:04:53 2024]  Iteration number: 0 with current cost as 0.12217110946159036 and parameters 
[-2.43860836  2.95229146 -1.52072696 -0.11653103  0.55388704 -2.77010893
  3.06858498  2.18960145  1.18552002 -1.06648312  1.03083055  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534327 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.6 fold... 
[Tue Apr  2 07:13:54 2024]  Iteration number: 0 with current cost as 0.13156737590921352 and parameters 
[-2.47315083  2.96174995 -1.53622802 -0.11653107  0.55388712 -2.77010893
  3.06858502  2.18960149  1.18552002 -1.06648305  0.74710448  1.14432449
  1.31029902 -1.8735468   0.7296508   2.88578419 -0.54534331 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 0.8 fold... 
[Tue Apr  2 07:21:27 2024]  Iteration number: 0 with current cost as 0.12137456873256851 and parameters 
[-2.81399055  2.41179529 -1.98172721 -0.11653103  0.5538871  -2.77010896
  3.06858499  2.18960145  1.18552    -1.06648308  0.59737616  1.14432446
  1.31029899 -1.87354679  0.7296508   2.88578419 -0.54534333 -0.47522485
 -2.0265424   0.7289737 ]. 
Working on 1.0 fold... 
[Tue Apr  2 07:27:44 2024]  Iteration number: 0 with current cost as 0.14147014854738818 and parameters 
[-2.79840683  2.43632996 -1.96260179 -0.11653105  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551998 -1.06648308  0.60980621  1.14432445
  1.31029899 -1.8735468   0.7296508   2.88578419 -0.54534334 -0.47522485
 -2.0265424   0.7289737 ]. 
Training complete taking 2277.660781145096 seconds. 
Discarding model... 

Training complete taking 56992.054822683334 total seconds. 
Now scoring model... 
Scoring complete taking 0.9640781879425049 seconds. 
Saved predicted values as A1-A1-CZ_Modified-Pauli-CRX_predicted_values.csv
Model scores: {'MSE_train': (1.0377334829690685,), 'R2_train': 0.857511380949645, 'MAE_train': 0.7822498472211953, 'MSE_test': 2.075275671219963, 'R2_test': 0.7931144022682624, 'MAE_test': 0.8570189196051317}. 
Saved model results as A1-A1-CZ_Modified-Pauli-CRX_results.json. 
