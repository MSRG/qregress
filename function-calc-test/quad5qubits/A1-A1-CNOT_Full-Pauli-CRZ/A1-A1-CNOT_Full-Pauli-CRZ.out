/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
/scratch/j/jacobsen/gjones/quad5qubits/quantum/Quantum.py:302: OptimizeWarning: Unknown solver options: tol
  opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback,
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin into X and y data. 
Loading dataset from /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin... 
Successfully loaded /scratch/j/jacobsen/gjones/quad5qubits/quadratic_test.bin into X and y data. 
Training model with dataset /scratch/j/jacobsen/gjones/quad5qubits/quadratic_train.bin 
 at time Mon Apr  1 16:01:54 2024... 
Training using 5-fold cross-validation. 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 16:02:11 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 16:11:17 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 16:11:34 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 16:20:25 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 16:21:56 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 16:28:59 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 16:29:15 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 16:36:46 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 16:44:20 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2579.8524057865143 seconds. 
Saving model as new best... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 16:45:10 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 16:53:55 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 16:54:11 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 17:03:00 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 17:04:31 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 17:11:29 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 17:11:45 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 17:19:10 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 17:26:47 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2546.6705543994904 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 17:27:38 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 17:36:20 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 17:36:37 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 17:45:31 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 17:47:01 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 17:54:02 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 17:54:18 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 18:01:47 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 18:09:23 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2560.3944017887115 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 18:10:19 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 18:19:20 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 18:19:37 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 18:28:24 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 18:30:10 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 18:37:26 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 18:37:44 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 18:45:07 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 18:52:37 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2590.020994901657 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.001, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 18:53:26 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 19:02:09 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 19:02:24 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 19:11:52 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 19:13:26 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 19:20:36 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 19:20:52 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 19:28:20 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 19:36:12 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2614.2584528923035 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 19:37:01 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 19:45:49 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 19:46:08 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 19:55:00 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 19:56:31 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 20:03:39 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 20:03:54 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 20:11:25 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 20:18:55 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2562.3369977474213 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 20:19:45 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 20:28:23 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 20:28:40 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 20:37:27 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 20:38:58 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 20:46:00 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 20:46:17 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 20:53:52 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 21:01:26 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2551.7830641269684 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 0.1}...

Working on 0.2 fold... 
[Mon Apr  1 21:02:16 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 21:11:07 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 21:11:26 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 21:20:13 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 21:21:44 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 21:28:59 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 21:29:17 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 21:37:08 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 21:44:39 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2594.305020570755 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 1}...

Working on 0.2 fold... 
[Mon Apr  1 21:45:29 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 21:54:07 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 21:54:25 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 22:03:14 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 22:04:45 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 22:11:43 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 22:12:00 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 22:19:28 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 22:27:01 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2540.9776861667633 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.01, 'beta': 10}...

Working on 0.2 fold... 
[Mon Apr  1 22:27:52 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 22:36:31 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 22:36:48 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 22:45:34 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 22:47:04 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 22:54:05 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 22:54:22 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 23:01:44 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 23:09:15 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2534.4672944545746 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.001}...

Working on 0.2 fold... 
[Mon Apr  1 23:10:05 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 23:18:51 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Mon Apr  1 23:19:07 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 23:27:53 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Mon Apr  1 23:29:23 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 23:36:22 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Mon Apr  1 23:36:38 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Mon Apr  1 23:44:03 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Mon Apr  1 23:51:37 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2541.0149190425873 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.01}...

Working on 0.2 fold... 
[Mon Apr  1 23:52:27 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 00:01:05 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 00:01:23 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 00:10:11 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 00:11:42 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 00:18:42 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 00:18:59 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 00:26:26 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 00:33:58 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2540.5928349494934 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 00:34:46 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 00:43:26 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 00:43:41 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 00:52:31 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 00:54:19 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 01:01:18 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 01:01:35 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 01:08:59 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 01:16:37 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2559.7597918510437 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 01:17:28 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 01:26:15 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 01:26:32 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 01:35:36 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 01:37:07 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 01:44:17 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 01:44:34 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 01:52:20 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 01:59:53 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2596.2764995098114 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 0.1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 02:00:44 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 02:09:24 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 02:09:42 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 02:18:27 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 02:19:58 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 02:26:57 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 02:27:14 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 02:34:40 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 02:42:28 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2555.700616836548 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 02:43:18 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 02:51:59 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 02:52:16 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 03:01:15 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 03:02:52 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 03:09:55 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 03:10:12 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 03:17:41 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 03:25:18 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2568.8612747192383 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 03:26:08 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 03:34:49 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 03:35:07 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 03:44:20 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 03:45:50 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 03:52:55 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 03:53:12 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 04:00:37 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 04:08:25 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2586.5229167938232 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 04:09:15 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 04:17:53 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 04:18:11 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 04:26:57 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 04:28:30 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 04:35:53 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 04:36:11 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 04:43:36 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 04:51:30 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2585.713546514511 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 04:52:21 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 05:01:31 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 05:01:48 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 05:10:56 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 05:12:27 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 05:19:28 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 05:19:46 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 05:27:14 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 05:34:49 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2598.7918479442596 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 1, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 05:35:38 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 05:44:37 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 05:44:54 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 05:53:40 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 05:55:11 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 06:03:01 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 06:03:18 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 06:11:06 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 06:18:54 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2644.2789742946625 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.001}...

Working on 0.2 fold... 
[Tue Apr  2 06:19:42 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 06:28:23 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 06:28:39 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 06:37:35 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 06:39:09 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 06:46:37 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 06:46:54 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 06:54:21 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 07:02:10 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2596.3306975364685 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.01}...

Working on 0.2 fold... 
[Tue Apr  2 07:03:00 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 07:11:37 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 07:11:55 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 07:20:42 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 07:22:39 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 07:29:38 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 07:29:55 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 07:37:27 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 07:45:21 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2591.474541902542 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 0.1}...

Working on 0.2 fold... 
[Tue Apr  2 07:46:10 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 07:54:53 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 07:55:09 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 08:04:24 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 08:06:00 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 08:13:00 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 08:13:16 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 08:20:42 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 08:28:16 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2574.8311955928802 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 1}...

Working on 0.2 fold... 
[Tue Apr  2 08:29:06 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 08:38:07 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 08:38:25 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 08:47:11 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 08:48:41 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 08:55:41 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 08:55:58 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 09:03:22 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 09:10:56 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2559.938896179199 seconds. 
Discarding model... 

Beginning training with hyperparameters {'alpha': 10, 'beta': 10}...

Working on 0.2 fold... 
[Tue Apr  2 09:11:45 2024]  Iteration number: 0 with current cost as 0.19680713604384892 and parameters 
[-2.70020139  2.26964142 -2.13564289 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61345783  1.14432445
  1.07414346 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522486
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 09:20:24 2024]  Iteration number: 50 with current cost as 0.17105013017296333 and parameters 
[-2.39121886  1.20073323 -3.85436989 -0.11653085  0.55388626 -2.77010893
  3.0685854   2.18960047  1.18551858 -1.06648324  1.4303101   1.1443232
  1.12284061 -1.87354595  0.72965063  2.88578417 -0.54534357 -0.47522565
 -2.02654215  0.72897245  1.60512535  2.8307714  -1.26456748 -0.25136218]. 
Working on 0.4 fold... 
[Tue Apr  2 09:20:41 2024]  Iteration number: 0 with current cost as 0.18243699413566206 and parameters 
[-2.72265063  2.26513418 -2.13434344 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61152739  1.14432445
  1.10021787 -1.8735468   0.7296508   2.88578419 -0.54534335 -0.47522485
 -2.02654241  0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 09:29:31 2024]  Iteration number: 50 with current cost as 0.1597391245797125 and parameters 
[-2.5106749   1.19399901 -4.02913923 -0.11652873  0.5538892  -2.77010663
  3.0685732   2.18959345  1.18552198 -1.06649185  1.37230512  1.14432649
  1.0028464  -1.87355014  0.7296413   2.88578488 -0.5453433  -0.47522457
 -2.02654671  0.72897514  1.60511901  2.83077149 -1.26456646 -0.25136082]. 
Working on 0.6 fold... 
[Tue Apr  2 09:31:02 2024]  Iteration number: 0 with current cost as 0.17965377140415068 and parameters 
[-2.66563403  2.27602939 -2.13640449 -0.11653103  0.55388708 -2.77010898
  3.06858498  2.18960145  1.18551998 -1.06648308  0.61888634  1.14432445
  1.0329862  -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 09:38:02 2024]  Iteration number: 50 with current cost as 0.15712426708849375 and parameters 
[-2.2082409   1.31812352 -3.67847633 -0.11653227  0.55388626 -2.77010916
  3.06858355  2.1896006   1.1855192  -1.06648362  1.33258995  1.14432349
  1.20884197 -1.87354844  0.72965044  2.88578287 -0.54534458 -0.47522446
 -2.02654235  0.72897404  1.60512668  2.83077152 -1.26456775 -0.25136171]. 
Working on 0.8 fold... 
[Tue Apr  2 09:38:18 2024]  Iteration number: 0 with current cost as 0.13264365022931293 and parameters 
[-2.63476622  2.30361241 -2.13734792 -0.11653103  0.55388708 -2.77010897
  3.06858498  2.18960145  1.18551998 -1.06648308  0.63601045  1.14432445
  0.99217868 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.72897369  1.60512664  2.83077107 -1.2645671  -0.25136105]. 
Working on 1.0 fold... 
[Tue Apr  2 09:45:50 2024]  Iteration number: 0 with current cost as 0.1419980829074226 and parameters 
[-2.6841763   2.29765712 -2.13511537 -0.11653102  0.55388708 -2.77010897
  3.06858499  2.18960145  1.18551999 -1.06648308  0.63293777  1.14432445
  1.04952541 -1.8735468   0.72965081  2.88578419 -0.54534335 -0.47522485
 -2.0265424   0.7289737   1.60512664  2.83077107 -1.2645671  -0.25136105]. 
[Tue Apr  2 09:53:36 2024]  Iteration number: 50 with current cost as 0.12727764815623893 and parameters 
[-2.44976408  1.24395412 -3.84198122 -0.11653109  0.55388615 -2.77010988
  3.06858434  2.18960069  1.18551904 -1.06648377  1.47818095  1.1443229
  0.98803609 -1.87354752  0.72964995  2.88578427 -0.54534289 -0.47522668
 -2.02654177  0.72897413  1.60512761  2.83077166 -1.26456748 -0.25136141]. 
Training complete taking 2561.1341264247894 seconds. 
Discarding model... 

Training complete taking 64336.29118800163 total seconds. 
Now scoring model... 
Scoring complete taking 0.8221070766448975 seconds. 
Saved predicted values as A1-A1-CNOT_Full-Pauli-CRZ_predicted_values.csv
Model scores: {'MSE_train': (3.262331820152274,), 'R2_train': 0.5520572829474903, 'MAE_train': 1.2090538237757091, 'MSE_test': 1.8155323281777132, 'R2_test': 0.8190083871144038, 'MAE_test': 1.1289009442854516}. 
Saved model results as A1-A1-CNOT_Full-Pauli-CRZ_results.json. 
