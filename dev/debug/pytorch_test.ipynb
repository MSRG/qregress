{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32edbc-0325-40d1-8ba4-5c7910985ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "import click\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import collections.abc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "# from qiskit_ibm_provider import IBMProvider\n",
    "\n",
    "from quantum.Evaluate import evaluate\n",
    "from settings import ANSATZ_LIST, ENCODER_LIST\n",
    "from quantum.Quantum import QuantumRegressor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e18698-ed78-4a27-b201-f41d660858b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings=\"./A2_HWE-CNOT/A2_HWE-CNOT.json\"\n",
    "train_set=\"./PCA5_0.8_Morgan_train.bin\"\n",
    "test_set=\"./PCA5_0.8_Morgan_test.bin\"\n",
    "scaler=\"./PCA5_0.8_Morgan_scaler.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a560f-03b8-4d69-970b-5bacd5a21090",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_set,'rb') as f:\n",
    "    TRAIN = joblib.load(f)\n",
    "\n",
    "with open(test_set,'rb') as f:\n",
    "    TEST = joblib.load(f)\n",
    "\n",
    "with open(scaler,'rb') as f:\n",
    "    SCALER = joblib.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5f42d-9d50-4b06-9a53-d1c5012e055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = TRAIN['X'],TEST['X'],TRAIN['y'],TEST['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0aee4a-cb7c-43d4-a084-f9fa2c66101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define custom Dataset\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.X = torch.from_numpy(features).float()\n",
    "        self.y = torch.from_numpy(targets).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# 5. Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = RegressionDataset(X_train, y_train)\n",
    "test_dataset = RegressionDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8e369-001f-441c-bb5a-68e9983888d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "OPTIMIZER = None\n",
    "SHOTS = None\n",
    "X_DIM = None\n",
    "BACKEND = None\n",
    "DEVICE = None\n",
    "SCALE_FACTORS = None\n",
    "ANSATZ = None\n",
    "ENCODER = None\n",
    "POSTPROCESS = None\n",
    "ERROR_MITIGATION = None\n",
    "LAYERS = None\n",
    "TOKEN = None\n",
    "HYPERPARAMETERS = None\n",
    "RE_UPLOAD_DEPTH = None\n",
    "MAX_ITER = None\n",
    "TOLERANCE = None\n",
    "NUM_QUBITS = None\n",
    "BATCH_SIZE = None\n",
    "NUM_CORES = None\n",
    "############################################\n",
    "# Utility functions\n",
    "############################################\n",
    "\n",
    "\n",
    "def parse_settings(settings_file):\n",
    "    with open(settings_file, 'r') as fp:\n",
    "        settings = json.load(fp)\n",
    "\n",
    "    global OPTIMIZER\n",
    "    OPTIMIZER = settings['OPTIMIZER']\n",
    "\n",
    "    global SHOTS\n",
    "    SHOTS = settings['SHOTS']\n",
    "                \n",
    "    global BACKEND\n",
    "    BACKEND = settings['BACKEND']\n",
    "\n",
    "    global DEVICE\n",
    "    DEVICE = settings['DEVICE']\n",
    "\n",
    "    global SCALE_FACTORS\n",
    "    SCALE_FACTORS = settings['SCALE_FACTORS']\n",
    "\n",
    "    global POSTPROCESS\n",
    "    POSTPROCESS = settings['POSTPROCESS']\n",
    "\n",
    "    global ERROR_MITIGATION\n",
    "    ERROR_MITIGATION = settings['ERROR_MITIGATION']\n",
    "\n",
    "    global LAYERS\n",
    "    LAYERS = settings['LAYERS']\n",
    "\n",
    "    global HYPERPARAMETERS\n",
    "    HYPERPARAMETERS = settings['HYPERPARAMETERS']\n",
    "    # f was removed from HYPERPARAMETERS, this ensures old settings files can still run.\n",
    "    if 'f' in HYPERPARAMETERS.keys():\n",
    "        _ = HYPERPARAMETERS.pop('f', None)\n",
    "\n",
    "    global RE_UPLOAD_DEPTH\n",
    "    RE_UPLOAD_DEPTH = settings['RE-UPLOAD_DEPTH']\n",
    "\n",
    "    global MAX_ITER\n",
    "    MAX_ITER = settings['MAX_ITER']\n",
    "\n",
    "    global TOLERANCE\n",
    "    try:\n",
    "        TOLERANCE = settings['TOLERANCE']\n",
    "    except KeyError:\n",
    "        TOLERANCE = None\n",
    "\n",
    "    global NUM_QUBITS\n",
    "    try:\n",
    "        NUM_QUBITS = settings['NUM_QUBITS']\n",
    "    except KeyError:\n",
    "        NUM_QUBITS = None\n",
    "\n",
    "    # classes aren't JSON serializable, so we store the key in the settings file and access it here.\n",
    "    global ANSATZ\n",
    "    ANSATZ = ANSATZ_LIST[settings['ANSATZ']]\n",
    "\n",
    "    global ENCODER\n",
    "    ENCODER = ENCODER_LIST[settings['ENCODER']]\n",
    "\n",
    "    global BATCH_SIZE\n",
    "    BATCH_SIZE = settings['BATCH_SIZE']\n",
    "    \n",
    "    global NUM_CORES\n",
    "    NUM_CORES = settings['NUM_CORES']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd62880e-1f05-498f-ac45-622c49275448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file):\n",
    "    print(f'Loading dataset from {file}... ')\n",
    "    data = joblib.load(file)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    global X_DIM\n",
    "    _, X_DIM = X.shape\n",
    "    print(f'Successfully loaded {file} into X and y data. ')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1952a86-1ce6-4a6d-9188-076a38a22c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_kwargs():\n",
    "    #  First have to apply specific ansatz settings: setting number of layers and the number of wires based on features\n",
    "    ANSATZ.layers = LAYERS\n",
    "    ANSATZ.set_wires(range(X_DIM))\n",
    "\n",
    "    kwargs = {\n",
    "        'encoder': ENCODER,\n",
    "        'variational': ANSATZ,\n",
    "        'num_qubits': X_DIM,\n",
    "        'optimizer': OPTIMIZER,\n",
    "        # 'optimizer': \"BFGS\",\n",
    "        'max_iterations': MAX_ITER,\n",
    "        'tol': TOLERANCE,\n",
    "        'device': DEVICE,\n",
    "        'shots': SHOTS,\n",
    "        'backend': BACKEND,\n",
    "        'postprocess': POSTPROCESS,\n",
    "        'error_mitigation': ERROR_MITIGATION,\n",
    "        'token': TOKEN,\n",
    "        're_upload_depth': RE_UPLOAD_DEPTH,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'njobs':NUM_CORES\n",
    "    }\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9295276-686b-4c66-be01-012b5d4cbb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addf0d4-50d8-42ae-abec-092915b26bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_dataset(train_set)\n",
    "parse_settings(settings)\n",
    "if DEVICE == 'qiskit.ibmq':\n",
    "    save_token(instance, token)\n",
    "\n",
    "global NUM_QUBITS\n",
    "global X_DIM\n",
    "if NUM_QUBITS is not None:\n",
    "    X_DIM = NUM_QUBITS\n",
    "elif X_DIM == 1:  # if X_DIM is None and num_qubits wasn't specified anywhere use a default value of 2.\n",
    "    NUM_QUBITS = 2\n",
    "    X_DIM = NUM_QUBITS\n",
    "\n",
    "kwargs = create_kwargs()\n",
    "title=False\n",
    "if title is None:\n",
    "    title = os.path.basename(settings)\n",
    "    title, _ = os.path.splitext(title)\n",
    "\n",
    "\n",
    "\n",
    "if test_set is not None:\n",
    "    X_test, y_test = load_dataset(test_set)\n",
    "else:\n",
    "    X_test, y_test = None, None\n",
    "\n",
    "scaler = joblib.load(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d338ad-9bbf-48e4-8962-17f6b06fa2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Define the model\n",
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(SimpleRegressor, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# input_dim = X_train.shape[1]\n",
    "# print(input_dim)\n",
    "# hidden_dim = 64\n",
    "# model = SimpleRegressor(input_dim, hidden_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3437f19-f2d2-437a-a4fd-d2e2e8f8ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in range(1,5):\n",
    "# device='qulacs.simulator'\n",
    "# num_qubits=5\n",
    "# device = qml.device(device, wires=num_qubits, expansion_strategy=\"device\")\n",
    "\n",
    "\n",
    "# re_upload_depth=3\n",
    "# n_layers=1\n",
    "# @qml.qnode(device, interface=\"torch\")\n",
    "# def circuit(inputs, weights):\n",
    "#     print(inputs.shape,weights.shape)\n",
    "#     for i in range(re_upload_depth):\n",
    "#         qml.AngleEmbedding(inputs, wires=range(num_qubits))\n",
    "#         qml.BasicEntanglerLayers(weights, wires=range(num_qubits))\n",
    "    \n",
    "#     return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # qml.draw_mpl(circuit,level=3)(train_dataset[0:][0],np.random.rand(n_layers,num_qubits))\n",
    "# # # plt.savefig('trash.png')\n",
    "# # plt.title(f\"{n_layers} {np.random.rand(n_layers,num_qubits).shape}\")\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# weight_shapes = {\"weights\": (n_layers, num_qubits)}\n",
    "# print(weight_shapes)\n",
    "# qlayer = qml.qnn.TorchLayer(circuit, weight_shapes)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = torch.nn.Sequential(*[qlayer]).to(device)\n",
    "# print(model)\n",
    "# print(model(train_dataset[0:][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f837e5-3646-4432-9d18-d7c4ccefea79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b5bae-3619-48a6-9616-2bbfcc466427",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits=5\n",
    "re_upload_depth=3\n",
    "# re_upload_depth=1\n",
    "LAYERS=1\n",
    "\n",
    "device='qulacs.simulator'\n",
    "device = qml.device(device, wires=num_qubits, expansion_strategy=\"device\")\n",
    "\n",
    "encoder=ENCODER_LIST['A2']\n",
    "\n",
    "variational=ANSATZ_LIST['HWE-CNOT']\n",
    "variational.set_wires(range(num_qubits))\n",
    "variational.layers = LAYERS\n",
    "\n",
    "\n",
    "num_params = variational.num_params * re_upload_depth\n",
    "generator = np.random.default_rng(12958234)\n",
    "initial_parameters = generator.uniform(-np.pi, np.pi, num_params)\n",
    "# @qml.qnode(device, interface=\"torch\")\n",
    "@qml.qnode(device, interface=\"torch\")\n",
    "def circuit(inputs, weights):\n",
    "    #  builds the circuit with the given encoder and variational circuits.\n",
    "    #  encoder and variational circuits must have only two required parameters, params/feats and wires\n",
    "    weights = weights.reshape(re_upload_depth,-1)\n",
    "    for i in range(re_upload_depth):\n",
    "        params = weights[i]\n",
    "        encoder(inputs, wires=range(num_qubits))\n",
    "        variational(params, wires=range(num_qubits))        \n",
    "    return qml.expval(qml.PauliZ(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deaac37-403b-4d5d-baa4-6e1e459faf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_shapes = {\"weights\": (LAYERS,initial_parameters.size)}\n",
    "print(weight_shapes)\n",
    "# qlayer = qml.qnn.TorchLayer(circuit, weight_shapes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class HybridModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qlayer = qml.qnn.TorchLayer(circuit, weight_shapes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return self.qlayer(x)\n",
    "\n",
    "model = HybridModel()\n",
    "\n",
    "\n",
    "# model = torch.nn.Sequential(*[qlayer]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb3262-6276-46ac-9450-285c207a30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset[0:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5b350-ce3f-41ee-bd4a-730f519c3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(train_loader.dataset[0:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488e26f-abec-4c19-a7a1-622a5eef74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21823a7-e17d-4a87-85c4-eae9faf2aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(qlayer.parameters(), lr=learning_rate)\n",
    "\n",
    "# 8. Training loop\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    test_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            test_running_loss += loss.item() * batch_X.size(0)\n",
    "    test_epoch_loss = test_running_loss / len(test_loader.dataset)\n",
    "    test_losses.append(test_epoch_loss)\n",
    "    \n",
    "    if (epoch+1) % 1 == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {epoch_loss:.4e} - Test Loss: {test_epoch_loss:.4e} - {abs(epoch_loss-test_epoch_loss):.4e}\")\n",
    "\n",
    "    if epoch>0 and abs(epoch_loss-test_epoch_loss)<=1e-6 and abs(np.mean(train_losses[-3:])-np.mean(test_losses[-3:]))<=1e-6:\n",
    "        print(\"Early stopping!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7a989-54bc-4993-b200-7535f710e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        outputs = torch.tensor([model(x) for x in batch_X])\n",
    "        predictions.extend(outputs.squeeze().tolist())\n",
    "        actuals.extend(batch_y.squeeze().tolist())\n",
    "\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "print(f\"\\nTest MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R$^2$: {r2:.4f}\")\n",
    "\n",
    "# 10. Visualization\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(actuals, predictions, alpha=0.6)\n",
    "plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'r--')  # Diagonal line\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs Actual Values')\n",
    "plt.show()\n",
    "\n",
    "# 11. Plot Loss Curves\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training and Test Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca914a1c-289d-4cbf-a533-b3aa46c0b6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
