{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5d930-ef1f-4de0-9d12-563898def350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install shap\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# SHAP\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b388753-da4e-4014-91f2-42cea2cf8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gaussian_kernel = RBF()\n",
    "\n",
    "# remove basic linear models (ridge, lasso, elastic) and expensive models (gpr)\n",
    "\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'elastic': ElasticNet(),\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'rfr': RandomForestRegressor(),\n",
    "    'grad': GradientBoostingRegressor(),\n",
    "    'svr': SVR(),\n",
    "    'krr': KernelRidge(),\n",
    "    'gpr': GaussianProcessRegressor()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'ridge': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10, 50, 100, 1000]\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': [1,5,10],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'rfr': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'grad': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'svr': {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.1, 0.01, 0.001]\n",
    "    },\n",
    "    'krr': {\n",
    "        'kernel': ['linear', 'laplacian', 'rbf'],\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001]\n",
    "    },\n",
    "    'gpr': {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "        'kernel': [gaussian_kernel]\n",
    "    },\n",
    "    'lasso': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    },\n",
    "    'elastic': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'l1_ratio': [0.2, 0.5, 0.8],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062da41-4233-49a3-adce-c3f54686a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regular(model):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    params\n",
    "    ------    \n",
    "    model: str\n",
    "        Model to test\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        Dictionary containing evaluation metrics\n",
    "\n",
    "    model: trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler\n",
    "    x_scaler = scaler((-1, 1))\n",
    "    y_scaler = scaler((-1, 1))    \n",
    "    X_train, X_test, y_train, y_test = x_scaler.fit_transform(X.loc[train]), x_scaler.transform(X.loc[test]), y_scaler.fit_transform(Y.loc[train].to_numpy()).flatten(), y_scaler.transform(Y.loc[test].to_numpy()).flatten()\n",
    "    scores,model=gridsearch(model,X_train, y_train,X_test,y_test,scaler)\n",
    "    \n",
    "    return scores,model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060d87a-3a33-4903-a996-81c91580c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pca(components,model):\n",
    "    \"\"\"\n",
    "    Test dimensionality reduction using principal component analysis (PCA)\n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    components: int\n",
    "        Number of dimensions to reduce too\n",
    "        \n",
    "    model: str\n",
    "        Model to test\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        Dictionary containing evaluation metrics\n",
    "\n",
    "    model: trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler\n",
    "    x_scaler = scaler((-1, 1))\n",
    "    y_scaler = scaler((-1, 1))\n",
    "    \n",
    "    pca = PCA(n_components=components)\n",
    "    X_train, X_test, y_train, y_test = pca.fit_transform(x_scaler.fit_transform(X.loc[train])), pca.transform(x_scaler.transform(X.loc[test])), y_scaler.fit_transform(Y.loc[train].to_numpy()).flatten(), y_scaler.transform(Y.loc[test].to_numpy()).flatten()\n",
    "    scores,model=gridsearch(model,X_train, y_train,X_test,y_test,y_scaler)\n",
    "    # with open(f'{components}_Morgan_train.bin','wb') as f:\n",
    "    #     joblib.dump({'X':X_train,'y':y_train},f)\n",
    "    # with open(f'{components}_Morgan_test.bin','wb') as f:\n",
    "    #     joblib.dump({'X':X_test,'y':y_test},f)\n",
    "    # with open(f'{components}_Morgan_scaler.bin','wb') as f:\n",
    "    #     joblib.dump(y_scaler,f)\n",
    "    return scores,model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e98a9c-7920-43d5-aae4-b2be45ff1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_shap(n_feats,model):\n",
    "    \"\"\"\n",
    "    Test dimensionality reduction using SHapely Additive Explanations (SHAP)\n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    n_feats: int\n",
    "        Number of best features to reduce too\n",
    "        \n",
    "    model: str\n",
    "        Model to test\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        Dictionary containing evaluation metrics\n",
    "    \n",
    "    model: trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler\n",
    "    x_scaler = scaler((-1, 1))\n",
    "    y_scaler = scaler((-1, 1))\n",
    "    \n",
    "    SHAPX=X.iloc[:,sorted_cols[-n_feats:]]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = x_scaler.fit_transform(SHAPX.loc[train].to_numpy()), x_scaler.transform(SHAPX.loc[test].to_numpy()), y_scaler.fit_transform(Y.loc[train].to_numpy()).flatten(), y_scaler.transform(Y.loc[test].to_numpy()).flatten()\n",
    "    \n",
    "    scores,model=gridsearch(model,X_train, y_train,X_test,y_test,y_scaler)\n",
    "    # with open(f'{n_feats}_SHAP_train.bin','wb') as f:\n",
    "    #     joblib.dump({'X':X_train,'y':y_train},f)\n",
    "    # with open(f'{n_feats}_SHAP_test.bin','wb') as f:\n",
    "    #     joblib.dump({'X':X_test,'y':y_test},f)\n",
    "    # with open(f'{n_feats}_SHAP_scaler.bin','wb') as f:\n",
    "    #     joblib.dump(y_scaler,f)\n",
    "        \n",
    "    return scores,model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86333ac7-9042-4a68-9c03-f00324b8ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model,X_tr, y_tr,X_tst,y_tst,scaler):\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV for a given model\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    model: str\n",
    "        Name of model\n",
    "\n",
    "    X_tr: np.array\n",
    "        X training\n",
    "\n",
    "    y_tr: np.array\n",
    "        Y Training\n",
    "\n",
    "    X_tst: np.array\n",
    "        X test\n",
    "\n",
    "    y_tst: np.array\n",
    "        y test\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        scored models\n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "    # Grab model and model parameters to perform gridsearchcv\n",
    "    current_model = models[model]\n",
    "    current_param_grid = param_grid[model]\n",
    "\n",
    "    grid_search = GridSearchCV(current_model, current_param_grid, cv=5,n_jobs=12,verbose=10000)\n",
    "\n",
    "    print(f'Now fitting {model}... ')\n",
    "\n",
    "    grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f'Completed fitting {model} in {time.time() - st:.4f} seconds. ')\n",
    "\n",
    "    # Take the best model and evaluate using known metrics\n",
    "    model=best_model\n",
    "    scores = {}\n",
    "    st = time.time()\n",
    "    print('Now scoring model... ')\n",
    "    y_tr_pred = model.predict(X_tr)\n",
    "    y_tst_pred = model.predict(X_tst)\n",
    "\n",
    "    y_tr = scaler.inverse_transform(y_tr.reshape(-1,1)).flatten()\n",
    "    y_tr_pred = scaler.inverse_transform(y_tr_pred.reshape(-1,1)).flatten()\n",
    "    y_tst = scaler.inverse_transform(y_tst.reshape(-1,1)).flatten()\n",
    "    y_tst_pred = scaler.inverse_transform(y_tst_pred.reshape(-1,1)).flatten()\n",
    "    # plt.scatter(y_tr,y_tr_pred)\n",
    "    # plt.scatter(y_tst,y_tst_pred)\n",
    "    # plt.scatter(y_tr, y_tr)\n",
    "    # plt.scatter(y_tst,y_tst)\n",
    "    # plt.show()\n",
    "            \n",
    "    scores['MSE_train'] = mean_squared_error(y_tr, y_tr_pred),\n",
    "    scores['R2_train'] = r2_score(y_tr, y_tr_pred)\n",
    "    scores['MAE_train'] = mean_absolute_error(y_tr, y_tr_pred)\n",
    "    \n",
    "    scores['MSE_test'] = mean_squared_error(y_tst, y_tst_pred)\n",
    "    scores['R2_test'] = r2_score(y_tst, y_tst_pred)\n",
    "    scores['MAE_test'] = mean_absolute_error(y_tst, y_tst_pred)\n",
    "    print(f\"Train R2 {scores['R2_train']:.4f}\")\n",
    "    print(f\"Test R2 {scores['R2_test']:.4f}\")\n",
    "    print(f\"Train MAE {scores['MAE_train']:.4f}\")\n",
    "    print(f\"Test MAE {scores['MAE_test']:.4f}\")\n",
    "    print()\n",
    "    return scores, best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe0f0f-18b9-4242-9c7b-af6f5d9abe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.read_csv(os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'database','y.csv.gz'), compression='gzip',index_col=0)\n",
    "\n",
    "X_path=os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'database',f'Morgan_sub.csv.gz')\n",
    "if os.path.exists(X_path):\n",
    "    X=pd.read_csv(X_path, compression='gzip',index_col=0)\n",
    "\n",
    "train,test=train_test_split(list(X.index), train_size=0.8,test_size=0.2,random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X.loc[train], X.loc[test], Y.loc[train].to_numpy().flatten(), Y.loc[test].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd29ed-20f3-4a71-a1cd-8344656ac835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9359039-03de-4a27-bfaf-0f2c482aec52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler\n",
    "x_scaler = scaler((-1, 1))\n",
    "y_scaler = scaler((-1, 1))\n",
    "\n",
    "model='rfr'\n",
    "n_feats=5\n",
    "components=5\n",
    "\n",
    "# # Normal\n",
    "scores,model=run_regular(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cb9e0-5def-406e-b953-ab43879e69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores).rename(index={0:'full'})\n",
    "scores_df['features'] = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a125d4a-2639-4e95-92ac-16c4ece0ac2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # SHAP\n",
    "explainer = shap.Explainer(model.predict, X_test,n_jobs=12,max_evals=X.shape[1]*2 + 1)\n",
    "shap_values = explainer(X_test)\n",
    "shap.plots.bar(shap_values,max_display=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a049db-1527-42f8-954f-2837889a3766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduced={}\n",
    "model='rfr'\n",
    "for i in [5,16]:\n",
    "    sorted_cols=np.argsort(np.mean(np.abs(shap_values.values),axis=0))\n",
    "    shap_scores,shap_model=test_shap(i,model)\n",
    "    \n",
    "    #PCA\n",
    "    pca_scores,pca_model=test_pca(i,model)\n",
    "\n",
    "    reduced[i]={'SHAP':shap_scores,'PCA':pca_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f231600-cdce-4a53-bb13-7b8108b2c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76d4c4-ada7-4265-8416-73461fa7148a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f99954-0173-4e93-ade0-2540515e0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfredfmt = []\n",
    "for k,v in reduced.items():\n",
    "    dfred = pd.DataFrame(v).T\n",
    "    dfred['features']=k\n",
    "    dfred.index = ['_'.join([j[0],str(j[1])]) for j in (list(zip(dfred.index,len(dfred.index)*[k])))]\n",
    "    dfredfmt.append(dfred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9dd764-e18c-4f66-b628-c849c7d7f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat(dfredfmt+[scores_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996df59c-e39c-47a1-b686-174f43df5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c40d2f-353a-4649-a3b6-3428b89e9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['set'] = [i.split('_')[0] if len(i.split('_'))>1 else i for i in data_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344d0be-cb15-47cf-8d18-ae5804131202",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_melt = data_df.rename(columns={'MAE_train':\"Train\",'MAE_test':'Test'}).melt(id_vars=['set','features'],value_vars=['Train','Test'])\n",
    "\n",
    "R2_melt = data_df.rename(columns={'R2_train':\"Train\",'R2_test':'Test'}).melt(id_vars=['set','features'],value_vars=['Train','Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037d636-7a08-4d58-8764-7f09b9b199c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=R2_melt,x='set',y='value',col='variable',hue='features',kind='bar',palette=sns.color_palette('Paired',6))\n",
    "g.set_axis_labels(\"Set\", \"R$^{2}$\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "g._legend.set_bbox_to_anchor((1.06, 0.5))  # Position legend to the right\n",
    "g._legend.set_frame_on(True)\n",
    "\n",
    "# Add labels over each bar\n",
    "for ax in g.axes.flat:\n",
    "    for bar in ax.patches:\n",
    "        height = bar.get_height()\n",
    "        if height!=0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height,\n",
    "                f'{height:.2f}',  # Format the label as desired\n",
    "                ha='center',\n",
    "                va='bottom'\n",
    "            )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.expanduser(\"~\"),'qregress/images/BSE/classical_features_MAE.png'),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2b1b4-e682-4d66-9dfa-bc1dde4621e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=MAE_melt,x='set',y='value',col='variable',hue='features',kind='bar',palette=sns.color_palette('Paired',6))\n",
    "g.set_axis_labels(\"Set\", \"Mean Absolute Error (kcal/mol)\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "# Add labels over each bar\n",
    "# Add labels over each bar\n",
    "for ax in g.axes.flat:\n",
    "    for bar in ax.patches:\n",
    "        height = bar.get_height()\n",
    "        if height!=0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height,\n",
    "                f'{height:.2f}',  # Format the label as desired\n",
    "                ha='center',\n",
    "                va='bottom'\n",
    "            )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.expanduser(\"~\"),'qregress/images/BSE/classical_features_MAE.png'),dpi=300,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python . (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
