{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67115fbb-34c5-4281-a97a-821d2fba9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install shap\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# SHAP\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f67d6c-4173-4aa7-a627-f8ca7f9874a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob(os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'database','*.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3c7bf-4598-4d8b-a13c-b275c3829059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776c485-4e86-4ebf-823f-d40fbf924167",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsize=[ 0.1,0.3, 0.5, 0.7,0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a1e7d-e689-43af-8ff7-2b77c338b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gaussian_kernel = RBF()\n",
    "\n",
    "# remove basic linear models (ridge, lasso, elastic) and expensive models (gpr)\n",
    "\n",
    "models = {\n",
    "    # 'ridge': Ridge(),\n",
    "    # 'lasso': Lasso(),\n",
    "    # 'elastic': ElasticNet(),\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'rfr': RandomForestRegressor(),\n",
    "    # 'grad': GradientBoostingRegressor(),\n",
    "    # 'svr': SVR(),\n",
    "    'krr': KernelRidge(),\n",
    "    # 'gpr': GaussianProcessRegressor()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'ridge': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10, 50, 100, 1000]\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': [1,5,10],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'rfr': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'grad': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'svr': {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.1, 0.01, 0.001]\n",
    "    },\n",
    "    'krr': {\n",
    "        'kernel': ['linear', 'laplacian', 'rbf'],\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001]\n",
    "    },\n",
    "    'gpr': {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "        'kernel': [gaussian_kernel]\n",
    "    },\n",
    "    'lasso': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    },\n",
    "    'elastic': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'l1_ratio': [0.2, 0.5, 0.8],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c94630-aba5-43bf-80a2-a0d7174983a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model,X_tr, y_tr,X_tst,y_tst):\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV for a given model\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    model: str\n",
    "        Name of model\n",
    "\n",
    "    X_tr: np.array\n",
    "        X training\n",
    "\n",
    "    y_tr: np.array\n",
    "        Y Training\n",
    "\n",
    "    X_tst: np.array\n",
    "        X test\n",
    "\n",
    "    y_tst: np.array\n",
    "        y test\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        scored models\n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "    # Grab model and model parameters to perform gridsearchcv\n",
    "    current_model = models[model]\n",
    "    current_param_grid = param_grid[model]\n",
    "\n",
    "    grid_search = GridSearchCV(current_model, current_param_grid, cv=5,n_jobs=-1)\n",
    "\n",
    "    print(f'Now fitting {model}... ')\n",
    "\n",
    "    grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f'Completed fitting {model} in {time.time() - st:.4f} seconds. ')\n",
    "\n",
    "    # Take the best model and evaluate using known metrics\n",
    "    model=best_model\n",
    "    scores = {}\n",
    "    st = time.time()\n",
    "    print('Now scoring model... ')\n",
    "    y_tr_pred = model.predict(X_tr)\n",
    "    y_tst_pred = model.predict(X_tst)\n",
    "\n",
    "    # plt.scatter(y_tr,y_tr_pred)\n",
    "    # plt.scatter(y_tst,y_tst_pred)\n",
    "    # plt.scatter(y_tr, y_tr)\n",
    "    # plt.scatter(y_tst,y_tst)\n",
    "    # plt.show()\n",
    "            \n",
    "    scores['MSE_train'] = mean_squared_error(y_tr, y_tr_pred),\n",
    "    scores['R2_train'] = r2_score(y_tr, y_tr_pred)\n",
    "    scores['MAE_train'] = mean_absolute_error(y_tr, y_tr_pred)\n",
    "    \n",
    "    scores['MSE_test'] = mean_squared_error(y_tst, y_tst_pred)\n",
    "    scores['R2_test'] = r2_score(y_tst, y_tst_pred)\n",
    "    scores['MAE_test'] = mean_absolute_error(y_tst, y_tst_pred)\n",
    "    print(f\"Train R2 {scores['R2_train']:.4f}\")\n",
    "    print(f\"Test R2 {scores['R2_test']:.4f}\")\n",
    "    print(f\"Train MAE {scores['MAE_train']:.4f}\")\n",
    "    print(f\"Test MAE {scores['MAE_test']:.4f}\")\n",
    "    print()\n",
    "    return scores, best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e389523-eb01-46c8-a286-90714b0ec83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.read_csv(os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'database','y.csv.gz'), compression='gzip',index_col=0)\n",
    "Reps=['CM', 'MACCS', 'PI', 'RDKit', 'Morgan']\n",
    "      # , 'SOAP']\n",
    "divisions=[\"AB\",\"sub\"]\n",
    "\n",
    "test_models_out={}\n",
    "for r in Reps:\n",
    "    test_models_out[r]={}\n",
    "    for d in divisions:\n",
    "        test_models_out[r][d]={}\n",
    "        print(f'Start: {r}_{d}')\n",
    "        X_path=os.path.join(os.path.dirname(os.path.dirname(os.getcwd())),'database',f'{r}_{d}.csv.gz')\n",
    "        if os.path.exists(X_path):\n",
    "            X=pd.read_csv(X_path, compression='gzip',index_col=0)\n",
    "            print(X.shape[1])\n",
    "            train,test=train_test_split(list(X.index), train_size=0.8,test_size=0.2,random_state=42)\n",
    "            X_train, X_test, y_train, y_test = X.loc[train].to_numpy(), X.loc[test].to_numpy(), Y.loc[train].to_numpy().flatten(), Y.loc[test].to_numpy().flatten()\n",
    "    \n",
    "            scoring={}\n",
    "            t0_init=time.perf_counter()\n",
    "            for m in models.keys():\n",
    "                t0=time.perf_counter()\n",
    "                scores,model=gridsearch(m,X_train, y_train,X_test,y_test)\n",
    "                tf=time.perf_counter()-t0\n",
    "                scores['timing']=tf\n",
    "                scoring[m]=scores\n",
    "                print(m,tf)\n",
    "            print(f\"Overall {time.perf_counter()-t0_init:.2f}\")\n",
    "            stat_df=pd.concat([pd.DataFrame.from_dict(v).rename(index={0:k}) for k,v in scoring.items()])\n",
    "            test_models_out[r][d]=stat_df\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3662af-3bee-4193-a963-a0377e5c1f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df=[]\n",
    "for k,v in test_models_out.items():\n",
    "    if k!='PI':\n",
    "        df=v['AB'][['R2_train','R2_test']].reset_index().melt(id_vars='index')\n",
    "        df['model']=len(df)*[k]\n",
    "        df['Feat']=['AB']*len(df)\n",
    "        df1=v['sub'][['R2_train','R2_test']].reset_index().melt(id_vars='index')\n",
    "        df1['model']=len(df1)*[k]\n",
    "        df1['Feat']=['sub']*len(df1)\n",
    "        results_df.append(pd.concat([df,df1],axis=0))\n",
    "    else:\n",
    "        df=v['AB'][['R2_train','R2_test']].reset_index().melt(id_vars='index')\n",
    "        df['model']=len(df)*[k]\n",
    "        df['Feat']=['AB']*len(df)   \n",
    "        results_df.append(df)\n",
    "\n",
    "results_df=pd.concat(results_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ade1c4-d1ef-43dc-a428-84a7f865a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models_out['Morgan']['sub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb27ff-0eb6-4a1b-b162-36d665af3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.facet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f760040f-11fe-4322-bb86-a2a9fa396953",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.catplot(data=results_df,x='model',hue='variable',y='value',col='index',row='Feat',kind='bar',palette=sns.color_palette('Paired',5),legend=True)\n",
    "\n",
    "# extract the matplotlib axes_subplot objects from the FacetGrid\n",
    "for ax in g.axes.ravel():\n",
    "    \n",
    "    # iterate through the axes containers\n",
    "    for c in ax.containers:\n",
    "        ax.bar_label(c, fmt='{:,.2f}')\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"classical_funcfit.png\",dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2133c3-0faa-490e-84ab-04beefdaf9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_shap(n_feats,model):\n",
    "    \"\"\"\n",
    "    Test dimensionality reduction using SHapely Additive Explanations (SHAP)\n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    n_feats: int\n",
    "        Number of best features to reduce too\n",
    "        \n",
    "    model: str\n",
    "        Model to test\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        Dictionary containing evaluation metrics\n",
    "    \n",
    "    model: trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    SHAPX=X.iloc[:,sorted_cols[-n_feats:]]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = SHAPX.loc[train].to_numpy(), SHAPX.loc[test].to_numpy(), Y.loc[train].to_numpy(), Y.loc[test].to_numpy()\n",
    "    scores,model=gridsearch(model,X_train, y_train,X_test,y_test)\n",
    "    return scores,model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a0115-7aa5-413c-bc8d-2a6a264cb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pca(components,model):\n",
    "    \"\"\"\n",
    "    Test dimensionality reduction using principal component analysis (PCA)\n",
    "    \n",
    "    params\n",
    "    ------\n",
    "    components: int\n",
    "        Number of dimensions to reduce too\n",
    "        \n",
    "    model: str\n",
    "        Model to test\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        Dictionary containing evaluation metrics\n",
    "\n",
    "    model: trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=components)\n",
    "    X_train, X_test, y_train, y_test = pca.fit_transform(X.loc[train]), pca.transform(X.loc[test]), Y.loc[train].to_numpy(), Y.loc[test].to_numpy()\n",
    "    scores,model=gridsearch(model,X_train, y_train,X_test,y_test)\n",
    "    with open(f'{components}_Morgan_train.bin','wb') as f:\n",
    "        joblib.dump({'X':X_train,'y':y_train},f)\n",
    "    with open(f'{components}_Morgan_test.bin','wb') as f:\n",
    "        joblib.dump({'X':X_test,'y':y_test},f)\n",
    "        \n",
    "    return scores,model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be99e60-327b-4f92-b622-cd08d1d74484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regular(model):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    params\n",
    "    ------    \n",
    "    model: str\n",
    "        Model to test\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        Dictionary containing evaluation metrics\n",
    "\n",
    "    model: trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = X.loc[train], X.loc[test], Y.loc[train].to_numpy(), Y.loc[test].to_numpy()\n",
    "    scores,model=gridsearch(model,X_train, y_train,X_test,y_test)\n",
    "    \n",
    "    return scores,model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2799bab-8cd2-4491-b71f-51f2670ae906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model='rfr'\n",
    "n_feats=5\n",
    "components=5\n",
    "\n",
    "# # Normal\n",
    "scores,model=run_regular(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c4b45-74ed-4d67-aff7-1f232c5eec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22635b01-f956-4975-8733-16afe5b90b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # SHAP\n",
    "explainer = shap.Explainer(model.predict, X_test,n_jobs=-1,max_evals=2048)\n",
    "shap_values = explainer(X)\n",
    "shap.plots.bar(shap_values,max_display=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415d0b0-8f0f-4925-8efb-ceba19d9f748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduced={}\n",
    "model='rfr'\n",
    "for i in [5,16]:\n",
    "    sorted_cols=np.argsort(np.mean(np.abs(shap_values.values),axis=0))\n",
    "    shap_scores,shap_model=test_shap(i,model)\n",
    "    \n",
    "    #PCA\n",
    "    pca_scores,pca_model=test_pca(i,model)\n",
    "\n",
    "    reduced[i]={'SHAP':shap_scores,'PCA':pca_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e57c1-188d-4afe-8379-5ed393bef4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
    "pal=sns.color_palette('Paired',4)\n",
    "for idx,(k,v) in enumerate(reduced.items()):\n",
    "    df=pd.DataFrame.from_dict(v).loc[['R2_train','R2_test']].reset_index().melt(id_vars='index') \n",
    "    if idx==0:\n",
    "        ax[idx]=sns.barplot(data=df,x='variable',hue='index',y='value',palette=[pal[idx],pal[idx+1]],ax=ax[idx])\n",
    "    else:\n",
    "        ax[idx]=sns.barplot(data=df,x='variable',hue='index',y='value',palette=[pal[2],pal[3]],ax=ax[idx])\n",
    "\n",
    "    for container in ax[idx].containers:\n",
    "        print(container)\n",
    "        ax[idx].bar_label(container, fmt='{:,.2f}')\n",
    "    ax[idx].set_title(f\"{k} Features\")\n",
    "    ax[idx].set_xlabel('Featurization')\n",
    "    ax[idx].set_ylabel(\"R$^{2}$\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Feat_redR2.png',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6743fc-2341-4fbf-ae60-cfccf69ed84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
