{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5c5cc-5a14-4c41-ab2f-aa7a63465d8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install pennylane pennylane-qiskit pennylane-qulacs --force-reinstall\n",
    "from glob import glob\n",
    "from pennylane import numpy as np\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit_ibm_runtime.fake_provider import FakeQuebec\n",
    "from quantum.Evaluate import evaluate\n",
    "from scipy.optimize import minimize, basinhopping\n",
    "from settings import ANSATZ_LIST, ENCODER_LIST\n",
    "from shutil import copy,SameFileError\n",
    "from sklearn.exceptions import InconsistentVersionWarning\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from quantum.circuits.Encoders import iqp_embedding\n",
    "from tqdm import tqdm\n",
    "import click\n",
    "import collections.abc\n",
    "import itertools\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "import time\n",
    "import dill\n",
    "from pennylane_qiskit import qiskit_session\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe10d30-eea3-4a35-9708-b694f2329628",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "optimization_level = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ad851-ad2d-4366-85eb-f33344746ebb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasinBounds:\n",
    "    def __init__(self, xmax=np.pi, xmin=-np.pi):\n",
    "        self.xmax = xmax\n",
    "        self.xmin = xmin\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        x = kwargs[\"x_new\"]\n",
    "        tmax = bool(np.all(x <= self.xmax))\n",
    "        tmin = bool(np.all(x >= self.xmin))\n",
    "        return tmax and tmin\n",
    "\n",
    "\n",
    "class QuantumRegressor:\n",
    "    \"\"\"\n",
    "    Machine learning model based on quantum circuit learning.\n",
    "\n",
    "    Methods\n",
    "    ------\n",
    "    fit(x, y, initial_parameters=None, detailed_results=False, load_state=None, callback_interval=None)\n",
    "        Fits the model instance to the given x and y data.\n",
    "    predict(x)\n",
    "        Predicts y values for a given array of input data based on previous training.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder,\n",
    "            variational,\n",
    "            num_qubits,\n",
    "            optimization_level,\n",
    "            optimizer: str = 'COBYLA',\n",
    "            max_iterations: int = None,\n",
    "            tol: float = 1e-8,\n",
    "            device: str = 'default.qubit',\n",
    "            backend: str = None,\n",
    "            postprocess: str = None,\n",
    "            error_mitigation=None,\n",
    "            shots: int = None,\n",
    "            re_upload_depth: int = 1,\n",
    "            f: float = 1.,\n",
    "            alpha: float = 0.,\n",
    "            beta: float = 0,\n",
    "            token: str = None,\n",
    "            batch_size: int=None,\n",
    "            njobs: int=None):\n",
    "        self.hyperparameters = {'f': f, 'alpha': alpha, 'beta': beta}\n",
    "        self.callback_interval = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.params = None\n",
    "        self._batch_size = batch_size\n",
    "        self._re_upload_depth = re_upload_depth\n",
    "        self.error_mitigation = error_mitigation\n",
    "        self.num_qubits = num_qubits\n",
    "        self.max_iterations = max_iterations\n",
    "        if postprocess == 'None':\n",
    "            postprocess = None\n",
    "        self.postprocess = postprocess\n",
    "        self.encoder = encoder\n",
    "        self.variational = variational\n",
    "        self._set_device(device, backend, shots, token)\n",
    "        self._set_optimizer(optimizer)\n",
    "        self._tol = tol\n",
    "        self._build_qnode()\n",
    "        self.fit_count = 0\n",
    "        self.cached_results = {}\n",
    "        self.njobs = njobs \n",
    "        self.optimization_level = optimization_level\n",
    "        print(self.njobs)\n",
    "        os.environ[\"OMP_NUM_THREADS\"] = str(self.njobs)\n",
    "        print(os.environ[\"OMP_NUM_THREADS\"])\n",
    "    def _set_device(self, device, backend, shots, token=None):\n",
    "        #  sets the models quantum device. If using IBMQ asks for proper credentials\n",
    "        if device == 'qiskit.remote':\n",
    "            print('Running on IBMQ Runtime')\n",
    "            service = QiskitRuntimeService(channel=\"ibm_quantum\", instance='pinq-quebec-hub/univ-toronto/default')\n",
    "            self._backend = service.least_busy(operational=True, simulator=False, min_num_qubits=self.num_qubits)\n",
    "            if self.error_mitigation == None:\n",
    "                self.device = qml.device(device, wires=127, backend=self._backend,shots=shots,resilience_level=0,seed_transpiler=42)\n",
    "            elif self.error_mitigation == 'TREX':\n",
    "                self.device = qml.device(device, wires=127, backend=self._backend,shots=shots,resilience_level=1,seed_transpiler=42)         \n",
    "            \n",
    "        elif device == 'qiskit.aer' and backend == \"fake\":\n",
    "            # Example based on https://pennylane.ai/qml/demos/tutorial_error_mitigation/\n",
    "            \n",
    "            # A simple test for state vector simulation self.device = qml.device(device, backend=AerSimulator(), wires=self.num_qubits,shots=shots)\n",
    "            service = QiskitRuntimeService(channel=\"ibm_quantum\", instance='pinq-quebec-hub/univ-toronto/default')\n",
    "            device_backend = service.least_busy(operational=True, simulator=False, min_num_qubits=self.num_qubits)\n",
    "            self._backend=AerSimulator.from_backend(device_backend)\n",
    "            if self.error_mitigation == 'TREX':\n",
    "                self.device = qml.device(\"qiskit.remote\", backend=self._backend, wires=127,shots=shots,resilience_level=1,optimization_level=self.optimization_level,seed_transpiler=42)\n",
    "            else:\n",
    "                self.device = qml.device(\"qiskit.remote\", backend=self._backend, wires=127,shots=shots,resilience_level=0,seed_transpiler=42)\n",
    "            print(dir(self.device))\n",
    "            # self.device.set_transpile_args(**{'resilience_level': 0})            \n",
    "            # device_backend = FakeQuebec()\n",
    "            # backend = AerSimulator.from_backend(device_backend)\n",
    "            # print(backend.name)\n",
    "            # noise_model = NoiseModel.from_backend(backend)\n",
    "            # self._backend=backend\n",
    "            # self.device = qml.device(device, backend=self._backend, wires=self.num_qubits, noise_model=noise_model,shots=shots)\n",
    "            # self.device.set_transpile_args(**{'resilience_level': 0})\n",
    "\n",
    "\n",
    "            # if self.error_mitigation == 'TREX':\n",
    "            #     self.device.set_transpile_args(**{'resilience_level': 1})\n",
    "        else:\n",
    "            self.device = qml.device(device, wires=self.num_qubits, shots=shots)\n",
    "\n",
    "    def _set_optimizer(self, optimizer):\n",
    "        #  sets the desired optimizer. SPSA is not available in scipy and has to be handled separately in fitting\n",
    "        if optimizer == 'SPSA':\n",
    "            self.use_scipy = False\n",
    "            self.optimizer = optimizer\n",
    "        elif optimizer == 'BasinHopping':\n",
    "            self.use_scipy = False\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.use_scipy = True\n",
    "            self.optimizer = optimizer\n",
    "\n",
    "    def _circuit(self, features, parameters):\n",
    "        #  builds the circuit with the given encoder and variational circuits.\n",
    "        #  encoder and variational circuits must have only two required parameters, params/feats and wires\n",
    "        for i in range(self._re_upload_depth):\n",
    "            params = parameters[self._num_params() * i:self._num_params() * (i + 1)]\n",
    "            self.encoder(features, wires=range(self.num_qubits))\n",
    "            # GMJ: 11/26/24 a hack to get this to work for Full-CRZ/X\n",
    "            try:\n",
    "                self.variational(params, wires=range(self.num_qubits))\n",
    "            except:\n",
    "                self.variational(params, wires=range(self.num_qubits))\n",
    "\n",
    "        if self.postprocess is None:\n",
    "            return qml.expval(qml.PauliZ(0))\n",
    "        elif self.postprocess is not None:\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(self.num_qubits)]\n",
    "\n",
    "    def _build_qnode(self):\n",
    "        #  builds QNode from device and circuit using mitiq error mitigation if specified.\n",
    "        self.qnode = qml.QNode(self._circuit, self.device)\n",
    "\n",
    "    def _cost(self, parameters):\n",
    "        # GMJ Batch loss\n",
    "        if self._batch_size is not None and self.njobs is not None:\n",
    "            batch_partitions = np.array_split(np.random.randint(0, len(self.x), len(self.x)),len(self.x)//self._batch_size)\n",
    "            base_cost = np.mean(joblib.Parallel(n_jobs=self.njobs,verbose=0)(joblib.delayed(mean_squared_error)(self.y[i], self.predict(self.x[i], params=parameters)) for i in tqdm(batch_partitions,desc=f\"Cost (Batches {len(batch_partitions)} of size {self._batch_size})\")))\n",
    "        else:\n",
    "            pred = np.array(self.predict(self.x, params=parameters)).reshape(*self.y.shape)\n",
    "            base_cost = mean_squared_error(self.y, pred)        \n",
    "            \n",
    "        \n",
    "        if self.postprocess is None or self.postprocess == 'None' or self.postprocess == 'simple':\n",
    "            return base_cost\n",
    "        elif self.postprocess == 'ridge':\n",
    "            extra_params = parameters[-self.num_qubits:]\n",
    "            alpha = self.hyperparameters['alpha']\n",
    "\n",
    "            return base_cost + alpha * np.linalg.norm(extra_params)\n",
    "        elif self.postprocess == 'lasso':\n",
    "            extra_params = parameters[-self.num_qubits:]\n",
    "            alpha = self.hyperparameters['alpha']\n",
    "\n",
    "            l1_norm = 0\n",
    "            for param in extra_params:\n",
    "                l1_norm += np.abs(param)\n",
    "\n",
    "            return base_cost + alpha * l1_norm\n",
    "        elif self.postprocess == 'elastic':\n",
    "            extra_params = parameters[-self.num_qubits:]\n",
    "            alpha = self.hyperparameters['alpha']\n",
    "            beta = self.hyperparameters['beta']\n",
    "\n",
    "            l1_norm = 0\n",
    "            for param in extra_params:\n",
    "                l1_norm += np.abs(param)\n",
    "\n",
    "            return base_cost + beta * (alpha * l1_norm + (1 - alpha) * np.linalg.norm(extra_params))\n",
    "        else:\n",
    "            raise NotImplementedError(f'The given postprocess type {self.postprocess} is not implemented. ')\n",
    "\n",
    "    def _cost_wrapper(self, parameters):\n",
    "        # caches the results from the cost function, so they don't have to be recalculated if they get called again i.e.\n",
    "        # during the callback function for logging.\n",
    "        param_hash = hash(parameters.data.tobytes())\n",
    "        if param_hash in self.cached_results:\n",
    "            cost = self.cached_results[param_hash]\n",
    "        else:\n",
    "            cost = self._cost(parameters)\n",
    "            self.cached_results[param_hash] = cost\n",
    "\n",
    "        cost = np.array(cost)\n",
    "        return cost\n",
    "\n",
    "    def _num_params(self):\n",
    "        #  computes the number of parameters required for the implemented variational circuit\n",
    "        num_params = self.variational.num_params\n",
    "        return num_params\n",
    "\n",
    "    def _callback(self, xk):\n",
    "        cost_at_step = self._cost_wrapper(xk)            \n",
    "        if self.fit_count % 1 == 0:\n",
    "            print(f'[{time.asctime()}]  Iteration number: {self.fit_count} with current cost as {cost_at_step} and '\n",
    "                  f'parameters \\n{xk}. ')\n",
    "        filename = 'model_log.csv'\n",
    "        log = f'{time.asctime()},{self.fit_count},{cost_at_step},{xk}'\n",
    "        with open(filename, 'a') as outfile:\n",
    "            outfile.write(log)\n",
    "            outfile.write('\\n')\n",
    "        self.fit_count += 1\n",
    "        self._save_partial_state(xk)\n",
    "\n",
    "    def _save_partial_state(self, param_vector, force=False):\n",
    "        # saves every call to a bin file able to be loaded later by calling fit with load_state set to filename\n",
    "        interval = self.callback_interval\n",
    "        if interval is None:\n",
    "            interval = 5\n",
    "        if self.fit_count % interval == 0 or force:\n",
    "            partial_results = {\n",
    "                'parameters': np.array(param_vector),\n",
    "                'iterations': self.fit_count\n",
    "            }\n",
    "            if force is True and os.path.exists('partial_state_model.bin'):\n",
    "                outfile = 'final_state_model.bin'\n",
    "                os.remove('partial_state_model.bin')\n",
    "            else:\n",
    "                outfile = 'partial_state_model.bin'\n",
    "            \n",
    "            joblib.dump(partial_results, outfile)\n",
    "\n",
    "    def _load_partial_state(self, infile):\n",
    "        print('Loading partial state from file ' + infile)\n",
    "        partial_state = joblib.load(infile)\n",
    "        if type(partial_state) == dict:\n",
    "            param_vector = partial_state['parameters']\n",
    "            iteration = partial_state['iterations']\n",
    "            print('Loaded parameter_vector as', param_vector)\n",
    "            return param_vector, iteration\n",
    "        else:\n",
    "            print('Outdated partial file detected! Unexpected behaviour may occur.')\n",
    "            param_vector = partial_state\n",
    "            print('Loaded parameter_vector as', param_vector)\n",
    "        return param_vector, 0\n",
    "\n",
    "    def fit(self, x, y, initial_parameters=None, detailed_results=False, load_state=None, callback_interval=None):\n",
    "        \"\"\"\n",
    "        Fits the current model to the given x and y data. If no initial parameters are given then random ones will be\n",
    "        chosen. Optimal parameters are stored in the model for use in predict and returned in this function.\n",
    "\n",
    "        :param x: np.array\n",
    "            x data to fit\n",
    "        :param y: np.array\n",
    "            y data to fit\n",
    "        :param initial_parameters: list, optional\n",
    "            initial parameters to start optimizer\n",
    "        :param detailed_results: bool, optional\n",
    "            whether to return detailed results of optimization or just parameters\n",
    "        :param load_state: str, optional\n",
    "            file to load partial fit data from\n",
    "        :param callback_interval: int, optional\n",
    "            how often to save the optimization steps to file\n",
    "        :return:\n",
    "            returns the optimal parameters found by optimizer. If detailed_results=True and optimizer is scipy, then\n",
    "            will be of type scipy optimizer results stored in dictionary.\n",
    "        \"\"\"\n",
    "        self.fit_count = 0\n",
    "        with open('model_log.csv', 'w') as outfile:\n",
    "            outfile.write('Time,Iteration,Cost,Parameters')\n",
    "            outfile.write('\\n')\n",
    "        self.callback_interval = callback_interval\n",
    "\n",
    "        if load_state is not None:\n",
    "            param_vector, self.fit_count = self._load_partial_state(load_state)\n",
    "            initial_parameters = param_vector\n",
    "        elif initial_parameters is None:\n",
    "            num_params = self._num_params() * self._re_upload_depth\n",
    "            generator = np.random.default_rng(12958234)\n",
    "            initial_parameters = generator.uniform(-np.pi, np.pi, num_params)\n",
    "            if self.postprocess is not None:\n",
    "                additional_num_params = self.num_qubits\n",
    "                additional_params = generator.uniform(-1, 1, additional_num_params)\n",
    "                initial_parameters = np.concatenate((initial_parameters, additional_params))\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        params = initial_parameters\n",
    "            \n",
    "        try:\n",
    "            with qiskit_session(self.device) as session:\n",
    "                print(\"Session details: \",session)\n",
    "                if self.use_scipy:\n",
    "                    options = {\n",
    "                        'maxiter': self.max_iterations - self.fit_count,\n",
    "                        'tol': self._tol,\n",
    "                        'disp': True\n",
    "                    }\n",
    "                    opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback, options=options)\n",
    "                    self.params = opt_result['x']\n",
    "                elif self.optimizer == 'BasinHopping':\n",
    "                    minimizer_kwargs = {\"method\": \"BFGS\"}\n",
    "                    opt_result = basinhopping(self._cost_wrapper, x0=params, minimizer_kwargs=minimizer_kwargs,\n",
    "                                              accept_test=BasinBounds(xmax=np.pi, xmin=-np.pi), niter=self.max_iterations,\n",
    "                                              callback=self._callback)\n",
    "                    self.params = opt_result['x']\n",
    "                else:\n",
    "           \n",
    "                    opt = qml.SPSAOptimizer(maxiter=self.max_iterations)\n",
    "                    cost = []\n",
    "                    for idx,_ in enumerate(range(self.max_iterations)):\n",
    "                        params, temp_cost = opt.step_and_cost(self._cost_wrapper, params)\n",
    "                        cost.append(temp_cost)\n",
    "                        self._callback(params)\n",
    "        \n",
    "                        if idx>0 and abs(cost[idx]-cost[idx-1])<=self._tol and abs(np.mean(cost[-3:])-temp_cost)<=self._tol:\n",
    "                            print(\"Early stopping!\")\n",
    "                            break\n",
    "                            \n",
    "                    opt_result = [params, cost]\n",
    "                    self.params = params                    \n",
    "\n",
    "        except:\n",
    "            if self.use_scipy:\n",
    "                options = {\n",
    "                    'maxiter': self.max_iterations - self.fit_count,\n",
    "                    'tol': self._tol,\n",
    "                    'disp': True\n",
    "                }\n",
    "                opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback, options=options)\n",
    "                self.params = opt_result['x']\n",
    "            elif self.optimizer == 'BasinHopping':\n",
    "                minimizer_kwargs = {\"method\": \"BFGS\"}\n",
    "                opt_result = basinhopping(self._cost_wrapper, x0=params, minimizer_kwargs=minimizer_kwargs,\n",
    "                                          accept_test=BasinBounds(xmax=np.pi, xmin=-np.pi), niter=self.max_iterations,\n",
    "                                          callback=self._callback)\n",
    "                self.params = opt_result['x']\n",
    "            else:\n",
    "       \n",
    "                opt = qml.SPSAOptimizer(maxiter=self.max_iterations)\n",
    "                cost = []\n",
    "                for idx,_ in enumerate(range(self.max_iterations)):\n",
    "                    params, temp_cost = opt.step_and_cost(self._cost_wrapper, params)\n",
    "                    cost.append(temp_cost)\n",
    "                    self._callback(params)\n",
    "    \n",
    "                    if idx>0 and abs(cost[idx]-cost[idx-1])<=self._tol and abs(np.mean(cost[-3:])-temp_cost)<=self._tol:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                        \n",
    "                opt_result = [params, cost]\n",
    "                self.params = params                    \n",
    "            \n",
    "\n",
    "        self._save_partial_state(params, force=True)\n",
    "        if detailed_results:\n",
    "            for key, value in opt_result.items():\n",
    "                if type(value) is np.ndarray:\n",
    "                    value = value.tolist()\n",
    "                    for i, x in enumerate(value):\n",
    "                        if type(x) is np.bool_:\n",
    "                            value[i] = bool(x)\n",
    "                    opt_result[key] = value\n",
    "                elif type(value) is np.bool_:\n",
    "                    value = bool(value)\n",
    "                    opt_result[key] = value\n",
    "            with open('detailed_results.json', 'w') as outfile:\n",
    "                try:\n",
    "                    json.dump(opt_result, outfile)\n",
    "                except:\n",
    "                    print('Could not dump detailed results. Not json serializable. ')\n",
    "        return self.params\n",
    "\n",
    "    def predict(self, x, params=None,evaluate=False):\n",
    "        \"\"\"\n",
    "        Predicts a set of output data given a set of input data x using the trained parameters found with fit\n",
    "\n",
    "        :param x: np.array\n",
    "            x data to predict outputs of in the model\n",
    "        :param params: list\n",
    "            optional parameters to use in prediction, used for internal cost functions.\n",
    "        :raises ValueError:\n",
    "            if fit is not first called then raises error explaining that the model must first be trained\n",
    "        :return: np.ndarray\n",
    "            predicted values corresponding to each datapoint in x\n",
    "        \"\"\"\n",
    "\n",
    "        if evaluate==True:\n",
    "            try:\n",
    "                with qiskit_session(self.device) as session:\n",
    "                    print(\"Session details: \",session)\n",
    "                    f = self.hyperparameters['f']\n",
    "                    if params is None:\n",
    "                        # if no parameters are passed then we are predicting the fitted model, so we use the stored parameters.\n",
    "                        params = self.params\n",
    "            \n",
    "                    if self.postprocess is None:\n",
    "                        return [f * self.qnode(features=features, parameters=params) for features in tqdm(x,desc=\"Predict\")]\n",
    "                    else:\n",
    "                        return [np.dot(f * np.array(self.qnode(features=features, parameters=params[:-self.num_qubits])),params[-self.num_qubits:]) for features in x]                 \n",
    "            except:\n",
    "                f = self.hyperparameters['f']\n",
    "                if params is None:\n",
    "                    # if no parameters are passed then we are predicting the fitted model, so we use the stored parameters.\n",
    "                    params = self.params\n",
    "        \n",
    "                if self.postprocess is None:\n",
    "                    return [f * self.qnode(features=features, parameters=params) for features in tqdm(x,desc=\"Predict\")]\n",
    "                else:\n",
    "                    return [np.dot(f * np.array(self.qnode(features=features, parameters=params[:-self.num_qubits])),params[-self.num_qubits:]) for features in x]\n",
    "                \n",
    "\n",
    "        else:\n",
    "            f = self.hyperparameters['f']\n",
    "            if params is None:\n",
    "                # if no parameters are passed then we are predicting the fitted model, so we use the stored parameters.\n",
    "                params = self.params\n",
    "    \n",
    "            if self.postprocess is None:\n",
    "                return [f * self.qnode(features=features, parameters=params) for features in tqdm(x,desc=\"Predict\")]\n",
    "            else:\n",
    "                return [np.dot(f * np.array(self.qnode(features=features, parameters=params[:-self.num_qubits])),params[-self.num_qubits:]) for features in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871d989-1536-46cb-bedd-1351a0090678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_1d(model, X_train, X_test, y_train, y_test, plot=True, title=\"\"):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    scores = {'MSE_train': mean_squared_error(y_train, y_train_pred),\n",
    "              'MSE_test': mean_squared_error(y_test, y_test_pred),\n",
    "              'R2_train': r2_score(y_train, y_train_pred),\n",
    "              'R2_test': r2_score(y_test, y_test_pred)\n",
    "              }\n",
    "    if plot:\n",
    "        plt.title(title)\n",
    "        plt.scatter(X_train, y_train_pred, color='b', label='Train', s=10)\n",
    "        plt.scatter(X_test, y_test_pred, color='orange', label='Test', s=10)\n",
    "        plt.scatter(X_train, y_train, color='green', label='Data', s=10)\n",
    "        plt.scatter(X_test, y_test, color='green', s=10)\n",
    "        plt.legend()\n",
    "    return scores\n",
    "\n",
    "\n",
    "def evaluate(model, X_train, y_train, X_test=None, y_test=None, plot: bool = False, title: str = 'defult',\n",
    "             y_scaler=None):\n",
    "    scores = {}\n",
    "    st = time.time()\n",
    "    print('Now scoring model... ')\n",
    "    y_train_pred = np.array(model.predict(X_train,evaluate=True))\n",
    "    y_train_pred = y_scaler.inverse_transform(y_train_pred.reshape(-1, 1))\n",
    "    y_train = y_scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "    scores['MSE_train'] = mean_squared_error(y_train, y_train_pred),\n",
    "    scores['R2_train'] = r2_score(y_train, y_train_pred)\n",
    "    scores['MAE_train'] = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    y_test_pred = None\n",
    "    y_test = y_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    if y_test is not None:\n",
    "        y_test_pred = np.array(model.predict(X_test,evaluate=True))\n",
    "        y_test_pred = y_scaler.inverse_transform(y_test_pred.reshape(-1, 1))\n",
    "        scores['MSE_test'] = mean_squared_error(y_test, y_test_pred)\n",
    "        scores['R2_test'] = r2_score(y_test, y_test_pred)\n",
    "        scores['MAE_test'] = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        if y_test_pred is not None:\n",
    "            plt.scatter(y_test, y_test_pred, color='b', s=10, label=f'Test, MAE = {scores[\"MAE_test\"]:.2f}')\n",
    "        plt.scatter(y_train, y_train_pred, color='r', s=10, label=f'Train, MAE = {scores[\"MAE_train\"]:.2f}')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.xlabel('Actual')\n",
    "        plt.axis('scaled')\n",
    "\n",
    "        max_val = max(max(plt.xlim()), max(plt.ylim()))\n",
    "        plt.xlim((0, max_val))\n",
    "        plt.ylim((0, max_val))\n",
    "\n",
    "        x_min, x_max = plt.xlim()\n",
    "        y_min, y_max = plt.ylim()\n",
    "        plt.plot([x_min, x_max], [y_min, y_max], 'k--', alpha=0.2, label='y=x')\n",
    "        plt.legend()\n",
    "        plt.savefig(title+'_plot.svg')\n",
    "\n",
    "        if X_test.shape[1] == 1:\n",
    "            plt.figure()\n",
    "            plt.title(title)\n",
    "            plt.scatter(X_train, y_train_pred, color='b', label='Train', s=10)\n",
    "            plt.scatter(X_test, y_test_pred, color='orange', label='Test', s=10)\n",
    "            plt.scatter(X_train, y_train, color='green', label='Data', s=10)\n",
    "            plt.scatter(X_test, y_test, color='green', s=10)\n",
    "            plt.legend()\n",
    "            plt.savefig(title+'_1D_plot.svg')\n",
    "\n",
    "    print(f'Scoring complete taking {time.time() - st} seconds. ')\n",
    "\n",
    "    return scores, y_test_pred, y_train_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab67588-51e0-4ae3-acc4-f3ac4bd26d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global variables\n",
    "OPTIMIZER = None\n",
    "SHOTS = None\n",
    "X_DIM = None\n",
    "BACKEND = None\n",
    "DEVICE = None\n",
    "ANSATZ = None\n",
    "ENCODER = None\n",
    "POSTPROCESS = None\n",
    "ERROR_MITIGATION = None\n",
    "LAYERS = None\n",
    "TOKEN = None\n",
    "HYPERPARAMETERS = None\n",
    "RE_UPLOAD_DEPTH = None\n",
    "MAX_ITER = None\n",
    "TOLERANCE = None\n",
    "NUM_QUBITS = None\n",
    "BATCH_SIZE = None\n",
    "NUM_CORES = None\n",
    "############################################\n",
    "# Utility functions\n",
    "############################################\n",
    "\n",
    "\n",
    "def parse_settings(settings_file):\n",
    "    with open(settings_file, 'r') as fp:\n",
    "        settings = json.load(fp)\n",
    "\n",
    "    global OPTIMIZER\n",
    "    OPTIMIZER = settings['OPTIMIZER']\n",
    "\n",
    "    global SHOTS\n",
    "    SHOTS = settings['SHOTS']\n",
    "                \n",
    "    global BACKEND\n",
    "    BACKEND = settings['BACKEND']\n",
    "\n",
    "    global DEVICE\n",
    "    DEVICE = settings['DEVICE']\n",
    "\n",
    "    global POSTPROCESS\n",
    "    POSTPROCESS = settings['POSTPROCESS']\n",
    "\n",
    "    global ERROR_MITIGATION\n",
    "    ERROR_MITIGATION = settings['ERROR_MITIGATION']\n",
    "\n",
    "    global LAYERS\n",
    "    LAYERS = settings['LAYERS']\n",
    "\n",
    "    global HYPERPARAMETERS\n",
    "    HYPERPARAMETERS = settings['HYPERPARAMETERS']\n",
    "    # f was removed from HYPERPARAMETERS, this ensures old settings files can still run.\n",
    "    if 'f' in HYPERPARAMETERS.keys():\n",
    "        _ = HYPERPARAMETERS.pop('f', None)\n",
    "\n",
    "    global RE_UPLOAD_DEPTH\n",
    "    RE_UPLOAD_DEPTH = settings['RE-UPLOAD_DEPTH']\n",
    "\n",
    "    global MAX_ITER\n",
    "    MAX_ITER = settings['MAX_ITER']\n",
    "\n",
    "    global TOLERANCE\n",
    "    try:\n",
    "        TOLERANCE = settings['TOLERANCE']\n",
    "    except KeyError:\n",
    "        TOLERANCE = None\n",
    "\n",
    "    global NUM_QUBITS\n",
    "    try:\n",
    "        NUM_QUBITS = settings['NUM_QUBITS']\n",
    "    except KeyError:\n",
    "        NUM_QUBITS = None\n",
    "\n",
    "    # classes aren't JSON serializable, so we store the key in the settings file and access it here.\n",
    "    global ANSATZ\n",
    "    ANSATZ = ANSATZ_LIST[settings['ANSATZ']]\n",
    "\n",
    "    global ENCODER\n",
    "    ENCODER = ENCODER_LIST[settings['ENCODER']]\n",
    "\n",
    "    global BATCH_SIZE\n",
    "    BATCH_SIZE = settings['BATCH_SIZE']\n",
    "    \n",
    "    global NUM_CORES\n",
    "    NUM_CORES = settings['NUM_CORES']\n",
    "\n",
    "def load_dataset(file):\n",
    "    print(f'Loading dataset from {file}... ')\n",
    "    data = joblib.load(file)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    global X_DIM\n",
    "    _, X_DIM = X.shape\n",
    "    print(f'Successfully loaded {file} into X and y data. ')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def save_token(instance, token):\n",
    "    global TOKEN\n",
    "    TOKEN = token\n",
    "    QiskitRuntimeService.save_account(channel='ibm_quantum', instance=instance, token=token, overwrite=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a3edd-65b2-4b07-a82c-df72b9e77745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_circuits(title):\n",
    "    draw_ansatz = qml.draw_mpl(ANSATZ)\n",
    "    draw_ansatz(np.random.rand(ANSATZ.num_params))\n",
    "    plt.savefig(title + '_ansatz.svg')\n",
    "\n",
    "    draw_encoder = qml.draw_mpl(ENCODER)\n",
    "    draw_encoder(np.random.rand(X_DIM), range(X_DIM))\n",
    "    plt.savefig(title + '_encoder.svg')\n",
    "\n",
    "\n",
    "def create_kwargs():\n",
    "    #  First have to apply specific ansatz settings: setting number of layers and the number of wires based on features\n",
    "    ANSATZ.layers = LAYERS\n",
    "    ANSATZ.set_wires(range(X_DIM))\n",
    "\n",
    "    kwargs = {\n",
    "        'encoder': ENCODER,\n",
    "        'variational': ANSATZ,\n",
    "        'num_qubits': X_DIM,\n",
    "        'optimizer': OPTIMIZER,\n",
    "        # 'optimizer': \"BFGS\",\n",
    "        'max_iterations': MAX_ITER,\n",
    "        'tol': TOLERANCE,\n",
    "        'device': DEVICE,\n",
    "        'shots': SHOTS,\n",
    "        'backend': BACKEND,\n",
    "        'postprocess': POSTPROCESS,\n",
    "        'error_mitigation': ERROR_MITIGATION,\n",
    "        'token': TOKEN,\n",
    "        're_upload_depth': RE_UPLOAD_DEPTH,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'njobs':NUM_CORES\n",
    "    }\n",
    "    return kwargs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6d857-243a-4dd9-bb38-546456dd6fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb292a4a-e147-4dad-a80c-21044511b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings=\"./IQP_Full-Pauli-CRZ/qulacsIQP_Full-Pauli-CRZ.json\" \n",
    "settings=\"./IQP_Full-Pauli-CRZ/fakeIQP_Full-Pauli-CRZ.json\" \n",
    "# settings=\"./IQP_Full-Pauli-CRZ/IQP_Full-Pauli-CRZ.json\" \n",
    "save_path='./IQP_Full-Pauli-CRZ'\n",
    "train_set=\"0.1_linear_train.bin\"\n",
    "scaler=\"linear_scaler.bin\" \n",
    "test_set=\"linear_test.bin\" \n",
    "resume_file=os.path.join(os.path.expanduser('~'),\"qregress/function-calc-test/learning_curves/linear/0.1/IQP_Full-Pauli-CRZ/final_state_model.bin\")\n",
    "title=\"IQP_Full-Pauli-CRZ\"\n",
    "save_circuits=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8a6af-e774-4690-86df-656c8af9b3d3",
   "metadata": {},
   "source": [
    "### Write a function that runs training in a session but model evaluation prediction in a session also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f94995-9e9e-4c97-adfa-ff78ff1dd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains the quantum regressor with the settings in the given settings file using the dataset from the given train\n",
    "and test files. Will perform grid search on a default hyperparameter space unless they are specified. Saves scores\n",
    "and best hyperparameters to joblib dumps and graphs of performance and circuit drawings as mpl svg.\n",
    "\"\"\"\n",
    "X_train, y_train = load_dataset(train_set)\n",
    "parse_settings(settings)\n",
    "if DEVICE == 'qiskit.ibmq':\n",
    "    save_token(instance, token)\n",
    "\n",
    "global NUM_QUBITS\n",
    "global X_DIM\n",
    "\n",
    "if NUM_QUBITS is not None:\n",
    "    X_DIM = NUM_QUBITS\n",
    "elif X_DIM == 1:  # if X_DIM is None and num_qubits wasn't specified anywhere use a default value of 2.\n",
    "    NUM_QUBITS = 2\n",
    "    X_DIM = NUM_QUBITS\n",
    "\n",
    "kwargs = create_kwargs()\n",
    "\n",
    "if title is None:\n",
    "    title = os.path.basename(settings)\n",
    "    title, _ = os.path.splitext(title)\n",
    "\n",
    "if save_circuits:\n",
    "    plot_circuits(title)\n",
    "\n",
    "if test_set is not None:\n",
    "    X_test, y_test = load_dataset(test_set)\n",
    "else:\n",
    "    X_test, y_test = None, None\n",
    "\n",
    "scaler = joblib.load(scaler)\n",
    "\n",
    "print(f'Training model with dataset {train_set} \\n at time {time.asctime()}... ')\n",
    "st = time.time()\n",
    "\n",
    "model = QuantumRegressor(**kwargs)\n",
    "model.fit(X_train, y_train, load_state=resume_file)\n",
    "hyperparams = None\n",
    "\n",
    "et = time.time()\n",
    "print(f'Training complete taking {et - st} total seconds. ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c480f-b044-4aab-8ad5-0122186fd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# removes temporary file created during training.\n",
    "if os.path.exists(title + '_tentative_model.bin'):\n",
    "    os.remove('tentative_model.bin')\n",
    "elif os.path.exists('tentative_model.bin'):\n",
    "    os.remove('tentative_model.bin')\n",
    "\n",
    "scores, test_pred, train_pred = evaluate(model, X_train, y_train, X_test, y_test, plot=True, title=title,\n",
    "                                         y_scaler=scaler)\n",
    "y_train = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "name = title + '_predicted_values.csv'\n",
    "train_pred, y_train, test_pred, y_test = train_pred.tolist(), y_train.tolist(), test_pred.tolist(), y_test.tolist()\n",
    "df_train = pd.DataFrame({'Predicted': train_pred, 'Reference': y_train})\n",
    "df_train['Data'] = 'Train'\n",
    "df_test = pd.DataFrame({'Predicted': test_pred, 'Reference': y_test})\n",
    "df_test['Data'] = 'Test'\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df = df[['Data', 'Predicted', 'Reference']]\n",
    "\n",
    "df.to_csv(name, index=False)\n",
    "print(f'Saved predicted values as {name}')\n",
    "\n",
    "print(f'Model scores: {scores}. ')\n",
    "\n",
    "results = scores\n",
    "\n",
    "if len(HYPERPARAMETERS['alpha']) != 1:\n",
    "    results['hyperparameters'] = hyperparams\n",
    "results_title = title + '_results.json'\n",
    "with open(results_title, 'w') as outfile:\n",
    "    json.dump(results, outfile)\n",
    "    pass\n",
    "print(f'Saved model results as {results_title}. ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a2e45-8d28-4c23-bd46-17d0d4c9e421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
