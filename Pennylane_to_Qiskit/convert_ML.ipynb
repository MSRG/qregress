{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8f5c2c-b710-429b-9f46-14c842ed6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import click\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import collections.abc\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "# !{sys.executable} -m pip install spsa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"12\"\n",
    "from scipy.optimize import minimize\n",
    "# Qiskit\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Pauli, SparsePauliOp, Operator\n",
    "from qiskit.primitives import StatevectorEstimator\n",
    "from qiskit.circuit import Parameter, ParameterVector\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_ibm_runtime import EstimatorV2 as Estimator\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from qiskit_ibm_runtime.fake_provider import FakeQuebec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8cd7b1-46c5-4d8e-966b-87a99489ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mitarai(quantumcircuit,num_wires,paramname='x'):\n",
    "    # encoding as proposed by Mitarai et al.\n",
    "    num_features = num_wires\n",
    "    features = ParameterVector(paramname,num_features*2)\n",
    "    for i in range(num_wires):\n",
    "        feature_idx = i % num_features  # Calculate the feature index using modulo\n",
    "        quantumcircuit.ry(np.arcsin(features[feature_idx * 2]), i)\n",
    "        quantumcircuit.rz(np.arccos(features[feature_idx * 2 + 1] ** 2), i)\n",
    "\n",
    "\n",
    "def double_angle(quantumcircuit, num_wires,paramname='x'):\n",
    "    #  creates a circuit that encodes features into wires via angle encoding with an RY then RZ gate\n",
    "    #  the features are encoded 1-1 onto the qubits\n",
    "    #  if more wires are passed then features the remaining wires will be filled from the beginning of the feature list\n",
    "    num_features = num_wires\n",
    "    features = ParameterVector(paramname,num_features*2)\n",
    "    for i in range(num_wires):\n",
    "        feature_index = i % num_features\n",
    "        quantumcircuit.ry(features[feature_index], i)\n",
    "        quantumcircuit.rz(features[feature_index], i)\n",
    "\n",
    "def entangle_cnot(quantumcircuit,num_wires):\n",
    "    #  entangles all of the wires in a circular fashion using cnot gates\n",
    "    for i in range(num_wires):\n",
    "        \n",
    "        if i == num_wires - 1:\n",
    "            quantumcircuit.cx(i, 0)\n",
    "        else:\n",
    "            quantumcircuit.cx(i, i+1)\n",
    "\n",
    "\n",
    "def entangle_cz(quantumcircuit,num_wires):\n",
    "    #  entangles all of the wires in a circular fashion using cz gates\n",
    "    for i in range(num_wires):\n",
    "        \n",
    "        if i == num_wires - 1:\n",
    "            quantumcircuit.cz(i, 0)\n",
    "        else:\n",
    "            quantumcircuit.cz(i, i+1)\n",
    "\n",
    "\n",
    "def HardwareEfficient(quantumcircuit,num_wires,paramname='theta'):\n",
    "    parameters = ParameterVector(paramname,num_wires*3)\n",
    "    for qubit in range(num_wires):\n",
    "        quantumcircuit.rx(parameters[qubit * 3], qubit)  \n",
    "        quantumcircuit.rz(parameters[qubit * 3 + 1], qubit)  \n",
    "        quantumcircuit.rx(parameters[qubit * 3 + 2], qubit)  \n",
    "    entangle_cnot(quantumcircuit,num_wires)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98051576-89f8-4a1d-980e-3708e2089ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def circuit(nqubits):\n",
    "#     qc = QuantumCircuit(nqubits)\n",
    "#     mitarai(qc,nqubits)\n",
    "#     entangle_cz(qc,nqubits)\n",
    "#     qc.barrier()\n",
    "#     mitarai(qc,nqubits,paramname='x1')\n",
    "#     entangle_cz(qc,nqubits)\n",
    "#     qc.barrier()\n",
    "#     HardwareEfficient(qc,nqubits)\n",
    "#     qc.barrier()\n",
    "#     return qc\n",
    "\n",
    "\n",
    "def circuit(nqubits,RUD=1):\n",
    "    qc = QuantumCircuit(nqubits)\n",
    "    for i in range(RUD):\n",
    "        double_angle(qc,nqubits,paramname=f'x{i}')\n",
    "        qc.barrier()\n",
    "        HardwareEfficient(qc,nqubits,paramname=f'theta{i}')\n",
    "        qc.barrier()\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8bf691c-13a0-4a08-8ef7-eb0aa14bb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class regressor:\n",
    "    def __init__(self,\n",
    "                 n_qubits,\n",
    "                 optimizer: str = 'COBYLA',\n",
    "                 tol: float = 1e-8,\n",
    "                 postprocess: str = None,\n",
    "                 error_mitigation=None,\n",
    "                 scale_factors: list = None,\n",
    "                 f: float = 1.,\n",
    "                 alpha: float = 0.,\n",
    "                 beta: float = 0,\n",
    "                 batch_size: int=None,\n",
    "                 njobs: int=None,                 \n",
    "                 device='statevector',\n",
    "                 shots=None,\n",
    "                 max_iterations=100):\n",
    "        self.device = device\n",
    "        self.shots = shots\n",
    "        self.circuit = circuit(num_qubits)\n",
    "        self.max_iterations = max_iterations\n",
    "        self.n_qubits = n_qubits\n",
    "        self.hyperparameters = {'f': f, 'alpha': alpha, 'beta': beta}\n",
    "        if scale_factors is None:\n",
    "            scale_factors = [1, 3, 5]\n",
    "        self.callback_interval = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.params = None\n",
    "        self._batch_size = batch_size\n",
    "        self.error_mitigation = error_mitigation\n",
    "        if postprocess == 'None':\n",
    "            postprocess = None\n",
    "        self.postprocess = postprocess\n",
    "        self._set_device()\n",
    "        self._set_optimizer(optimizer)\n",
    "        self._tol = tol\n",
    "        self.fit_count = 0\n",
    "        self.cached_results = {}\n",
    "        self.njobs = njobs \n",
    "        print(self.njobs)\n",
    "        os.environ[\"OMP_NUM_THREADS\"] = str(self.njobs)\n",
    "        print(os.environ[\"OMP_NUM_THREADS\"])        \n",
    "        observables_labels = ''.join(['I']*(self.n_qubits-1))+'Z'\n",
    "        observables = [SparsePauliOp(observables_labels)]\n",
    "        self.mapped_observables = [observable.apply_layout(self.circuit.layout) for observable in observables]\n",
    "        \n",
    "    def _set_device(self):\n",
    "        if self.device=='real':\n",
    "            service = QiskitRuntimeService(channel=\"ibm_quantum\", instance='pinq-quebec-hub/univ-toronto/default')\n",
    "            self._backend = service.least_busy(operational=True, simulator=False, min_num_qubits=self.n_qubits)\n",
    "            self.estimator = Estimator(mode=backend)\n",
    "            \n",
    "            if self.shots==None:\n",
    "                self.estimator.options.default_shots = 1024.0\n",
    "            else:\n",
    "                self.estimator.options.default_shots = self.shots            \n",
    "            \n",
    "\n",
    "            if self.error_mitigation == 'TREX':\n",
    "                self.estimator.options.resilience_level = 1\n",
    "            else:\n",
    "                self.estimator.options.resilience_level = 0\n",
    "                \n",
    "        elif self.device == \"fake\":\n",
    "            self._backend = FakeQuebec()\n",
    "            target = self._backend.target\n",
    "            pm = generate_preset_pass_manager(target=target)\n",
    "            if self.shots==None:\n",
    "                self.estimator.options.default_shots = 1024.0\n",
    "            else:\n",
    "                self.estimator.options.default_shots = self.shots            \n",
    "            \n",
    "            if self.error_mitigation == 'TREX':\n",
    "                self.estimator.options.resilience_level = 1\n",
    "            else:\n",
    "                self.estimator.options.resilience_level = 0\n",
    "                \n",
    "        elif self.device == 'statevector':\n",
    "            self.estimator = StatevectorEstimator()\n",
    "            \n",
    "\n",
    "                \n",
    "    def _map_features(self,X):\n",
    "        if len(X)==1:\n",
    "            featparams = dict([(i,X.item()) for idx,i in enumerate(self.circuit.parameters) if 'x' in i.name])\n",
    "        else:\n",
    "            featparams = dict([(i,X[idx % num_qubits]) for idx,i in enumerate(self.circuit.parameters) if 'x' in i.name])\n",
    "        return featparams\n",
    "    \n",
    "    def _assign_parameters(self,parameters):\n",
    "        parameter_dict = dict(zip([i for i in self.circuit.parameters if 'theta' in i.name],parameters.flatten()))        \n",
    "        return parameter_dict\n",
    "        \n",
    "\n",
    "            \n",
    "    def _cost_wrapper(self, parameters):\n",
    "        # caches the results from the cost function, so they don't have to be recalculated if they get called again i.e.\n",
    "        # during the callback function for logging.\n",
    "        param_hash = hash(parameters.data.tobytes())\n",
    "        if param_hash in self.cached_results:\n",
    "            cost = self.cached_results[param_hash]\n",
    "        else:\n",
    "            cost = self._cost(parameters)\n",
    "            self.cached_results[param_hash] = cost\n",
    "        print('GMJ Cost wrapper',cost,parameters)\n",
    "        return cost                   \n",
    "\n",
    "    def _save_partial_state(self, param_vector, force=False):\n",
    "        # saves every call to a bin file able to be loaded later by calling fit with load_state set to filename\n",
    "        interval = self.callback_interval\n",
    "        if interval is None:\n",
    "            interval = 5\n",
    "        if self.fit_count % interval == 0 or force:\n",
    "            partial_results = {\n",
    "                'parameters': param_vector,\n",
    "                'iterations': self.fit_count\n",
    "            }\n",
    "            if force is True and os.path.exists('partial_state_model.bin'):\n",
    "                outfile = 'final_state_model.bin'\n",
    "                os.remove('partial_state_model.bin')\n",
    "            else:\n",
    "                outfile = 'partial_state_model.bin'\n",
    "            joblib.dump(partial_results, outfile)\n",
    "    \n",
    "    def _cost(self, parameters):\n",
    "        pred = self.predict(self.x, params=parameters)\n",
    "        base_cost = mean_squared_error(self.y, pred)    \n",
    "        return base_cost\n",
    "\n",
    "    def _load_partial_state(self, infile):\n",
    "        print('Loading partial state from file ' + infile)\n",
    "        partial_state = joblib.load(infile)\n",
    "        if type(partial_state) == dict:\n",
    "            param_vector = partial_state['parameters']\n",
    "            iteration = partial_state['iterations']\n",
    "            print('Loaded parameter_vector as', param_vector)\n",
    "            return param_vector, iteration\n",
    "        else:\n",
    "            print('Outdated partial file detected! Unexpected behaviour may occur.')\n",
    "            param_vector = partial_state\n",
    "            print('Loaded parameter_vector as', param_vector)\n",
    "        return param_vector, 0\n",
    "\n",
    "    def fit(self, x, y, initial_parameters=None, detailed_results=False, load_state=None, callback_interval=None):\n",
    "        \"\"\"\n",
    "        Fits the current model to the given x and y data. If no initial parameters are given then random ones will be\n",
    "        chosen. Optimal parameters are stored in the model for use in predict and returned in this function.\n",
    "\n",
    "        :param x: np.array\n",
    "            x data to fit\n",
    "        :param y: np.array\n",
    "            y data to fit\n",
    "        :param initial_parameters: list, optional\n",
    "            initial parameters to start optimizer\n",
    "        :param detailed_results: bool, optional\n",
    "            whether to return detailed results of optimization or just parameters\n",
    "        :param load_state: str, optional\n",
    "            file to load partial fit data from\n",
    "        :param callback_interval: int, optional\n",
    "            how often to save the optimization steps to file\n",
    "        :return:\n",
    "            returns the optimal parameters found by optimizer. If detailed_results=True and optimizer is scipy, then\n",
    "            will be of type scipy optimizer results stored in dictionary.\n",
    "        \"\"\"\n",
    "        self.fit_count = 0\n",
    "        with open('model_log.csv', 'w') as outfile:\n",
    "            outfile.write('Time,Iteration,Cost,Parameters')\n",
    "            outfile.write('\\n')\n",
    "        self.callback_interval = callback_interval\n",
    "\n",
    "        if load_state is not None:\n",
    "            param_vector, self.fit_count = self._load_partial_state(load_state)\n",
    "            initial_parameters = param_vector\n",
    "        elif initial_parameters is None:\n",
    "            num_params = self._num_params()\n",
    "            generator = np.random.default_rng(12958234)\n",
    "            initial_parameters = generator.uniform(-np.pi, np.pi, num_params)\n",
    "            if self.postprocess is not None:\n",
    "                additional_num_params = self.n_qubits\n",
    "                additional_params = generator.uniform(-1, 1, additional_num_params)\n",
    "                initial_parameters = np.concatenate((initial_parameters, additional_params))\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        params = initial_parameters\n",
    "        print(f'GMJ init params: {params}')\n",
    "        if self.use_scipy:\n",
    "            options = {\n",
    "                'maxiter': self.max_iterations - self.fit_count,\n",
    "                'tol': self._tol,\n",
    "                'disp': True\n",
    "            }\n",
    "            if self.device == 'statevector':\n",
    "                opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback, options=options)\n",
    "                self.params = opt_result['x']\n",
    "            else:\n",
    "                with Session(backend=self._backend) as session:            \n",
    "                    opt_result = minimize(self._cost_wrapper, x0=params, method=self.optimizer, callback=self._callback, options=options)\n",
    "                    self.params = opt_result['x']\n",
    "            print(f'GMJ opt params: {self.params}')\n",
    "            \n",
    "        else:\n",
    "            opt = qml.SPSAOptimizer(maxiter=self.max_iterations)\n",
    "            cost = []\n",
    "            if self.device == 'statevector':\n",
    "                for idx,_ in enumerate(range(self.max_iterations)):\n",
    "                    params, temp_cost = opt.step_and_cost(self._cost_wrapper, params)\n",
    "                    cost.append(temp_cost)\n",
    "                    self._callback(params)\n",
    "    \n",
    "                    if idx>0 and abs(cost[idx]-cost[idx-1])<=self._tol and abs(np.mean(cost[-3:])-temp_cost)<=self._tol:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                     \n",
    "            else:\n",
    "                with Session(backend=self._backend) as session:\n",
    "                    for idx,_ in enumerate(range(self.max_iterations)):\n",
    "                        params, temp_cost = opt.step_and_cost(self._cost_wrapper, params)\n",
    "                        cost.append(temp_cost)\n",
    "                        self._callback(params)\n",
    "        \n",
    "                        if idx>0 and abs(cost[idx]-cost[idx-1])<=self._tol and abs(np.mean(cost[-3:])-temp_cost)<=self._tol:\n",
    "                            print(\"Early stopping!\")\n",
    "                            break\n",
    "                        \n",
    "            opt_result = [params, cost]\n",
    "            self.params = params\n",
    "\n",
    "        self._save_partial_state(params, force=True)\n",
    "        if detailed_results:\n",
    "            for key, value in opt_result.items():\n",
    "                if type(value) is np.ndarray:\n",
    "                    value = value.tolist()\n",
    "                    for i, x in enumerate(value):\n",
    "                        if type(x) is np.bool_:\n",
    "                            value[i] = bool(x)\n",
    "                    opt_result[key] = value\n",
    "                elif type(value) is np.bool_:\n",
    "                    value = bool(value)\n",
    "                    opt_result[key] = value\n",
    "            with open('detailed_results.json', 'w') as outfile:\n",
    "                try:\n",
    "                    json.dump(opt_result, outfile)\n",
    "                except:\n",
    "                    print('Could not dump detailed results. Not json serializable. ')\n",
    "        return self.params\n",
    "\n",
    "    def predict(self, x, params=None):\n",
    "        \"\"\"\n",
    "        Predicts a set of output data given a set of input data x using the trained parameters found with fit\n",
    "\n",
    "        :param x: np.array\n",
    "            x data to predict outputs of in the model\n",
    "        :param params: list\n",
    "            optional parameters to use in prediction, used for internal cost functions.\n",
    "        :raises ValueError:\n",
    "            if fit is not first called then raises error explaining that the model must first be trained\n",
    "        :return: np.ndarray\n",
    "            predicted values corresponding to each datapoint in x\n",
    "        \"\"\"\n",
    "        f = self.hyperparameters['f']\n",
    "        print('GMJ predict params:',params)\n",
    "        if params is None:\n",
    "            # if no parameters are passed then we are predicting the fitted model, so we use the stored parameters.\n",
    "            params = self.params\n",
    "\n",
    "        if self.postprocess is None:\n",
    "            return [f * self.qnode(features=features, parameters=params) for features in tqdm(x,desc=\"Predict\")]\n",
    "        else:\n",
    "            return [np.dot(f * np.array(self.qnode(features=features, parameters=params[:-self.n_qubits])),params[-self.n_qubits:]) for features in x]\n",
    "\n",
    "\n",
    "    def _callback(self, xk):\n",
    "        cost_at_step = self._cost_wrapper(xk)\n",
    "        if self.fit_count % 1 == 0:\n",
    "            print(f'[{time.asctime()}]  Iteration number: {self.fit_count} with current cost as {cost_at_step} and '\n",
    "                  f'parameters \\n{xk}. ')\n",
    "        filename = 'model_log.csv'\n",
    "        log = f'{time.asctime()},{self.fit_count},{cost_at_step},{xk}'\n",
    "        with open(filename, 'a') as outfile:\n",
    "            outfile.write(log)\n",
    "            outfile.write('\\n')\n",
    "        self.fit_count += 1\n",
    "        self._save_partial_state(xk)    \n",
    "\n",
    "    def _num_params(self):\n",
    "        #  computes the number of parameters required for the implemented variational circuit\n",
    "        num_params = len(self.circuit.parameters)\n",
    "        return num_params\n",
    "        \n",
    "    def qnode(self,features,parameters):\n",
    "        featparams = self._map_features(features)\n",
    "        parameter_dict = self._assign_parameters(parameters)\n",
    "        paramdict = parameter_dict | featparams\n",
    "        # Ensure parameters from an optimizer or external calculation are strictly real\n",
    "        paramdict = {p: float(np.real_if_close(d, tol=1e-7)) for p, d in paramdict.items()}\n",
    "        \n",
    "        self.circuit = self.circuit.assign_parameters(paramdict)\n",
    "        job = self.estimator.run([(self.circuit, self.mapped_observables)])\n",
    "        y_pred = job.result()[0].data.evs\n",
    "        return y_pred\n",
    "\n",
    "    def _set_optimizer(self, optimizer):\n",
    "        #  sets the desired optimizer. SPSA is not available in scipy and has to be handled separately in fitting\n",
    "        if optimizer == 'SPSA':\n",
    "            self.use_scipy = False\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.use_scipy = True\n",
    "            self.optimizer = optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11cb5805-20c7-493a-b96c-8eac41dcc1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grierjones/miniconda3/envs/qml_min/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('linear_train.bin','rb') as f:\n",
    "    train = joblib.load(f)\n",
    "\n",
    "with open('linear_test.bin','rb') as f:\n",
    "    test = joblib.load(f)\n",
    "\n",
    "with open('linear_scaler.bin','rb') as f:\n",
    "    scaler = joblib.load(f)\n",
    "X_train, y_train = train['X'],train['y']\n",
    "X_test, y_test = test['X'],test['y']\n",
    "\n",
    "\n",
    "with open('PCA5_0.8_Morgan_train.bin','rb') as f:\n",
    "    bse_train = joblib.load(f)\n",
    "\n",
    "with open('PCA5_0.8_Morgan_test.bin','rb') as f:\n",
    "    bse_test = joblib.load(f)\n",
    "\n",
    "with open('PCA5_0.8_Morgan_scaler.bin','rb') as f:\n",
    "    bse_scaler = joblib.load(f)\n",
    "\n",
    "X_bse_train, y_bse_train = bse_train['X'],bse_train['y']\n",
    "X_bse_test, y_bse_test = bse_test['X'],bse_test['y']\n",
    "\n",
    "\n",
    "X_bse_train[np.isclose(X_bse_train,1)]=1\n",
    "X_bse_train[np.isclose(X_bse_train,-1)]=-1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('5_DDCC_train.bin','rb') as f:\n",
    "    ddcc_train = joblib.load(f)\n",
    "\n",
    "with open('5_DDCC_test.bin','rb') as f:\n",
    "    ddcc_test = joblib.load(f)\n",
    "\n",
    "with open('5_DDCC_scaler.bin','rb') as f:\n",
    "    ddcc_scaler = joblib.load(f)\n",
    "\n",
    "X_ddcc_train, y_ddcc_train = ddcc_train['X'],ddcc_train['y']\n",
    "X_ddcc_test, y_ddcc_test = ddcc_test['X'],ddcc_test['y']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9143986-cc85-4fbf-9f29-88ff86fab634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(params, ansatz, hamiltonian, estimator,X):\n",
    "    num_qubits = ansatz.num_qubits\n",
    "    if len(X)==1:\n",
    "        featparams = dict([(i,X.item()) for idx,i in enumerate(ansatz.parameters) if 'x' in i.name])\n",
    "    else:\n",
    "        featparams = dict([(i,X[idx % num_qubits]) for idx,i in enumerate(ansatz.parameters) if 'x' in i.name])\n",
    "    \n",
    "    ansatz = ansatz.assign_parameters(featparams)    \n",
    "    pub = (ansatz, [hamiltonian], [params])\n",
    "    result = estimator.run(pubs=[pub]).result()\n",
    "    energy = result[0].data.evs[0]\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7b7a7c-4d12-48be-b87b-b7ced65de3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(params, ansatz, hamiltonian, estimator,X,y):\n",
    "    \"\"\"Return estimate of energy from estimator\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        params (ndarray): Array of ansatz parameters\n",
    "        ansatz (QuantumCircuit): Parameterized ansatz circuit\n",
    "        hamiltonian (SparsePauliOp): Operator representation of Hamiltonian\n",
    "        estimator (EstimatorV2): Estimator primitive instance\n",
    "        cost_history_dict: Dictionary for storing intermediate results\n",
    "\n",
    "    Returns:\n",
    "        float: Energy estimate\n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = np.array([predict(params, ansatz, hamiltonian, estimator,x) for x in X]).reshape(*y.shape)\n",
    "    # print(y,y_pred)\n",
    "    loss = mean_squared_error(y,y_pred)\n",
    "    cost_history_dict[\"iters\"] += 1\n",
    "    cost_history_dict[\"prev_vector\"] = params\n",
    "    cost_history_dict[\"cost_history\"].append(loss)\n",
    "    print(f\"Iters. done: {cost_history_dict['iters']} [Current cost: {loss}/Accuracy: {r2_score(y,y_pred)}]\")\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c8a9c5d-9799-4c45-aa46-8df12a30b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history_dict = {\n",
    "    \"prev_vector\": None,\n",
    "    \"iters\": 0,\n",
    "    \"cost_history\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0172f0c5-8225-47b8-91e3-8e113113d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 5\n",
    "RUD = 3\n",
    "# X = X_bse_train[0:1].flatten()\n",
    "# Y = y_bse_test[0:1]\n",
    "\n",
    "# X,Y = X_bse_train, y_bse_train\n",
    "X,Y = X_ddcc_train, y_ddcc_train\n",
    "# X,Y = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9051da58-bc28-460b-b293-f9e0315a82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qc = circuit(num_qubits,RUD)\n",
    "# qc.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd52caac-5d5c-4cc4-9c76-aeae8ea6a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = len([i for i in list(qc.parameters) if 'theta' in i.name]) // RUD\n",
    "# x0 = 2 * np.pi * np.random.random(num_params)\n",
    "generator = np.random.default_rng(12958234)\n",
    "x0 = np.tile(generator.uniform(-np.pi, np.pi, num_params),RUD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37a160-f338-4f3d-9b17-c1c695681785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Iters. done: 1 [Current cost: 0.20048492812102017/Accuracy: -1.2143684399333639]\n",
      "Iters. done: 2 [Current cost: 0.16101045085061022/Accuracy: -0.7783703952439489]\n",
      "Iters. done: 3 [Current cost: 0.15515653507187915/Accuracy: -0.7137135331449425]\n",
      "Iters. done: 4 [Current cost: 0.19917588392855604/Accuracy: -1.1999099658054688]\n",
      "Iters. done: 5 [Current cost: 0.14078644746081895/Accuracy: -0.5549950260569632]\n",
      "Iters. done: 6 [Current cost: 0.16044532618445775/Accuracy: -0.772128558328405]\n",
      "Iters. done: 7 [Current cost: 0.13970326212163237/Accuracy: -0.543031176942852]\n",
      "Iters. done: 8 [Current cost: 0.1541920452296305/Accuracy: -0.7030606831410633]\n",
      "Iters. done: 9 [Current cost: 0.14894434338927504/Accuracy: -0.645099491512489]\n",
      "Iters. done: 10 [Current cost: 0.13766449131012645/Accuracy: -0.5205128271418595]\n",
      "Iters. done: 11 [Current cost: 0.13995474104227956/Accuracy: -0.5458087771864653]\n",
      "Iters. done: 12 [Current cost: 0.1492004875824794/Accuracy: -0.6479286199802485]\n",
      "Iters. done: 13 [Current cost: 0.149917571674028/Accuracy: -0.6558488581546864]\n",
      "Iters. done: 14 [Current cost: 0.11974118002268476/Accuracy: -0.3225487446246207]\n",
      "Iters. done: 15 [Current cost: 0.1039243280569925/Accuracy: -0.14785063569353474]\n",
      "Iters. done: 16 [Current cost: 0.10553875147615949/Accuracy: -0.16568204228153882]\n",
      "Iters. done: 17 [Current cost: 0.11773942370230757/Accuracy: -0.30043922216912367]\n",
      "Iters. done: 18 [Current cost: 0.10340826683485692/Accuracy: -0.14215070755389592]\n",
      "Iters. done: 19 [Current cost: 0.12340381675827353/Accuracy: -0.3630027940648486]\n",
      "Iters. done: 20 [Current cost: 0.10922112610541104/Accuracy: -0.20635409797893178]\n",
      "Iters. done: 21 [Current cost: 0.11272271845741963/Accuracy: -0.24502940223481762]\n",
      "Iters. done: 22 [Current cost: 0.1251838002370935/Accuracy: -0.3826628217589132]\n",
      "Iters. done: 23 [Current cost: 0.13788547837123785/Accuracy: -0.5229536429096329]\n",
      "Iters. done: 24 [Current cost: 0.13492189002094176/Accuracy: -0.49022062615194195]\n",
      "Iters. done: 25 [Current cost: 0.10873737342039039/Accuracy: -0.20101101963143542]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(num_params)\n",
    "# x0=np.array([-2.90335709,2.22986535,-2.00373979,-0.16646551,0.63465958,-2.72860048 ,2.66349506,2.2229548,1.7837882,-1.05017446,0.51676695,1.19521426 ,1.66007016,-1.56591128,0.73095999]).flatten()\n",
    "# print(x0.shape)\n",
    "estimator = StatevectorEstimator()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "observables_labels = ''.join(['I']*(num_qubits-1))+\"Z\"\n",
    "observables = [SparsePauliOp(observables_labels)]\n",
    "mapped_observables = [observable.apply_layout(qc.layout) for observable in observables]\n",
    "\n",
    "\n",
    "\n",
    "# job = estimator.run([(qc, mapped_observables)])\n",
    "# y_pred = job.result()[0].data.evs\n",
    "scores = []\n",
    "for i in range(10):\n",
    "    cost_history_dict = {\n",
    "        \"prev_vector\": None,\n",
    "        \"iters\": 0,\n",
    "        \"cost_history\": [],\n",
    "    }    \n",
    "    res = minimize(\n",
    "        cost_func,\n",
    "        x0,\n",
    "        args=(qc, mapped_observables, estimator,X,Y),\n",
    "        method=\"cobyla\", options={'maxiter':50}\n",
    ")\n",
    "    x0 = res.x\n",
    "\n",
    "    y_pred = np.array([predict(x0,qc, mapped_observables, estimator,x) for x in X])\n",
    "    r2 = r2_score(Y,y_pred)\n",
    "    loss = mean_squared_error(Y,y_pred)\n",
    "    print(f\"Iteration: {i} R2: {r2} MSE: {loss}\")\n",
    "    scores.append((r2,loss))\n",
    "    # if i % 10 ==0:\n",
    "    plt.scatter(Y,Y,label='true')\n",
    "    plt.scatter(Y,y_pred,label='pred')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # plt.show()\n",
    "# cost_func(x0,qc,mapped_observables,estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f8df09-b874-4b54-9b5c-4f738d88852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([predict(x0,qc, mapped_observables, estimator,x) for x in X])\n",
    "r2_score(Y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff23d4-0f77-4c9f-a568-61c8bf633ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(scores)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4eba1-8de5-4a29-a615-7ea53b4672c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(scores)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3245679-08c7-414a-805b-5756d2dad92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82fdc4-9192-41a7-9a57-e78feb1504a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50f91c-4426-470a-a832-bc3fe6af58d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
