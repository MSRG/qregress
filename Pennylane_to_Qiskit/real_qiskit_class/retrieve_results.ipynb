{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecc455-f3a5-4ad0-b6fd-b6fe5743f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "import os\n",
    "n_jobs = 16\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_jobs)\n",
    "import joblib\n",
    "import click\n",
    "import json\n",
    "import time\n",
    "from glob import glob\n",
    "import itertools\n",
    "import collections.abc\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "# !{sys.executable} -m pip install qcircuit\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import re\n",
    "from joblib import Parallel, delayed, dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a3045-5adf-4d99-8617-cd6e2c9dbaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 12\n",
    " \n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bbf6d-dc56-49e4-a334-10fc8e7b180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top=os.getcwd()\n",
    "with open(os.path.join(top,'5_DDCC_train.bin'),'rb') as f:\n",
    "    ddcc_train = joblib.load(f)\n",
    "\n",
    "with open(os.path.join(top,'5_DDCC_test.bin'),'rb') as f:\n",
    "    ddcc_test = joblib.load(f)\n",
    "\n",
    "with open(os.path.join(top,'5_DDCC_scaler.bin'),'rb') as f:\n",
    "    ddcc_scaler = joblib.load(f)\n",
    "\n",
    "X_ddcc_train, y_ddcc_train = ddcc_train['X'],ddcc_train['y']\n",
    "X_ddcc_test, y_ddcc_test = ddcc_test['X'],ddcc_test['y']\n",
    "\n",
    "X_ddcc_train = X_ddcc_train.reshape(-1,64,5)[0:4]\n",
    "X_ddcc_test = X_ddcc_test.reshape(-1,64,5)[0:4]\n",
    "y_ddcc_train = y_ddcc_train.reshape(-1,64)[0:4]\n",
    "y_ddcc_test = y_ddcc_test.reshape(-1,64)[0:4]\n",
    "\n",
    "\n",
    "# X_train, y_train = X_ddcc_train, y_ddcc_train\n",
    "# X_test, y_test = X_ddcc_test, y_ddcc_test\n",
    "X_train, y_train = X_ddcc_train, y_ddcc_train\n",
    "X_test, y_test = X_ddcc_test, y_ddcc_test\n",
    "\n",
    "# X_train = [X_train[i:i+4] for i in range(0,len(X_train),4)]\n",
    "# X_test = [X_test[i:i+4] for i in range(0,len(X_test),4)]\n",
    "scaler = ddcc_scaler\n",
    "\n",
    "# print(len(X_train),X_train[0].shape,X_train[-1].shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33080687-acb6-4977-b3cd-8d43350f607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_data(path):\n",
    "    '''\n",
    "    Given a globbed path, return the job_n.txt, *_train.txt, and *_test.txt files\n",
    "    '''\n",
    "    iterations = []\n",
    "    train_metric = []\n",
    "    test_metric = []\n",
    "    for i in path:\n",
    "        try:\n",
    "            numbers = int(re.search(r'jobs_(\\d+)\\.txt', i).group(1))\n",
    "            iterations.append(i)\n",
    "        except:\n",
    "            if 'test' in i:\n",
    "                test_metric.append(i)\n",
    "            else:\n",
    "                train_metric.append(i)\n",
    "            \n",
    "    return sorted(iterations,key=lambda x: int(re.search(r'jobs_(\\d+)\\.txt', x).group(1))), train_metric, test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d44b0-0b11-46de-907d-1b3417758584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_jobs_from_file(service, filename):\n",
    "    \"\"\"Fetch all job results from a given file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        job_ids = f.readlines()\n",
    "    return [service.job(job_id.strip()).result() for job_id in job_ids]\n",
    "\n",
    "def grab_jobs(lst):\n",
    "    \"\"\"Parallelize over job files, fetching results concurrently.\"\"\"\n",
    "    service = QiskitRuntimeService(\n",
    "        channel='ibm_quantum',\n",
    "        instance='pinq-quebec-hub/univ-toronto/default'\n",
    "    )\n",
    "\n",
    "    # Parallel processing of files\n",
    "    jobs = Parallel(n_jobs=-1,backend='threading')(\n",
    "        delayed(fetch_jobs_from_file)(service, filename) for filename in tqdm(lst)\n",
    "    )\n",
    "\n",
    "    return np.array(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828960a-aac2-4b81-89cd-204b145234af",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_100, train_100, test_100 = grab_data(glob('100_iter/*txt'))\n",
    "iter_500, train_500, test_500 = grab_data(glob('500_iter/*txt'))\n",
    "iter_1000, train_1000, test_1000 = grab_data(glob('1000_iter/*txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502bb51-b905-4ee1-91d9-27262aa4aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_100 = grab_jobs(iter_100)\n",
    "# y_100 = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_100]).reshape(*results_100.shape)\n",
    "\n",
    "\n",
    "# results_500 = grab_jobs(iter_500)\n",
    "# y_500 = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_500]).reshape(*results_500.shape)\n",
    "\n",
    "# results_1000 = grab_jobs(iter_1000)\n",
    "# y_1000 = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_1000]).reshape(*results_1000.shape)\n",
    "# with open('y_100.npy', 'wb') as f:\n",
    "#     np.save(f, y_100)\n",
    "# with open('y_500.npy', 'wb') as f:\n",
    "#     np.save(f, y_500)\n",
    "# with open('y_1000.npy', 'wb') as f:\n",
    "#     np.save(f, y_1000)\n",
    "\n",
    "# results_train_100 = grab_jobs(train_100)\n",
    "# y_100_train = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_train_100]).reshape(*y_train.shape)\n",
    "\n",
    "\n",
    "# results_train_500 = grab_jobs(train_500)\n",
    "# y_500_train = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_train_500]).reshape(*y_train.shape)\n",
    "\n",
    "# results_train_1000 = grab_jobs(train_1000)\n",
    "# y_1000_train = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_train_1000]).reshape(*y_train.shape)\n",
    "\n",
    "# results_test_100 = grab_jobs(test_100)\n",
    "# y_100_test = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_test_100]).reshape(*y_test.shape)\n",
    "\n",
    "\n",
    "# results_test_500 = grab_jobs(test_500)\n",
    "# y_500_test = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_test_500]).reshape(*y_test.shape)\n",
    "\n",
    "# results_test_1000 = grab_jobs(test_1000)\n",
    "# y_1000_test = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_test_1000]).reshape(*y_test.shape)\n",
    "\n",
    "# with open('y_100_test.npy', 'wb') as f:\n",
    "#     np.save(f, y_100_test)\n",
    "# with open('y_500_test.npy', 'wb') as f:\n",
    "#     np.save(f, y_500_test)\n",
    "# with open('y_1000_test.npy', 'wb') as f:\n",
    "#     np.save(f, y_1000_test)\n",
    "\n",
    "\n",
    "# with open('y_100_train.npy', 'wb') as f:\n",
    "#     np.save(f, y_100_train)\n",
    "# with open('y_500_train.npy', 'wb') as f:\n",
    "#     np.save(f, y_500_train)\n",
    "# with open('y_1000_train.npy', 'wb') as f:\n",
    "#     np.save(f, y_1000_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c57f6-95c7-4729-9c34-baec32549ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a3b3b-8210-43df-879a-91b203e261e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('y_100_test.npy', 'rb') as f:\n",
    "    y_100_test = np.load(f)\n",
    "with open('y_500_test.npy', 'rb') as f:\n",
    "    y_500_test = np.load(f)\n",
    "with open('y_1000_test.npy', 'rb') as f:\n",
    "    y_1000_test = np.load(f)   \n",
    "\n",
    "\n",
    "    \n",
    "with open('y_100_train.npy', 'rb') as f:\n",
    "    y_100_train = np.load(f)\n",
    "with open('y_500_train.npy', 'rb') as f:\n",
    "    y_500_train = np.load(f)\n",
    "with open('y_1000_train.npy', 'rb') as f:\n",
    "    y_1000_train = np.load(f)       \n",
    "    \n",
    "with open('y_100.npy', 'rb') as f:\n",
    "    y_100 = np.load(f)\n",
    "with open('y_500.npy', 'rb') as f:\n",
    "    y_500 = np.load(f)\n",
    "with open('y_1000.npy', 'rb') as f:\n",
    "    y_1000 = np.load(f)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d12db-95d8-47c2-b26d-f9e99100793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_100_test = scaler.inverse_transform(y_100_test.flatten().reshape(-1,1)).flatten()\n",
    "y_500_test = scaler.inverse_transform(y_500_test.flatten().reshape(-1,1)).flatten()\n",
    "y_1000_test = scaler.inverse_transform(y_1000_test.flatten().reshape(-1,1)).flatten()\n",
    "y_100_train = scaler.inverse_transform(y_100_train.flatten().reshape(-1,1)).flatten()\n",
    "y_500_train = scaler.inverse_transform(y_500_train.flatten().reshape(-1,1)).flatten()\n",
    "y_1000_train = scaler.inverse_transform(y_1000_train.flatten().reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d754711-43f1-494b-9945-2594386be704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deec282-32e7-4ada-b0f5-b41701579865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_100 = scaler.inverse_transform(y_100.flatten().reshape(-1,1)).reshape(*y_100.shape)\n",
    "y_500 = scaler.inverse_transform(y_500.flatten().reshape(-1,1)).reshape(*y_500.shape)\n",
    "y_1000 = scaler.inverse_transform(y_1000.flatten().reshape(-1,1)).reshape(*y_1000.shape)\n",
    "\n",
    "\n",
    "\n",
    "y_ddcc_train = scaler.inverse_transform(y_ddcc_train.flatten().reshape(-1,1)).reshape(*y_ddcc_train.shape)\n",
    "y_ddcc_test = scaler.inverse_transform(y_ddcc_test.flatten().reshape(-1,1)).reshape(*y_ddcc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df45f43-4282-4fdc-b440-4e15e16cf5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_ddcc_train.flatten(),y_100_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453521fe-1d71-4a81-8aa6-359dffd68322",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_ddcc_train.flatten(),y_500_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c795150-67cc-43b3-a6c5-859ed3dabc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_ddcc_train.flatten(),y_1000_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8e14b-38f3-4be3-8917-bb9720a67c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_100 = [mean_squared_error(y_ddcc_train.flatten(),i.flatten()) for i in y_100]\n",
    "MSE_500 = [mean_squared_error(y_ddcc_train.flatten(),i.flatten()) for i in y_500]\n",
    "MSE_1000 = [mean_squared_error(y_ddcc_train.flatten(),i.flatten()) for i in y_1000]\n",
    "\n",
    "combined_MSE = MSE_100+MSE_500+MSE_1000\n",
    "min_MSE_idx = np.argmin(MSE_100+MSE_500+MSE_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce0f14-c6da-41f2-89c0-9279d5328aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train = np.vstack([y_100,y_500,y_1000])[min_MSE_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071a673-6770-41c8-a6d0-c14a4e31ff95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04270795-ef31-4f67-8262-6c75b13f7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.expanduser('~'),'qregress/qml_DDCC/RUD_AL/5AL/A2_HWE-CNOT/A2_HWE-CNOT_results.json')) as f:\n",
    "    statevector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fafb5a-52d2-4d5b-b3f7-b6054f61d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "'/Users/grierjones/qregress/qml_DDCC/RUD_AL/5AL/A2_HWE-CNOT/A2_HWE-CNOT_predicted_values.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a822dc-5b1d-40c1-89b2-507cc7feed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "statevectordf = pd.read_csv(os.path.join(os.path.expanduser('~'),'qregress/qml_DDCC/RUD_AL/5AL/A2_HWE-CNOT/A2_HWE-CNOT_predicted_values.csv'))\n",
    "statevectordf['Predicted'] = [float(i.strip('[]')) for i in statevectordf['Predicted']]\n",
    "statevectordf['Reference'] = [float(i.strip('[]')) for i in statevectordf['Reference']]\n",
    "statevectordf['Device'] = len(statevectordf)*['State Vector']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601fa68-f8d8-45f7-adc6-a90f78a07ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "statevectordf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612215e6-863e-4f37-8f01-947ec37b0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbest = pd.DataFrame(np.vstack([y_ddcc_train.flatten(),best_train.flatten()]),index=['Reference','Predicted']).T\n",
    "dfbest['Device'] = len(dfbest)*['ibm_quebec']\n",
    "dfbest['Data'] = len(dfbest)*['Train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f5ceb-c520-4ef4-9edc-0d20d715cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=pd.concat([statevectordf,dfbest]),x='Reference',y='Predicted',hue='Device',style='Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4ab96-2420-4fd8-95fb-b3eec73aabe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400799f5-8513-4cc1-b60e-3218350396d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2692af-749d-415f-bc6b-20a0c7548c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "statevectordf.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa87cfc-d6ea-40ab-b38e-7299673c7382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e887875-8253-4dc2-b72f-01ed0ebee694",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 10e-2\n",
    "# Create the figure with a 2D grid (scatter + KDE for Predicted + KDE for Reference)\n",
    "fig, axes = plt.subplots(\n",
    "    2, 2, \n",
    "    figsize=(8, 8),\n",
    "    gridspec_kw={'width_ratios': [4, 1], 'height_ratios': [1, 4]},\n",
    "    constrained_layout=True,\n",
    "    # sharey='row',  # Keep y-axis sharing, but remove sharex to control ticks manually,\n",
    "    # sharex='col'\n",
    ")\n",
    "axes[0, -1].axis(\"off\")\n",
    "sns.scatterplot(data=dfbest,x='Reference',y='Predicted',label=\"Best ibm_quebec: R$^{2}=$\"+f\"{r2_score(dfbest['Reference'],dfbest['Predicted']):.4f}\", edgecolors='black',ax=axes[1,0])\n",
    "# sns.scatterplot(data=statevectordf[statevectordf['Data']=='Train'],x='Reference',y='Predicted',label=\"State Vector: R$^{2}=$\"+f\"{r2_score(statevectordf['Reference'],statevectordf['Predicted']):.4f}\", edgecolors='black',ax=axes[1,0])\n",
    "axes[1,0].plot(range(-1,2),range(-1,2),'k--')\n",
    "axes[1,0].set_ylim(-spread,spread)\n",
    "axes[1,0].set_xlim(-spread,spread)\n",
    "axes[1,0].set_ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "axes[1,0].set_xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "axes[1,0].legend()\n",
    "\n",
    "\n",
    "# sns.kdeplot(data=pd.concat([dfbest,statevectordf[statevectordf['Data']=='Train']]),hue='Device',x='Reference',ax=axes[0,0],fill=True)\n",
    "sns.kdeplot(data=dfbest,x='Reference',ax=axes[0,0],fill=True, bw_adjust=2)\n",
    "# sns.kdeplot(data=statevectordf[statevectordf['Data']=='Train'],x='Reference',ax=axes[0,0],fill=True, bw_adjust=2)\n",
    "axes[0,0].set_xticklabels([])  # Hide labels but keep ticks\n",
    "axes[0,0].set_xlabel(\"\")  # Remove x-labels\n",
    "axes[0,0].set_xlim(-spread,spread)\n",
    "axes[0,0].set_ylim(0,100)\n",
    "\n",
    "# sns.kdeplot(data=pd.concat([dfbest,statevectordf[statevectordf['Data']=='Train']]),hue='Device',y='Predicted',ax=axes[1,1],fill=True)\n",
    "sns.kdeplot(data=dfbest,y='Predicted',ax=axes[1,1],fill=True, bw_adjust=2)\n",
    "# sns.kdeplot(data=statevectordf[statevectordf['Data']=='Train'],y='Predicted',ax=axes[1,1],fill=True, bw_adjust=2)\n",
    "axes[1,1].set_yticklabels([])  # Hide labels but keep ticks\n",
    "axes[1,1].set_ylabel(\"\")  # Remove x-labels\n",
    "axes[1,1].set_ylim(-spread,spread)\n",
    "axes[1,1].set_xlim(0,100)\n",
    "# plt.subplots_adjust(wspace=0.1, hspace=0.1)  # Adjust width and height spacing\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/bestibm_vs_statevector.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e898e8f-cecb-4898-b042-6d386ac8bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.scatter(y_ddcc_train.flatten(),best_train.flatten(),label=\"Best ibm_quebec R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),best_train.flatten()):.4f}\",color='r', edgecolors='black')\n",
    "# sns.scatterplot(data=dfbest,x='Reference',y='Predicted',label=\"Best ibm_quebec: R$^{2}=$\"+f\"{r2_score(dfbest['Reference'],dfbest['Predicted']):.4f}\", edgecolors='black')\n",
    "# sns.scatterplot(data=statevectordf[statevectordf['Data']=='Train'],x='Reference',y='Predicted',label=\"State Vector: R$^{2}=$\"+f\"{r2_score(statevectordf['Reference'],statevectordf['Predicted']):.4f}\", edgecolors='black')\n",
    "# plt.plot(range(-1,2),range(-1,2),'k--')\n",
    "# plt.ylim(-3e-2,3e-2)\n",
    "# plt.xlim(-3e-2,3e-2)\n",
    "# plt.ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "# plt.xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/bestibm_vs_statevector.png'),dpi=300,bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5cf020-25c7-4948-aa30-6fe869ba705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_ddcc_train.flatten(),y_1000_train.flatten(),label=\"ibm_quebec Train R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),y_1000_train.flatten()):.4f}\",color='b', edgecolors='black')\n",
    "plt.scatter(y_ddcc_test.flatten(),y_1000_test.flatten(),label=\"ibm_quebec Test R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),y_1000_test.flatten()):.4f}\",color='g', edgecolors='black')\n",
    "sns.scatterplot(data=statevectordf[statevectordf['Data']=='Train'],x='Reference',y='Predicted',label=\"State Vector Train: R$^{2}=$\"+f\"{r2_score(statevectordf[statevectordf['Data']=='Train']['Reference'],statevectordf[statevectordf['Data']=='Train']['Predicted']):.4f}\", edgecolors='black')\n",
    "sns.scatterplot(data=statevectordf[statevectordf['Data']=='Test'],x='Reference',y='Predicted',label=\"State Vector Test: R$^{2}=$\"+f\"{r2_score(statevectordf[statevectordf['Data']=='Test']['Reference'],statevectordf[statevectordf['Data']=='Test']['Predicted']):.4f}\", edgecolors='black')\n",
    "plt.plot(range(-1,2),range(-1,2),'k--')\n",
    "plt.ylim(-3e-2,3e-2)\n",
    "plt.xlim(-3e-2,3e-2)\n",
    "plt.ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "plt.xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/finalibm_vs_statevector.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa8eaa-6589-456f-822f-c307be0c7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.DataFrame(np.hstack([np.vstack([y_ddcc_train.flatten(),y_1000_train.flatten()]),np.vstack([y_ddcc_test.flatten(),y_1000_test.flatten()])]),index=['Reference','Predicted']).T\n",
    "finaldf['Data'] = len(y_ddcc_train.flatten())*['Train']+len(y_ddcc_test.flatten())*['Test']\n",
    "finaldf['Device'] = len(finaldf)*['ibm_quebec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b2c43-e3c5-4513-9179-cab93a152fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ddcc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c356d95-cc29-4430-9361-0c3b810a16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette('Paired',6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aeae6c-89fa-460f-b708-a1feea5c5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d0775-ff44-49bd-95bd-44f87d4a19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf[\"Data\"] = finaldf[\"Data\"] + \" (\" + finaldf[\"Device\"] + \")\"\n",
    "statevectordf[\"Data\"] = statevectordf[\"Data\"] + \" (\" + statevectordf[\"Device\"] + \")\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66beef69-94aa-43ed-ad37-fb81ada507ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "statevectordf['Reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90774dc-0ccf-4f9e-abb8-166ddebe0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a18f7-3df5-4f2f-b243-811303fb5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1000_train.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d0b77-d0ed-4e46-9288-7acaa657d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 10e-2\n",
    "# Create the figure with a 2D grid (scatter + KDE for Predicted + KDE for Reference)\n",
    "fig, axes = plt.subplots(\n",
    "    2, 2, \n",
    "    figsize=(10, 10),\n",
    "    gridspec_kw={'width_ratios': [4, 1.7], 'height_ratios': [1.7, 4]},\n",
    "    constrained_layout=True,\n",
    "    # sharey='row',  # Keep y-axis sharing, but remove sharex to control ticks manually,\n",
    "    # sharex='col'\n",
    ")\n",
    "axes[0, -1].axis(\"off\")\n",
    "# sns.scatterplot(data=finaldf,x='Reference',y='Predicted',hue='Data',style='Data',markers=['o', 's'], edgecolors='black',ax=axes[1,0],palette=)\n",
    "axes[1,0].scatter(y_ddcc_train.flatten(),y_1000_train.flatten(),marker='s',label=\"ibm_quebec Train R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),y_1000_train.flatten()):.4f}\",color=cmap[0], edgecolors='black')\n",
    "axes[1,0].scatter(y_ddcc_test.flatten(),y_1000_test.flatten(),label=\"ibm_quebec Test R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),y_1000_test.flatten()):.4f}\",color=cmap[1], edgecolors='black')\n",
    "# sns.scatterplot(data=statevectordf,hue='Data',x='Reference',y='Predicted',style='Data',markers=['d', 'D'], edgecolors='black',ax=axes[1,0],palette=cmap[2:4])\n",
    "axes[1,0].plot(range(-1,2),range(-1,2),'k--')\n",
    "axes[1,0].set_ylim(-spread,spread)\n",
    "axes[1,0].set_xlim(-spread,spread)\n",
    "axes[1,0].set_ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "axes[1,0].set_xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "axes[1,0].legend()\n",
    "\n",
    "\n",
    "# sns.histplot(data=pd.concat([finaldf,statevectordf]),hue='Data',x='Reference',ax=axes[0,0],fill=True,palette=cmap[0:4])\n",
    "# sns.histplot(data=finaldf,hue='Data',x='Reference',ax=axes[0,0],fill=True,palette=cmap[0:2],stat='probability',kde=True)\n",
    "# axes[0,0].set_yscale('log')\n",
    "sns.kdeplot(data=finaldf,hue='Data',x='Reference',ax=axes[0,0],fill=True, bw_adjust=2,palette=cmap[0:2])\n",
    "# sns.kdeplot(data=statevectordf,hue='Data',x='Reference',ax=axes[0,0],fill=True, bw_adjust=2,palette=cmap[3:5])\n",
    "axes[0,0].set_xticklabels([])  # Hide labels but keep ticks\n",
    "axes[0,0].set_xlabel(\"\")  # Remove x-labels\n",
    "axes[0,0].set_xlim(-spread,spread)\n",
    "axes[0,0].set_ylim(1,60)\n",
    "# axes[0,0].legend(loc=3)\n",
    "\n",
    "# sns.histplot(data=pd.concat([finaldf,statevectordf]),hue='Data',y='Predicted',ax=axes[1,1],fill=True,palette=cmap[0:4])\n",
    "# sns.histplot(data=finaldf,hue='Data',y='Predicted',ax=axes[1,1],fill=True,palette=cmap[0:2],stat='probability',kde=True)\n",
    "# axes[1,1].set_xscale('log')\n",
    "sns.kdeplot(data=finaldf,hue='Data',y='Predicted',ax=axes[1,1],fill=True, bw_adjust=2,palette=cmap[0:2])\n",
    "# sns.kdeplot(data=statevectordf,hue='Data',y='Predicted',ax=axes[1,1],fill=True, bw_adjust=2,palette=cmap[3:5])\n",
    "# axes[1,1].set_xticks(np.hstack([0,np.logspace(0,4,3)]))\n",
    "# axes[1,1].set_xticklabels(['0']+[\"10$^{\"+f\"{np.log10(i):n}\"+\"}$\" for i in np.logspace(0,4,3)])  # Hide labels but keep ticks\n",
    "axes[1,1].set_yticklabels([])  # Hide labels but keep ticks\n",
    "axes[1,1].set_ylabel(\"\")  # Remove x-labels\n",
    "axes[1,1].set_ylim(-spread,spread)\n",
    "axes[1,1].set_xlim(1,60)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)  # Adjust width and height spacing\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/finalibm_vs_statevector.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294a3a0-68e4-46a6-9a8d-d90280f8b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([len(y_ddcc_train.flatten())*['Train']]+[len(y_ddcc_test.flatten())*['Test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75269f-de94-489b-be88-6450bfae9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# # Scatter plots\n",
    "# ax.scatter(y_ddcc_train.flatten(), y_1000_train.flatten(), \n",
    "#            label=\"ibm_quebec Train R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(), y_1000_train.flatten()):.4f}\", \n",
    "#            color='b', edgecolors='black')\n",
    "# ax.scatter(y_ddcc_test.flatten(), y_1000_test.flatten(), \n",
    "#            label=\"ibm_quebec Test R$^{2}=$\"+f\"{r2_score(y_ddcc_test.flatten(), y_1000_test.flatten()):.4f}\", \n",
    "#            color='g', edgecolors='black')\n",
    "\n",
    "# sns.scatterplot(data=statevectordf[statevectordf['Data'] == 'Train'], x='Reference', y='Predicted', \n",
    "#                 label=\"State Vector Train: R$^{2}=$\"+f\"{r2_score(statevectordf[statevectordf['Data'] == 'Train']['Reference'], statevectordf[statevectordf['Data'] == 'Train']['Predicted']):.4f}\", \n",
    "#                 ax=ax, edgecolor='black')\n",
    "\n",
    "# sns.scatterplot(data=statevectordf[statevectordf['Data'] == 'Test'], x='Reference', y='Predicted', \n",
    "#                 label=\"State Vector Test: R$^{2}=$\"+f\"{r2_score(statevectordf[statevectordf['Data'] == 'Test']['Reference'], statevectordf[statevectordf['Data'] == 'Test']['Predicted']):.4f}\", \n",
    "#                 ax=ax, edgecolor='black')\n",
    "\n",
    "# # Identity line\n",
    "# ax.plot(np.linspace(-1, 2, 100), np.linspace(-1, 2, 100), 'k--')\n",
    "\n",
    "# ax.set_ylim(-3e-2, 3e-2)\n",
    "# ax.set_xlim(-3e-2, 3e-2)\n",
    "# ax.set_ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "# ax.set_xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "# ax.legend()\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Create twin axes for KDE plots\n",
    "# top_ax = ax.twiny()\n",
    "# right_ax = ax.twinx()\n",
    "\n",
    "# # KDE distributions\n",
    "# sns.kdeplot(statevectordf['Reference'], ax=top_ax, color='gray', lw=2, clip=(-3e-2, 3e-2))\n",
    "# sns.kdeplot(statevectordf['Predicted'], ax=right_ax, color='gray', lw=2, clip=(-3e-2, 3e-2))\n",
    "\n",
    "# # Hide tick labels for KDE axes\n",
    "# top_ax.set_xticks([])\n",
    "# right_ax.set_yticks([])\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b4195-032e-439b-821d-c7c111ebb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(min_MSE_idx,combined_MSE[min_MSE_idx],color='r',label=f'MSE:{combined_MSE[min_MSE_idx]:.4e}')\n",
    "plt.plot(MSE_100+MSE_500+MSE_1000)\n",
    "plt.ylabel('Training Loss (MSE)')\n",
    "plt.xlabel('Iterations')\n",
    "plt.xlim(-10,900)\n",
    "plt.ylim(0,8e-4)\n",
    "# plt.hlines(statevector['MSE_train'][0],-100,1e4,color='r',linestyle='--',label=f'State Vector MSE:{statevector['MSE_train'][0]:.4e}')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/ibmq_loss.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a289863-685f-4f04-9bb9-9fe96aeb4181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
