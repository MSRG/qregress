{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fecc455-f3a5-4ad0-b6fd-b6fe5743f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "import os\n",
    "n_jobs = 16\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_jobs)\n",
    "import joblib\n",
    "import click\n",
    "import json\n",
    "import time\n",
    "from glob import glob\n",
    "import itertools\n",
    "import collections.abc\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "# !{sys.executable} -m pip install qcircuit\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import re\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590beb6d-3eeb-4342-8298-cca35b7a4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat([pd.read_csv(i,index_col=0).dropna() for i in sorted(glob('*csv'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a3045-5adf-4d99-8617-cd6e2c9dbaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 12\n",
    " \n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bbf6d-dc56-49e4-a334-10fc8e7b180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top=os.getcwd()\n",
    "with open(os.path.join(top,'0.1_5_DDCC_train.bin'),'rb') as f:\n",
    "    ddcc_train = joblib.load(f)\n",
    "\n",
    "with open(os.path.join(top,'0.1_5_DDCC_test.bin'),'rb') as f:\n",
    "    ddcc_test = joblib.load(f)\n",
    "\n",
    "with open(os.path.join(top,'0.1_5_DDCC_scaler.bin'),'rb') as f:\n",
    "    ddcc_scaler = joblib.load(f)\n",
    "\n",
    "X_ddcc_train, y_ddcc_train = ddcc_train['X'],ddcc_train['y']\n",
    "X_ddcc_test, y_ddcc_test = ddcc_test['X'],ddcc_test['y']\n",
    "\n",
    "X_ddcc_train = X_ddcc_train.reshape(-1,64,5)\n",
    "X_ddcc_test = X_ddcc_test.reshape(-1,64,5)\n",
    "y_ddcc_train = y_ddcc_train.reshape(-1,64)\n",
    "y_ddcc_test = y_ddcc_test.reshape(-1,64)\n",
    "\n",
    "\n",
    "# X_train, y_train = X_ddcc_train, y_ddcc_train\n",
    "# X_test, y_test = X_ddcc_test, y_ddcc_test\n",
    "X_train, y_train = X_ddcc_train, y_ddcc_train\n",
    "X_test, y_test = X_ddcc_test, y_ddcc_test\n",
    "\n",
    "# X_train = [X_train[i:i+4] for i in range(0,len(X_train),4)]\n",
    "# X_test = [X_test[i:i+4] for i in range(0,len(X_test),4)]\n",
    "scaler = ddcc_scaler\n",
    "\n",
    "# print(len(X_train),X_train[0].shape,X_train[-1].shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33080687-acb6-4977-b3cd-8d43350f607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_data(path):\n",
    "    '''\n",
    "    Given a globbed path, return the job_n.txt, *_train.txt, and *_test.txt files\n",
    "    '''\n",
    "    iterations = []\n",
    "    train_metric = []\n",
    "    test_metric = []\n",
    "    for i in path:\n",
    "        try:\n",
    "            numbers = int(re.search(r'jobs_(\\d+)\\.txt', i).group(1))\n",
    "            iterations.append(i)\n",
    "        except:\n",
    "            if 'test' in i:\n",
    "                test_metric.append(i)\n",
    "            else:\n",
    "                train_metric.append(i)\n",
    "            \n",
    "    return sorted(iterations,key=lambda x: int(re.search(r'jobs_(\\d+)\\.txt', x).group(1))), train_metric, test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d44b0-0b11-46de-907d-1b3417758584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_jobs_from_file(service, filename):\n",
    "    \"\"\"Fetch all job results from a given file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        job_ids = f.readlines()\n",
    "    return [service.job(job_id.strip()).result() for job_id in job_ids]\n",
    "\n",
    "def grab_jobs(lst):\n",
    "    \"\"\"Parallelize over job files, fetching results concurrently.\"\"\"\n",
    "\n",
    "\n",
    "    service = QiskitRuntimeService(\n",
    "        channel='ibm_quantum',\n",
    "        instance='pinq-quebec-hub/univ-toronto/pr-hans-arno-jac'\n",
    "    )\n",
    "    # Parallel processing of files\n",
    "    jobs = Parallel(n_jobs=-1,backend='threading')(\n",
    "        delayed(fetch_jobs_from_file)(service, filename) for filename in tqdm(lst)\n",
    "    )\n",
    "    \n",
    "    return np.array(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eaeb41-c98f-493b-aaba-588dd934216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(job):\n",
    "    try:\n",
    "        return np.array([list(i.data.values()) for i in service.job(job).result()]).flatten()\n",
    "    except:\n",
    "        return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de0b38-29d0-4abb-8f0f-3175cb08c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data=pd.concat([pd.read_csv(i) for i in glob('default_partition/workloads_*/*csv')]).sort_values(by='Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de07be-db3f-4f95-9628-628b05642102",
   "metadata": {},
   "outputs": [],
   "source": [
    "founddata = pd.concat([default_data[default_data['JobId']==i] for i in np.hstack([np.genfromtxt(i,dtype=str) for i in glob('run*/*.txt')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ae2e6-928d-408f-aa05-1356c90f4bd4",
   "metadata": {},
   "source": [
    "# 74 iter left, grab the length of each iter run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d4a45-b029-42d3-bc8f-76212773812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([np.genfromtxt(i,dtype=str) for i in glob('run*/*.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813d27d-87a5-4b0a-92ae-b3c23e7046d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdf = default_data.set_index('JobId').loc[[np.genfromtxt(i,dtype=str) for i in glob('run*/*.txt')][0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6bf62-bb1b-4dbe-b7d8-19a6e25a96d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobsall = []\n",
    "for i in glob('run*/*.txt'):\n",
    "    jobsdf = []\n",
    "    for j in np.genfromtxt(i,dtype=str):\n",
    "        try:\n",
    "            print(j,default_data.set_index('JobId')['Usage (seconds)'].loc[j])\n",
    "            jobsdf.append(default_data.set_index('JobId')['Usage (seconds)'].loc[j])\n",
    "        except:\n",
    "            # print(i)\n",
    "            continue\n",
    "    print(i,jobsdf)\n",
    "    jobsall.append(np.sum(jobsdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ef4f0-4475-4413-aaae-e2fbdcf0c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timings_per_iter = np.array(jobsall)\n",
    "np.mean(timings_per_iter[timings_per_iter!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54c550-a6d9-46af-87da-335a0c12400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(74 * 1351.0618556701031 ) /  60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e642af-c44f-4522-9562-40d037fbf3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1351.0618556701031 / 60) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e7605-1409-40d1-80c7-f7d447398948",
   "metadata": {},
   "outputs": [],
   "source": [
    "(70*4 * 74) / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67685b-9154-4f58-9c0d-b7248e691f19",
   "metadata": {},
   "outputs": [],
   "source": [
    " checkdf['Usage (seconds)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad19180-5f88-49e9-a389-3aae5e1f6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "[default_data[default_data['JobId']==j].shape for j in np.hstack([np.genfromtxt(i,dtype=str) for i in glob('run*/*.txt')])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded6089-458c-4662-bbff-03a1813c80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "founddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fddd6-94fa-47d3-8c7f-ec0dbd1f6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = QiskitRuntimeService(\n",
    "    channel='ibm_quantum',\n",
    "    instance='pinq-quebec-hub/univ-toronto/default'\n",
    ")\n",
    "\n",
    "data =  Parallel(n_jobs=-1)(\n",
    "        delayed(fetch)(i) for i in tqdm(founddata['JobId'])\n",
    "    )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9978e-902d-4a01-a487-d850139d9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ddcc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdfaf72-193e-4a01-a030-60a65f8811be",
   "metadata": {},
   "outputs": [],
   "source": [
    "192 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0803fa-e4a4-474c-83c9-ecc1e5e47925",
   "metadata": {},
   "outputs": [],
   "source": [
    "5502 / 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b6f44-2848-4ad2-8ac9-1c69339f7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack([i for i in data if type(i) is not str]).flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd88bb4-7c28-4096-a49d-2bd531c57afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # three_months_ago = datetime.datetime.now() - datetime.timedelta(days=21)\n",
    " \n",
    "# service = QiskitRuntimeService(\n",
    "#     channel='ibm_quantum',\n",
    "#     instance='pinq-quebec-hub/univ-toronto/default'\n",
    "# )\n",
    "# jobs_in_last_months = service.jobs(created_after=datetime.datetime(2025,5,6),descending=True,instance='pinq-quebec-hub/univ-toronto/default',limit=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba556f-a2a3-422c-8133-623fcd4ec450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_recent =  Parallel(n_jobs=-1)(\n",
    "#         delayed(fetch)(i.job_id()) for i in tqdm(jobs_in_last_months) if i.primitive_id == 'estimator'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddba7f5-bcf4-45b6-b4d9-7e7a7b33dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datadelta = datetime.datetime.now() - datetime.datetime(2025,5,6)\n",
    " \n",
    "service = QiskitRuntimeService(\n",
    "    channel='ibm_quantum',\n",
    "    instance='pinq-quebec-hub/univ-toronto/pr-hans-arno-jac'\n",
    ")\n",
    "jobs_in_last_months = service.jobs(created_after=datadelta,descending=True,instance='pinq-quebec-hub/univ-toronto/pr-hans-arno-jac',limit=None)\n",
    "\n",
    "data_recent =  Parallel(n_jobs=-1)(\n",
    "        delayed(fetch)(i.job_id()) for i in tqdm(jobs_in_last_months) if i.primitive_id == 'estimator'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139da6c-b4d9-4dce-af48-ba902cc39092",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jobs_in_last_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2b23a-1e95-4604-95fd-7fc82c5b77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_recent =  Parallel(n_jobs=-1)(\n",
    "        delayed(fetch)(i.job_id()) for i in tqdm(jobs_in_last_months) if i.primitive_id == 'estimator'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0d442-6ed9-4ff9-8d5d-a98baaf4042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_in_last_months[0].primitive_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6ae920-0429-4abe-b8cd-6b84d516b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_in_last_months[0].job_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920aa73-604e-4a5e-abf6-c6ce025c3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(service.jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8331bd2c-17d4-477a-bf9c-96f9c5728a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = QiskitRuntimeService(\n",
    "    channel='ibm_quantum',\n",
    "    instance='pinq-quebec-hub/univ-toronto/default'\n",
    ")\n",
    "service.job('d0crshyd8drg008zaby0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597cc7b-1754-4eed-9377-cb2b7396d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(service.jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b05e14-4ec2-4457-9a30-1b7a4f5dbdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_months_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2edc09-36f4-446b-a22e-4e8aadfd1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_in_last_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b690c-d1db-41b6-9799-9cac4839d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobids = []\n",
    "for i in sorted(glob(\"run*/*txt\"),key=lambda x: (x.split('/')[0],int(x.split('/')[1].replace('jobs_','').replace('.txt','')))):\n",
    "    with open(i,'r') as f:\n",
    "        jobids.append([i.strip() for i in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95354dd6-19ef-4ae2-964d-5b546b76e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "[i.job_id() for i in jobs_in_last_months if i.job_id() in sum(jobids,[])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac59f1-54e7-46a8-bc21-79d4a1ef868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in sorted(glob('run*')):\n",
    "    if os.path.isdir(i):\n",
    "        print(i)\n",
    "        try:\n",
    "            data.append(grab_jobs(sorted(glob(os.path.join(i,'job*txt')),key=lambda x: int(x.split('/')[1].replace('jobs_','').replace('.txt','')))))\n",
    "        except:\n",
    "            print(f\"This one is cooked {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7e36d-1267-41a7-9a5f-f48dc39e1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = grab_jobs(sorted(glob(\"run*/*txt\"),key=lambda x: (x.split('/')[0],int(x.split('/')[1].replace('jobs_','').replace('.txt',''))))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502bb51-b905-4ee1-91d9-27262aa4aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_10 = grab_jobs(iter_10)\n",
    "# y_10 = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_10]).reshape(*results_10.shape)\n",
    "\n",
    "# with open('y_10.npy', 'wb') as f:\n",
    "#     np.save(f, y_10)\n",
    "\n",
    "\n",
    "# results_train_10 = grab_jobs(train_10)\n",
    "# y_10_train = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_train_10]).reshape(*y_train.shape)\n",
    "\n",
    "# results_test_10 = grab_jobs(test_10)\n",
    "# y_10_test = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_test_10]).reshape(*y_test.shape)\n",
    "\n",
    "# with open('y_10_test.npy', 'wb') as f:\n",
    "#     np.save(f, y_10_test)\n",
    "# with open('y_10_train.npy', 'wb') as f:\n",
    "#     np.save(f, y_10_train)\n",
    "    \n",
    "# results_100 = grab_jobs(iter_100)\n",
    "# y_100 = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_100]).reshape(*results_100.shape)\n",
    "\n",
    "# results_500 = grab_jobs(iter_500)\n",
    "# y_500 = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_500]).reshape(*results_500.shape)\n",
    "\n",
    "# results_1000 = grab_jobs(iter_1000)\n",
    "# y_1000 = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_1000]).reshape(*results_1000.shape)\n",
    "# with open('y_100.npy', 'wb') as f:\n",
    "#     np.save(f, y_100)\n",
    "# with open('y_500.npy', 'wb') as f:\n",
    "#     np.save(f, y_500)\n",
    "# with open('y_1000.npy', 'wb') as f:\n",
    "#     np.save(f, y_1000)\n",
    "\n",
    "# results_train_100 = grab_jobs(train_100)\n",
    "# y_100_train = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_train_100]).reshape(*y_train.shape)\n",
    "\n",
    "\n",
    "# results_train_500 = grab_jobs(train_500)\n",
    "# y_500_train = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_train_500]).reshape(*y_train.shape)\n",
    "\n",
    "# results_train_1000 = grab_jobs(train_1000)\n",
    "# y_1000_train = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_train_1000]).reshape(*y_train.shape)\n",
    "\n",
    "# results_test_100 = grab_jobs(test_100)\n",
    "# y_100_test = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_test_100]).reshape(*y_test.shape)\n",
    "\n",
    "\n",
    "# results_test_500 = grab_jobs(test_500)\n",
    "# y_500_test = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_test_500]).reshape(*y_test.shape)\n",
    "\n",
    "# results_test_1000 = grab_jobs(test_1000)\n",
    "# y_1000_test = np.array([[[k.data.evs.flatten() for k in j] for j in i] for i in results_test_1000]).reshape(*y_test.shape)\n",
    "\n",
    "    \n",
    "# with open('y_100_test.npy', 'wb') as f:\n",
    "#     np.save(f, y_100_test)\n",
    "# with open('y_500_test.npy', 'wb') as f:\n",
    "#     np.save(f, y_500_test)\n",
    "# with open('y_1000_test.npy', 'wb') as f:\n",
    "#     np.save(f, y_1000_test)\n",
    "\n",
    "\n",
    "# with open('y_100_train.npy', 'wb') as f:\n",
    "#     np.save(f, y_100_train)\n",
    "# with open('y_500_train.npy', 'wb') as f:\n",
    "#     np.save(f, y_500_train)\n",
    "# with open('y_1000_train.npy', 'wb') as f:\n",
    "#     np.save(f, y_1000_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a3b3b-8210-43df-879a-91b203e261e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_10_test.npy', 'rb') as f:\n",
    "    y_10_test = np.load(f)\n",
    "\n",
    "with open('y_100_test.npy', 'rb') as f:\n",
    "    y_100_test = np.load(f)\n",
    "with open('y_500_test.npy', 'rb') as f:\n",
    "    y_500_test = np.load(f)\n",
    "with open('y_1000_test.npy', 'rb') as f:\n",
    "    y_1000_test = np.load(f)   \n",
    "\n",
    "\n",
    "with open('y_10_train.npy', 'rb') as f:\n",
    "    y_10_train = np.load(f)    \n",
    "with open('y_100_train.npy', 'rb') as f:\n",
    "    y_100_train = np.load(f)\n",
    "with open('y_500_train.npy', 'rb') as f:\n",
    "    y_500_train = np.load(f)\n",
    "with open('y_1000_train.npy', 'rb') as f:\n",
    "    y_1000_train = np.load(f)       \n",
    "\n",
    "\n",
    "with open('y_10.npy', 'rb') as f:\n",
    "    y_10 = np.load(f)\n",
    "with open('y_100.npy', 'rb') as f:\n",
    "    y_100 = np.load(f)\n",
    "with open('y_500.npy', 'rb') as f:\n",
    "    y_500 = np.load(f)\n",
    "with open('y_1000.npy', 'rb') as f:\n",
    "    y_1000 = np.load(f)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d12db-95d8-47c2-b26d-f9e99100793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_10_test = scaler.inverse_transform(y_10_test.flatten().reshape(-1,1)).flatten()\n",
    "y_100_test = scaler.inverse_transform(y_100_test.flatten().reshape(-1,1)).flatten()\n",
    "y_500_test = scaler.inverse_transform(y_500_test.flatten().reshape(-1,1)).flatten()\n",
    "y_1000_test = scaler.inverse_transform(y_1000_test.flatten().reshape(-1,1)).flatten()\n",
    "\n",
    "y_10_train = scaler.inverse_transform(y_10_train.flatten().reshape(-1,1)).flatten()\n",
    "y_100_train = scaler.inverse_transform(y_100_train.flatten().reshape(-1,1)).flatten()\n",
    "y_500_train = scaler.inverse_transform(y_500_train.flatten().reshape(-1,1)).flatten()\n",
    "y_1000_train = scaler.inverse_transform(y_1000_train.flatten().reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d754711-43f1-494b-9945-2594386be704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deec282-32e7-4ada-b0f5-b41701579865",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_10 = scaler.inverse_transform(y_10.flatten().reshape(-1,1)).reshape(*y_10.shape)\n",
    "y_100 = scaler.inverse_transform(y_100.flatten().reshape(-1,1)).reshape(*y_100.shape)\n",
    "y_500 = scaler.inverse_transform(y_500.flatten().reshape(-1,1)).reshape(*y_500.shape)\n",
    "y_1000 = scaler.inverse_transform(y_1000.flatten().reshape(-1,1)).reshape(*y_1000.shape)\n",
    "\n",
    "\n",
    "\n",
    "y_ddcc_train = scaler.inverse_transform(y_ddcc_train.flatten().reshape(-1,1)).reshape(*y_ddcc_train.shape)\n",
    "y_ddcc_test = scaler.inverse_transform(y_ddcc_test.flatten().reshape(-1,1)).reshape(*y_ddcc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cbde5-ac28-42af-a2de-ddc015312014",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_ddcc_train.flatten(),y_10_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df45f43-4282-4fdc-b440-4e15e16cf5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_ddcc_train.flatten(),y_100_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453521fe-1d71-4a81-8aa6-359dffd68322",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_ddcc_train.flatten(),y_500_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c795150-67cc-43b3-a6c5-859ed3dabc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_ddcc_train.flatten(),y_1000_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8e14b-38f3-4be3-8917-bb9720a67c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_10 = [mean_squared_error(y_ddcc_train.flatten(),i.flatten()) for i in y_10]\n",
    "MSE_100 = [mean_squared_error(y_ddcc_train.flatten(),i.flatten()) for i in y_100]\n",
    "MSE_500 = [mean_squared_error(y_ddcc_train.flatten(),i.flatten()) for i in y_500]\n",
    "MSE_1000 = [mean_squared_error(y_ddcc_train.flatten(),i.flatten()) for i in y_1000]\n",
    "\n",
    "combined_MSE = MSE_10+MSE_100+MSE_500+MSE_1000\n",
    "min_MSE_idx = np.argmin(MSE_10+MSE_100+MSE_500+MSE_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce0f14-c6da-41f2-89c0-9279d5328aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train = np.vstack([y_10,y_100,y_500,y_1000])[min_MSE_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04270795-ef31-4f67-8262-6c75b13f7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.expanduser('~'),'qregress/qml_DDCC/RUD_AL/5AL/A2_HWE-CNOT/A2_HWE-CNOT_results.json')) as f:\n",
    "    statevector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fafb5a-52d2-4d5b-b3f7-b6054f61d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "'/Users/grierjones/qregress/qml_DDCC/RUD_AL/5AL/A2_HWE-CNOT/A2_HWE-CNOT_predicted_values.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a822dc-5b1d-40c1-89b2-507cc7feed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "statevectordf = pd.read_csv(os.path.join(os.path.expanduser('~'),'qregress/qml_DDCC/RUD_AL/5AL/A2_HWE-CNOT/A2_HWE-CNOT_predicted_values.csv'))\n",
    "statevectordf['Predicted'] = [float(i.strip('[]')) for i in statevectordf['Predicted']]\n",
    "statevectordf['Reference'] = [float(i.strip('[]')) for i in statevectordf['Reference']]\n",
    "statevectordf['Device'] = len(statevectordf)*['State Vector']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601fa68-f8d8-45f7-adc6-a90f78a07ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "statevectordf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612215e6-863e-4f37-8f01-947ec37b0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbest = pd.DataFrame(np.vstack([y_ddcc_train.flatten(),best_train.flatten()]),index=['Reference','Predicted']).T\n",
    "dfbest['Device'] = len(dfbest)*['ibm_quebec']\n",
    "dfbest['Data'] = len(dfbest)*['Train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e887875-8253-4dc2-b72f-01ed0ebee694",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 10e-2\n",
    "# Create the figure with a 2D grid (scatter + KDE for Predicted + KDE for Reference)\n",
    "fig, axes = plt.subplots(\n",
    "    2, 2, \n",
    "    figsize=(8, 8),\n",
    "    gridspec_kw={'width_ratios': [4, 1], 'height_ratios': [1, 4]},\n",
    "    constrained_layout=True,\n",
    "    # sharey='row',  # Keep y-axis sharing, but remove sharex to control ticks manually,\n",
    "    # sharex='col'\n",
    ")\n",
    "axes[0, -1].axis(\"off\")\n",
    "sns.scatterplot(data=dfbest,x='Reference',y='Predicted',label=\"Best ibm_quebec: R$^{2}=$\"+f\"{r2_score(dfbest['Reference'],dfbest['Predicted']):.4f}\", edgecolors='black',ax=axes[1,0])\n",
    "# sns.scatterplot(data=statevectordf[statevectordf['Data']=='Train'],x='Reference',y='Predicted',label=\"State Vector: R$^{2}=$\"+f\"{r2_score(statevectordf['Reference'],statevectordf['Predicted']):.4f}\", edgecolors='black',ax=axes[1,0])\n",
    "axes[1,0].plot(range(-1,2),range(-1,2),'k--')\n",
    "axes[1,0].set_ylim(-spread,spread)\n",
    "axes[1,0].set_xlim(-spread,spread)\n",
    "axes[1,0].set_ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "axes[1,0].set_xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "axes[1,0].legend()\n",
    "\n",
    "\n",
    "# sns.kdeplot(data=pd.concat([dfbest,statevectordf[statevectordf['Data']=='Train']]),hue='Device',x='Reference',ax=axes[0,0],fill=True)\n",
    "sns.kdeplot(data=dfbest,x='Reference',ax=axes[0,0],fill=True, bw_adjust=2)\n",
    "# sns.kdeplot(data=statevectordf[statevectordf['Data']=='Train'],x='Reference',ax=axes[0,0],fill=True, bw_adjust=2)\n",
    "axes[0,0].set_xticklabels([])  # Hide labels but keep ticks\n",
    "axes[0,0].set_xlabel(\"\")  # Remove x-labels\n",
    "axes[0,0].set_xlim(-spread,spread)\n",
    "axes[0,0].set_ylim(0,100)\n",
    "\n",
    "# sns.kdeplot(data=pd.concat([dfbest,statevectordf[statevectordf['Data']=='Train']]),hue='Device',y='Predicted',ax=axes[1,1],fill=True)\n",
    "sns.kdeplot(data=dfbest,y='Predicted',ax=axes[1,1],fill=True, bw_adjust=2)\n",
    "# sns.kdeplot(data=statevectordf[statevectordf['Data']=='Train'],y='Predicted',ax=axes[1,1],fill=True, bw_adjust=2)\n",
    "axes[1,1].set_yticklabels([])  # Hide labels but keep ticks\n",
    "axes[1,1].set_ylabel(\"\")  # Remove x-labels\n",
    "axes[1,1].set_ylim(-spread,spread)\n",
    "axes[1,1].set_xlim(0,100)\n",
    "# plt.subplots_adjust(wspace=0.1, hspace=0.1)  # Adjust width and height spacing\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/bestibm_vs_statevector.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e898e8f-cecb-4898-b042-6d386ac8bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.scatter(y_ddcc_train.flatten(),best_train.flatten(),label=\"Best ibm_quebec R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),best_train.flatten()):.4f}\",color='r', edgecolors='black')\n",
    "# sns.scatterplot(data=dfbest,x='Reference',y='Predicted',label=\"Best ibm_quebec: R$^{2}=$\"+f\"{r2_score(dfbest['Reference'],dfbest['Predicted']):.4f}\", edgecolors='black')\n",
    "# sns.scatterplot(data=statevectordf[statevectordf['Data']=='Train'],x='Reference',y='Predicted',label=\"State Vector: R$^{2}=$\"+f\"{r2_score(statevectordf['Reference'],statevectordf['Predicted']):.4f}\", edgecolors='black')\n",
    "# plt.plot(range(-1,2),range(-1,2),'k--')\n",
    "# plt.ylim(-3e-2,3e-2)\n",
    "# plt.xlim(-3e-2,3e-2)\n",
    "# plt.ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "# plt.xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/bestibm_vs_statevector.png'),dpi=300,bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5cf020-25c7-4948-aa30-6fe869ba705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_ddcc_train.flatten(),y_1000_train.flatten(),label=\"ibm_quebec Train R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),y_1000_train.flatten()):.4f}\",color='b', edgecolors='black')\n",
    "plt.scatter(y_ddcc_test.flatten(),y_1000_test.flatten(),label=\"ibm_quebec Test R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),y_1000_test.flatten()):.4f}\",color='g', edgecolors='black')\n",
    "sns.scatterplot(data=statevectordf[statevectordf['Data']=='Train'],x='Reference',y='Predicted',label=\"State Vector Train: R$^{2}=$\"+f\"{r2_score(statevectordf[statevectordf['Data']=='Train']['Reference'],statevectordf[statevectordf['Data']=='Train']['Predicted']):.4f}\", edgecolors='black')\n",
    "sns.scatterplot(data=statevectordf[statevectordf['Data']=='Test'],x='Reference',y='Predicted',label=\"State Vector Test: R$^{2}=$\"+f\"{r2_score(statevectordf[statevectordf['Data']=='Test']['Reference'],statevectordf[statevectordf['Data']=='Test']['Predicted']):.4f}\", edgecolors='black')\n",
    "plt.plot(range(-1,2),range(-1,2),'k--')\n",
    "plt.ylim(-3e-2,3e-2)\n",
    "plt.xlim(-3e-2,3e-2)\n",
    "plt.ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "plt.xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/finalibm_vs_statevector.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa8eaa-6589-456f-822f-c307be0c7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.DataFrame(np.hstack([np.vstack([y_ddcc_train.flatten(),y_1000_train.flatten()]),np.vstack([y_ddcc_test.flatten(),y_1000_test.flatten()])]),index=['Reference','Predicted']).T\n",
    "finaldf['Data'] = len(y_ddcc_train.flatten())*['Train']+len(y_ddcc_test.flatten())*['Test']\n",
    "finaldf['Device'] = len(finaldf)*['ibm_quebec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b2c43-e3c5-4513-9179-cab93a152fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ddcc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c356d95-cc29-4430-9361-0c3b810a16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette('Paired',6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aeae6c-89fa-460f-b708-a1feea5c5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d0775-ff44-49bd-95bd-44f87d4a19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf[\"Data\"] = finaldf[\"Data\"] + \" (\" + finaldf[\"Device\"] + \")\"\n",
    "statevectordf[\"Data\"] = statevectordf[\"Data\"] + \" (\" + statevectordf[\"Device\"] + \")\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66beef69-94aa-43ed-ad37-fb81ada507ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "statevectordf['Reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90774dc-0ccf-4f9e-abb8-166ddebe0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a18f7-3df5-4f2f-b243-811303fb5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1000_train.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d0b77-d0ed-4e46-9288-7acaa657d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 10e-2\n",
    "# Create the figure with a 2D grid (scatter + KDE for Predicted + KDE for Reference)\n",
    "fig, axes = plt.subplots(\n",
    "    2, 2, \n",
    "    figsize=(10, 10),\n",
    "    gridspec_kw={'width_ratios': [4, 1.7], 'height_ratios': [1.7, 4]},\n",
    "    constrained_layout=True,\n",
    "    # sharey='row',  # Keep y-axis sharing, but remove sharex to control ticks manually,\n",
    "    # sharex='col'\n",
    ")\n",
    "axes[0, -1].axis(\"off\")\n",
    "# sns.scatterplot(data=finaldf,x='Reference',y='Predicted',hue='Data',style='Data',markers=['o', 's'], edgecolors='black',ax=axes[1,0],palette=)\n",
    "axes[1,0].scatter(y_ddcc_train.flatten(),y_1000_train.flatten(),marker='s',label=\"ibm_quebec Train R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),y_1000_train.flatten()):.4f}\",color=cmap[0], edgecolors='black')\n",
    "axes[1,0].scatter(y_ddcc_test.flatten(),y_1000_test.flatten(),label=\"ibm_quebec Test R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(),y_1000_test.flatten()):.4f}\",color=cmap[1], edgecolors='black')\n",
    "# sns.scatterplot(data=statevectordf,hue='Data',x='Reference',y='Predicted',style='Data',markers=['d', 'D'], edgecolors='black',ax=axes[1,0],palette=cmap[2:4])\n",
    "axes[1,0].plot(range(-1,2),range(-1,2),'k--')\n",
    "axes[1,0].set_ylim(-spread,spread)\n",
    "axes[1,0].set_xlim(-spread,spread)\n",
    "axes[1,0].set_ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "axes[1,0].set_xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "axes[1,0].legend()\n",
    "\n",
    "\n",
    "# sns.histplot(data=pd.concat([finaldf,statevectordf]),hue='Data',x='Reference',ax=axes[0,0],fill=True,palette=cmap[0:4])\n",
    "# sns.histplot(data=finaldf,hue='Data',x='Reference',ax=axes[0,0],fill=True,palette=cmap[0:2],stat='probability',kde=True)\n",
    "# axes[0,0].set_yscale('log')\n",
    "sns.kdeplot(data=finaldf,hue='Data',x='Reference',ax=axes[0,0],fill=True, bw_adjust=2,palette=cmap[0:2])\n",
    "# sns.kdeplot(data=statevectordf,hue='Data',x='Reference',ax=axes[0,0],fill=True, bw_adjust=2,palette=cmap[3:5])\n",
    "axes[0,0].set_xticklabels([])  # Hide labels but keep ticks\n",
    "axes[0,0].set_xlabel(\"\")  # Remove x-labels\n",
    "axes[0,0].set_xlim(-spread,spread)\n",
    "axes[0,0].set_ylim(1,60)\n",
    "# axes[0,0].legend(loc=3)\n",
    "\n",
    "# sns.histplot(data=pd.concat([finaldf,statevectordf]),hue='Data',y='Predicted',ax=axes[1,1],fill=True,palette=cmap[0:4])\n",
    "# sns.histplot(data=finaldf,hue='Data',y='Predicted',ax=axes[1,1],fill=True,palette=cmap[0:2],stat='probability',kde=True)\n",
    "# axes[1,1].set_xscale('log')\n",
    "sns.kdeplot(data=finaldf,hue='Data',y='Predicted',ax=axes[1,1],fill=True, bw_adjust=2,palette=cmap[0:2])\n",
    "# sns.kdeplot(data=statevectordf,hue='Data',y='Predicted',ax=axes[1,1],fill=True, bw_adjust=2,palette=cmap[3:5])\n",
    "# axes[1,1].set_xticks(np.hstack([0,np.logspace(0,4,3)]))\n",
    "# axes[1,1].set_xticklabels(['0']+[\"10$^{\"+f\"{np.log10(i):n}\"+\"}$\" for i in np.logspace(0,4,3)])  # Hide labels but keep ticks\n",
    "axes[1,1].set_yticklabels([])  # Hide labels but keep ticks\n",
    "axes[1,1].set_ylabel(\"\")  # Remove x-labels\n",
    "axes[1,1].set_ylim(-spread,spread)\n",
    "axes[1,1].set_xlim(1,60)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)  # Adjust width and height spacing\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/finalibm_vs_statevector.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294a3a0-68e4-46a6-9a8d-d90280f8b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([len(y_ddcc_train.flatten())*['Train']]+[len(y_ddcc_test.flatten())*['Test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75269f-de94-489b-be88-6450bfae9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# # Scatter plots\n",
    "# ax.scatter(y_ddcc_train.flatten(), y_1000_train.flatten(), \n",
    "#            label=\"ibm_quebec Train R$^{2}=$\"+f\"{r2_score(y_ddcc_train.flatten(), y_1000_train.flatten()):.4f}\", \n",
    "#            color='b', edgecolors='black')\n",
    "# ax.scatter(y_ddcc_test.flatten(), y_1000_test.flatten(), \n",
    "#            label=\"ibm_quebec Test R$^{2}=$\"+f\"{r2_score(y_ddcc_test.flatten(), y_1000_test.flatten()):.4f}\", \n",
    "#            color='g', edgecolors='black')\n",
    "\n",
    "# sns.scatterplot(data=statevectordf[statevectordf['Data'] == 'Train'], x='Reference', y='Predicted', \n",
    "#                 label=\"State Vector Train: R$^{2}=$\"+f\"{r2_score(statevectordf[statevectordf['Data'] == 'Train']['Reference'], statevectordf[statevectordf['Data'] == 'Train']['Predicted']):.4f}\", \n",
    "#                 ax=ax, edgecolor='black')\n",
    "\n",
    "# sns.scatterplot(data=statevectordf[statevectordf['Data'] == 'Test'], x='Reference', y='Predicted', \n",
    "#                 label=\"State Vector Test: R$^{2}=$\"+f\"{r2_score(statevectordf[statevectordf['Data'] == 'Test']['Reference'], statevectordf[statevectordf['Data'] == 'Test']['Predicted']):.4f}\", \n",
    "#                 ax=ax, edgecolor='black')\n",
    "\n",
    "# # Identity line\n",
    "# ax.plot(np.linspace(-1, 2, 100), np.linspace(-1, 2, 100), 'k--')\n",
    "\n",
    "# ax.set_ylim(-3e-2, 3e-2)\n",
    "# ax.set_xlim(-3e-2, 3e-2)\n",
    "# ax.set_ylabel(\"Predicted t$_{2}$-amplitudes\")\n",
    "# ax.set_xlabel(\"Calculated t$_{2}$-amplitudes\")\n",
    "# ax.legend()\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Create twin axes for KDE plots\n",
    "# top_ax = ax.twiny()\n",
    "# right_ax = ax.twinx()\n",
    "\n",
    "# # KDE distributions\n",
    "# sns.kdeplot(statevectordf['Reference'], ax=top_ax, color='gray', lw=2, clip=(-3e-2, 3e-2))\n",
    "# sns.kdeplot(statevectordf['Predicted'], ax=right_ax, color='gray', lw=2, clip=(-3e-2, 3e-2))\n",
    "\n",
    "# # Hide tick labels for KDE axes\n",
    "# top_ax.set_xticks([])\n",
    "# right_ax.set_yticks([])\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35577954-5f08-4932-b7d7-1444ed3e2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MSE_10+MSE_100+MSE_500+MSE_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b4195-032e-439b-821d-c7c111ebb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(min_MSE_idx,combined_MSE[min_MSE_idx],color='r',label=f'MSE:{combined_MSE[min_MSE_idx]:.4e}')\n",
    "plt.plot(range(1,len(MSE_10+MSE_100+MSE_500+MSE_1000)+1),MSE_10+MSE_100+MSE_500+MSE_1000)\n",
    "plt.ylabel('Training Loss (MSE)')\n",
    "plt.xlabel('Iterations')\n",
    "plt.xlim(0,900)\n",
    "plt.ylim(0,8e-4)\n",
    "# plt.hlines(statevector['MSE_train'][0],-100,1e4,color='r',linestyle='--',label=f'State Vector MSE:{statevector['MSE_train'][0]:.4e}')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.expanduser('~'),'qregress/images/DDCC/ibmq_loss.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a289863-685f-4f04-9bb9-9fe96aeb4181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
