{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ab896-3476-4635-8df6-2b82ae6a7e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install seaborn\n",
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import joblib\n",
    "import click\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import collections.abc\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from qiskit_ibm_provider import IBMProvider\n",
    "\n",
    "from quantum.Quantum import QuantumRegressor\n",
    "from quantum.Evaluate import evaluate\n",
    "from settings import ANSATZ_LIST, ENCODER_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026786d6-c985-4ace-82df-8e8429da2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "OPTIMIZER = None\n",
    "SHOTS = None\n",
    "X_DIM = None\n",
    "BACKEND = None\n",
    "DEVICE = None\n",
    "SCALE_FACTORS = None\n",
    "ANSATZ = None\n",
    "ENCODER = None\n",
    "POSTPROCESS = None\n",
    "ERROR_MITIGATION = None\n",
    "LAYERS = None\n",
    "PROVIDER = None\n",
    "TOKEN = None\n",
    "HYPERPARAMETERS = None\n",
    "RE_UPLOAD_DEPTH = None\n",
    "MAX_ITER = None\n",
    "TOLERANCE = None\n",
    "NUM_QUBITS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6afbb0-444e-486b-8663-11fc5abbf95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Utility functions\n",
    "############################################\n",
    "\n",
    "\n",
    "def parse_settings(settings_file):\n",
    "    with open(settings_file, 'r') as fp:\n",
    "        settings = json.load(fp)\n",
    "\n",
    "    global OPTIMIZER\n",
    "    OPTIMIZER = settings['OPTIMIZER']\n",
    "\n",
    "    global SHOTS\n",
    "    SHOTS = settings['SHOTS']\n",
    "\n",
    "    global BACKEND\n",
    "    BACKEND = settings['BACKEND']\n",
    "\n",
    "    global DEVICE\n",
    "    DEVICE = settings['DEVICE']\n",
    "\n",
    "    global SCALE_FACTORS\n",
    "    SCALE_FACTORS = settings['SCALE_FACTORS']\n",
    "\n",
    "    global POSTPROCESS\n",
    "    POSTPROCESS = settings['POSTPROCESS']\n",
    "\n",
    "    global ERROR_MITIGATION\n",
    "    ERROR_MITIGATION = settings['ERROR_MITIGATION']\n",
    "\n",
    "    global LAYERS\n",
    "    LAYERS = settings['LAYERS']\n",
    "\n",
    "    global HYPERPARAMETERS\n",
    "    HYPERPARAMETERS = settings['HYPERPARAMETERS']\n",
    "    # f was removed from HYPERPARAMETERS, this ensures old settings files can still run.\n",
    "    if 'f' in HYPERPARAMETERS.keys():\n",
    "        _ = HYPERPARAMETERS.pop('f', None)\n",
    "\n",
    "    global RE_UPLOAD_DEPTH\n",
    "    RE_UPLOAD_DEPTH = settings['RE-UPLOAD_DEPTH']\n",
    "\n",
    "    global MAX_ITER\n",
    "    MAX_ITER = settings['MAX_ITER']\n",
    "\n",
    "    global TOLERANCE\n",
    "    try:\n",
    "        TOLERANCE = settings['TOLERANCE']\n",
    "    except KeyError:\n",
    "        TOLERANCE = None\n",
    "\n",
    "    global NUM_QUBITS\n",
    "    try:\n",
    "        NUM_QUBITS = settings['NUM_QUBITS']\n",
    "    except KeyError:\n",
    "        NUM_QUBITS = None\n",
    "\n",
    "    # classes aren't JSON serializable, so we store the key in the settings file and access it here.\n",
    "    global ANSATZ\n",
    "    ANSATZ = ANSATZ_LIST[settings['ANSATZ']]\n",
    "\n",
    "    global ENCODER\n",
    "    ENCODER = ENCODER_LIST[settings['ENCODER']]\n",
    "\n",
    "\n",
    "def load_dataset(file):\n",
    "    print(f'Loading dataset from {file}... ')\n",
    "    data = joblib.load(file)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "    global X_DIM\n",
    "    _, X_DIM = X.shape\n",
    "    print(f'Successfully loaded {file} into X and y data. ')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def save_token(instance, token):\n",
    "    global PROVIDER\n",
    "    PROVIDER = IBMProvider(instance=instance)\n",
    "    global TOKEN\n",
    "    TOKEN = token\n",
    "\n",
    "\n",
    "############################################\n",
    "# Main\n",
    "############################################\n",
    "\n",
    "def main(settings, train_set, test_set, scaler, instance, token, save_circuits, title, resume_file):\n",
    "    \"\"\"\n",
    "    Trains the quantum regressor with the settings in the given settings file using the dataset from the given train\n",
    "    and test files. Will perform grid search on a default hyperparameter space unless they are specified. Saves scores\n",
    "    and best hyperparameters to joblib dumps and graphs of performance and circuit drawings as mpl svg.\n",
    "    \"\"\"\n",
    "    X_train, y_train = load_dataset(train_set)\n",
    "    parse_settings(settings)\n",
    "    if DEVICE == 'qiskit.ibmq':\n",
    "        save_token(instance, token)\n",
    "\n",
    "    global NUM_QUBITS\n",
    "    global X_DIM\n",
    "    if NUM_QUBITS is not None:\n",
    "        X_DIM = NUM_QUBITS\n",
    "    elif X_DIM == 1:  # if X_DIM is None and num_qubits wasn't specified anywhere use a default value of 2.\n",
    "        NUM_QUBITS = 2\n",
    "        X_DIM = NUM_QUBITS\n",
    "\n",
    "    kwargs = create_kwargs()\n",
    "\n",
    "    if title is None:\n",
    "        title = os.path.basename(settings)\n",
    "        title, _ = os.path.splitext(title)\n",
    "\n",
    "    if save_circuits:\n",
    "        plot_circuits(title)\n",
    "\n",
    "    if test_set is not None:\n",
    "        X_test, y_test = load_dataset(test_set)\n",
    "    else:\n",
    "        X_test, y_test = None, None\n",
    "\n",
    "    scaler = joblib.load(scaler)\n",
    "\n",
    "    print(f'Training model with dataset {train_set} \\n at time {time.asctime()}... ')\n",
    "    st = time.time()\n",
    "\n",
    "    if len(HYPERPARAMETERS['alpha']) != 1:\n",
    "        model, hyperparams, _, _ = grid_search(QuantumRegressor, HYPERPARAMETERS, X_train, y_train, **kwargs)\n",
    "    else:\n",
    "        model = QuantumRegressor(**kwargs)\n",
    "        model.fit(X_train, y_train, load_state=resume_file)\n",
    "        hyperparams = None\n",
    "\n",
    "    et = time.time()\n",
    "    print(f'Training complete taking {et - st} total seconds. ')\n",
    "\n",
    "    # removes temporary file created during training.\n",
    "    if os.path.exists(title + '_tentative_model.bin'):\n",
    "        os.remove('tentative_model.bin')\n",
    "    elif os.path.exists('tentative_model.bin'):\n",
    "        os.remove('tentative_model.bin')\n",
    "\n",
    "    scores, test_pred, train_pred = evaluate(model, X_train, y_train, X_test, y_test, plot=True, title=title,\n",
    "                                             y_scaler=scaler)\n",
    "    y_train = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "    y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    name = title + '_predicted_values.csv'\n",
    "    train_pred, y_train, test_pred, y_test = train_pred.tolist(), y_train.tolist(), test_pred.tolist(), y_test.tolist()\n",
    "    df_train = pd.DataFrame({'Predicted': train_pred, 'Reference': y_train})\n",
    "    df_train['Data'] = 'Train'\n",
    "    df_test = pd.DataFrame({'Predicted': test_pred, 'Reference': y_test})\n",
    "    df_test['Data'] = 'Test'\n",
    "    df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "    df = df[['Data', 'Predicted', 'Reference']]\n",
    "\n",
    "    df.to_csv(name, index=False)\n",
    "    print(f'Saved predicted values as {name}')\n",
    "\n",
    "    print(f'Model scores: {scores}. ')\n",
    "\n",
    "    results = scores\n",
    "\n",
    "    if len(HYPERPARAMETERS['alpha']) != 1:\n",
    "        results['hyperparameters'] = hyperparams\n",
    "    results_title = title + '_results.json'\n",
    "    with open(results_title, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "        pass\n",
    "    print(f'Saved model results as {results_title}. ')\n",
    "\n",
    "\n",
    "def plot_circuits(title):\n",
    "    draw_ansatz = qml.draw_mpl(ANSATZ)\n",
    "    draw_ansatz(np.random.rand(ANSATZ.num_params))\n",
    "    plt.savefig(title + '_ansatz.svg')\n",
    "\n",
    "    draw_encoder = qml.draw_mpl(ENCODER)\n",
    "    draw_encoder(np.random.rand(X_DIM), range(X_DIM))\n",
    "    plt.savefig(title + '_encoder.svg')\n",
    "\n",
    "\n",
    "def create_kwargs():\n",
    "    #  First have to apply specific ansatz settings: setting number of layers and the number of wires based on features\n",
    "    ANSATZ.layers = LAYERS\n",
    "    ANSATZ.set_wires(range(X_DIM))\n",
    "\n",
    "    kwargs = {\n",
    "        'encoder': ENCODER,\n",
    "        'variational': ANSATZ,\n",
    "        'num_qubits': X_DIM,\n",
    "#       'optimizer': OPTIMIZER,\n",
    "        'optimizer': \"BFGS\",\n",
    "        'max_iterations': MAX_ITER,\n",
    "        'tol': TOLERANCE,\n",
    "        'device': DEVICE,\n",
    "        'backend': BACKEND,\n",
    "        'postprocess': POSTPROCESS,\n",
    "        'error_mitigation': ERROR_MITIGATION,\n",
    "        'provider': PROVIDER,\n",
    "        'token': TOKEN,\n",
    "        're_upload_depth': RE_UPLOAD_DEPTH,\n",
    "    }\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def grid_search(model, hyperparameters: dict, X, y, folds: int = 5, **kwargs):\n",
    "    \"\"\"\n",
    "    Performs a grid search on the given model. Trains the model for each combination of hyperparameters. Scores each\n",
    "    model using MSE on the test fold using k-fold cross-validation saves the average across the folds as score and\n",
    "    returns the best performing model with its score and hyperparameters. Any additional parameters to be passed to\n",
    "    the model are handled with kwargs.\n",
    "\n",
    "    :return: trained_model, dict: best_hyperparameters, flaot: best_score, dict: results\n",
    "    \"\"\"\n",
    "    for x in hyperparameters.values():\n",
    "        if not isinstance(x, collections.abc.Sequence):\n",
    "            raise ValueError('Dictionary must contain list-like objects of values to try! ')\n",
    "\n",
    "    kf = KFold(n_splits=folds)\n",
    "    print(f'Training using {folds}-fold cross-validation. \\n')\n",
    "\n",
    "    results = {}\n",
    "    best_score = float('-inf')\n",
    "    best_model = None\n",
    "    best_hyperparameters = {}\n",
    "\n",
    "    param_combinations = list(itertools.product(*hyperparameters.values()))\n",
    "\n",
    "    for combination in param_combinations:\n",
    "        update = dict(zip(hyperparameters.keys(), combination))\n",
    "        kwargs.update(update)\n",
    "        print(f'Beginning training with hyperparameters {update}...\\n')\n",
    "        st = time.time()\n",
    "        k_score = []\n",
    "        count = 1\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            print(f'Working on {count / folds} fold... ')\n",
    "            count += 1\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            built_model = model(**kwargs)\n",
    "            built_model.fit(X_train, y_train, callback_interval=1)\n",
    "            y_pred = built_model.predict(X_test)\n",
    "            score = mean_squared_error(y_test, y_pred)\n",
    "            k_score.append(score)\n",
    "        score = np.array(k_score).mean()\n",
    "        results[f'{update}'] = score\n",
    "        print(f'Training complete taking {time.time() - st} seconds. ')\n",
    "        if score > best_score:\n",
    "            print('Saving model as new best... \\n')\n",
    "            best_score = score\n",
    "            best_model = built_model  # not sure about this line. Maybe I should return a different version of the model\n",
    "            # or re-train the model on the entire set.\n",
    "            best_hyperparameters = {key: kwargs[key] for key in hyperparameters.keys()}\n",
    "        else:\n",
    "            print('Discarding model... \\n')\n",
    "\n",
    "    with open('Grid_search.json', 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "    return best_model, best_hyperparameters, best_score, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77d1f0-8918-42e4-abe9-1c7199346b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topdir='/home/grierjones/qregress'\n",
    "# settings=\"./function-calc-test/5qubits/A2-A2-CNOT_ESU2/A2-A2-CNOT_ESU2.json\"\n",
    "train_set=os.path.join(topdir,\"function-calc-test/quadratic/quadratic_train.bin\")\n",
    "test_set=os.path.join(topdir,\"function-calc-test/quadratic/quadratic_test.bin\")\n",
    "scaler=os.path.join(topdir,\"function-calc-test/quadratic/quadratic_scaler.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305ab97-7832-4499-994e-d24d451e9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings=[]\n",
    "for i in os.listdir('function-calc-test/quad5qubits'):\n",
    "    dirs=os.path.join('function-calc-test/quad5qubits',i)\n",
    "    if os.path.isdir(dirs):\n",
    "        jsonfile=os.path.join(dirs,f\"{i}.json\")\n",
    "        if os.path.isfile(jsonfile):\n",
    "            settings.append(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd0c52-f3d2-4d24-8ff9-fdb9b2dd55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=None\n",
    "instance=None\n",
    "token=None\n",
    "save_circuits=False\n",
    "title=None\n",
    "resume_file=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e2034-81e9-49d8-89df-590b6ab22508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(settingsfile):\n",
    "    namedir=os.path.dirname(settingsfile)\n",
    "    done=namedir+'.done'\n",
    "    if os.path.exists(done)==False:\n",
    "        print(done)\n",
    "        os.chdir(namedir)\n",
    "        main(os.path.join(topdir,settingsfile), train_set, test_set, scaler, instance, token, save_circuits, title, resume_file)\n",
    "        print(f'finished {namedir}')\n",
    "        os.chdir(topdir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb7b67-f138-49f8-b6ac-05575fbc41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(topdir)\n",
    "out = Parallel(n_jobs=-1, verbose=100, pre_dispatch='1.5*n_jobs')(delayed(run_all)(i) for i in settings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9735bb-52d1-4e94-8f5a-c0384653d73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qchem",
   "language": "python",
   "name": "qchem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
