{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87501e89-2ae2-4bf7-901a-7da783601a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import sys \n",
    "# !{sys.executable} -m pip install \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import click\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import collections.abc\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from pennylane_qiskit import qiskit_device\n",
    "from pennylane_qiskit.qiskit_device import qiskit_session\n",
    "\n",
    "from tqdm import tqdm\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Session\n",
    "from qiskit_ibm_runtime.fake_provider import FakeQuebec\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"12\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a5d64f-c8de-4684-a3fa-9f77cdf79e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 5) (20, 5)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "generator = np.random.default_rng(12958234)\n",
    "\n",
    "# Synthetic data\n",
    "X=generator.uniform(-1, 1, (100,5))\n",
    "y=generator.uniform(-1, 1, (100,))\n",
    "X_train, X_test, y_train, y_test = X[:80,:],X[80:,:],y[:80],y[80:]\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Define custom Dataset\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.X = torch.from_numpy(features).float()\n",
    "        self.y = torch.from_numpy(targets).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = None \n",
    "train_dataset = RegressionDataset(X_train, y_train)\n",
    "test_dataset = RegressionDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686640cb-b3bd-4b5d-bf3c-1fc08d5df311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27349ac8-e134-4e13-8961-f6b41035febb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ca6c8-64bc-432c-b7e9-98aff72a3140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1a919f-8b74-4ba0-a4dd-c64d659bde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initial ize device and circuit\n",
    "num_qubits=5\n",
    "re_upload_depth=1\n",
    "n_layers=1\n",
    "\n",
    "service = QiskitRuntimeService(channel=\"ibm_quantum\", \n",
    "                               instance='pinq-quebec-hub/univ-toronto/matterlab'\n",
    "                              )\n",
    "_backend = service.backend('ibm_quebec')\n",
    "\n",
    "dev = qml.device(\n",
    "    \"qiskit.remote\",\n",
    "    wires=127,\n",
    "    shots=1024,\n",
    "    backend=_backend,\n",
    "    resilience_level=1,\n",
    "    optimization_level=1,\n",
    "    seed_transpiler=42,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Simple circuit\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit(inputs, weights):\n",
    "    for i in range(re_upload_depth):\n",
    "        qml.AngleEmbedding(inputs, wires=range(num_qubits))\n",
    "        qml.BasicEntanglerLayers(weights, wires=range(num_qubits))\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7afaf90c-9874-473f-819f-081521e73f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': (1, 5)}\n",
      "Sequential(\n",
      "  (0): <Quantum Torch Layer: func=circuit>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize pytorch model\n",
    "weight_shapes = {\"weights\": (n_layers, num_qubits)}\n",
    "print(weight_shapes)\n",
    "qlayer = qml.qnn.TorchLayer(circuit, weight_shapes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.nn.Sequential(*[qlayer]).to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(qlayer.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c6693-a922-4f73-a7a9-e41bb0ec9055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23fb3361-3aab-49e2-8006-f59ae140eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cwgkxhp9r49g00861cbg', 'backend_name': 'ibm_quebec', 'interactive_timeout': 60, 'max_time': 7200, 'active_timeout': 7200, 'state': 'open', 'accepting_jobs': True, 'last_job_started': None, 'last_job_completed': None, 'started_at': None, 'closed_at': None, 'activated_at': None, 'mode': 'dedicated', 'usage_time': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                       | 0/10 [00:00<?, ?it/s]\n",
      "Train:   0%|                                                                                                                                                                                | 0/80 [10:08<?, ?it/s]\u001b[A\n",
      "  0%|                                                                                                                                                                                       | 0/10 [10:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IBMRuntimeError",
     "evalue": "'The session is closed.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIBMRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[0;32m---> 16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_X\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    523\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[1;32m    290\u001b[0m     tensors,\n\u001b[1;32m    291\u001b[0m     grad_tensors_,\n\u001b[1;32m    292\u001b[0m     retain_graph,\n\u001b[1;32m    293\u001b[0m     create_graph,\n\u001b[1;32m    294\u001b[0m     inputs,\n\u001b[1;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/torch/autograd/function.py:306\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    305\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane/workflow/interfaces/torch.py:101\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_backward\u001b[0;34m(ctx, *flat_grad_outputs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_backward\u001b[39m(ctx, \u001b[38;5;241m*\u001b[39mflat_grad_outputs):\n\u001b[1;32m    100\u001b[0m     grad_outputs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_grad_outputs, ctx\u001b[38;5;241m.\u001b[39m_out_struct)\n\u001b[0;32m--> 101\u001b[0m     grad_inputs \u001b[38;5;241m=\u001b[39m orig_bw(ctx, \u001b[38;5;241m*\u001b[39mgrad_outputs)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# None corresponds to the diff of out_struct_holder\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(grad_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane/workflow/interfaces/torch.py:186\u001b[0m, in \u001b[0;36mExecuteTapes.backward\u001b[0;34m(ctx, *dy)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Torch obeys the dL/dz_conj convention instead of the\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# dL/dz convention of PennyLane, autograd and jax. This converts between the formats\u001b[39;00m\n\u001b[1;32m    185\u001b[0m dy \u001b[38;5;241m=\u001b[39m _recursive_conj(dy)\n\u001b[0;32m--> 186\u001b[0m vjps \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mjpc\u001b[38;5;241m.\u001b[39mcompute_vjp(ctx\u001b[38;5;241m.\u001b[39mtapes, dy)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# split tensor into separate entries\u001b[39;00m\n\u001b[1;32m    188\u001b[0m unpacked_vjps \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane/workflow/jacobian_products.py:304\u001b[0m, in \u001b[0;36mTransformJacobianProducts.compute_vjp\u001b[0;34m(self, tapes, dy)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_vjps(jacs, dy, tapes)\n\u001b[1;32m    300\u001b[0m vjp_tapes, processing_fn \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mgradients\u001b[38;5;241m.\u001b[39mbatch_vjp(\n\u001b[1;32m    301\u001b[0m     tapes, dy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_transform, gradient_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_kwargs\n\u001b[1;32m    302\u001b[0m )\n\u001b[0;32m--> 304\u001b[0m vjp_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_execute(\u001b[38;5;28mtuple\u001b[39m(vjp_tapes))\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(processing_fn(vjp_results))\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane/workflow/execution.py:212\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes, **_)\u001b[0m\n\u001b[1;32m    209\u001b[0m transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m transform_program(tapes)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[0;32m--> 212\u001b[0m     results \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mexecute(transformed_tapes, execution_config\u001b[38;5;241m=\u001b[39mexecution_config)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     results \u001b[38;5;241m=\u001b[39m ()\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane_qiskit/qiskit_device.py:66\u001b[0m, in \u001b[0;36mcustom_simulator_tracking.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(tracked_execute)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config\u001b[38;5;241m=\u001b[39mDefaultExecutionConfig):\n\u001b[0;32m---> 66\u001b[0m     results \u001b[38;5;241m=\u001b[39m tracked_execute(\u001b[38;5;28mself\u001b[39m, circuits, execution_config)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mactive:\n\u001b[1;32m     68\u001b[0m         res \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane/devices/modifiers/simulator_tracking.py:30\u001b[0m, in \u001b[0;36m_track_execute.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(untracked_execute)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config\u001b[38;5;241m=\u001b[39mDefaultExecutionConfig):\n\u001b[0;32m---> 30\u001b[0m     results \u001b[38;5;241m=\u001b[39m untracked_execute(\u001b[38;5;28mself\u001b[39m, circuits, execution_config)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuits, QuantumScript):\n\u001b[1;32m     32\u001b[0m         batch \u001b[38;5;241m=\u001b[39m (circuits,)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane_qiskit/qiskit_device.py:590\u001b[0m, in \u001b[0;36mQiskitDevice.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m         session\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 590\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m execute_circuits(session) \u001b[38;5;28;01mas\u001b[39;00m results:\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane_qiskit/qiskit_device.py:585\u001b[0m, in \u001b[0;36mQiskitDevice.execute.<locals>.execute_circuits\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m             execute_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_sampler\n\u001b[0;32m--> 585\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(execute_fn(circ, session))\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m results\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/pennylane_qiskit/qiskit_device.py:656\u001b[0m, in \u001b[0;36mQiskitDevice._execute_estimator\u001b[0;34m(self, circuit, session)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# split into one call per measurement\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# could technically be more efficient if there are some observables where we ask\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# for expectation value and variance on the same observable, but spending time on\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# that right now feels excessive\u001b[39;00m\n\u001b[1;32m    655\u001b[0m circ_and_obs \u001b[38;5;241m=\u001b[39m [(compiled_circuits[\u001b[38;5;241m0\u001b[39m], pauli_observables)]\n\u001b[0;32m--> 656\u001b[0m result \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    657\u001b[0m     circ_and_obs,\n\u001b[1;32m    658\u001b[0m     precision\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m circuit\u001b[38;5;241m.\u001b[39mshots\u001b[38;5;241m.\u001b[39mtotal_shots) \u001b[38;5;28;01mif\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    659\u001b[0m )\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_job \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    661\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_estimator_job(circuit\u001b[38;5;241m.\u001b[39mmeasurements, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/qiskit_ibm_runtime/estimator.py:193\u001b[0m, in \u001b[0;36mEstimatorV2.run\u001b[0;34m(self, pubs, precision)\u001b[0m\n\u001b[1;32m    191\u001b[0m coerced_pubs \u001b[38;5;241m=\u001b[39m [EstimatorPub\u001b[38;5;241m.\u001b[39mcoerce(pub, precision) \u001b[38;5;28;01mfor\u001b[39;00m pub \u001b[38;5;129;01min\u001b[39;00m pubs]\n\u001b[1;32m    192\u001b[0m validate_estimator_pubs(coerced_pubs)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(coerced_pubs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/qiskit_ibm_runtime/base_primitive.py:187\u001b[0m, in \u001b[0;36mBasePrimitiveV2._run\u001b[0;34m(self, pubs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Batch or Session\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    188\u001b[0m         program_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_program_id(),\n\u001b[1;32m    189\u001b[0m         inputs\u001b[38;5;241m=\u001b[39mprimitive_inputs,\n\u001b[1;32m    190\u001b[0m         options\u001b[38;5;241m=\u001b[39mruntime_options,\n\u001b[1;32m    191\u001b[0m         callback\u001b[38;5;241m=\u001b[39moptions_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    192\u001b[0m         result_decoder\u001b[38;5;241m=\u001b[39mDEFAULT_DECODERS\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_program_id()),\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend:\n\u001b[1;32m    196\u001b[0m     runtime_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\n",
      "File \u001b[0;32m~/miniconda3/envs/qml_min/lib/python3.12/site-packages/qiskit_ibm_runtime/session.py:41\u001b[0m, in \u001b[0;36m_active_session.<locals>._wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active:\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IBMRuntimeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe session is closed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mIBMRuntimeError\u001b[0m: 'The session is closed.'"
     ]
    }
   ],
   "source": [
    "\n",
    "with qiskit_session(dev,max_time='2h') as session:\n",
    "    print(session.details())\n",
    "    # Training loop\n",
    "    epochs = 10\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_X, batch_y in tqdm(train_loader, desc=\"Train\"):\n",
    "            optimizer.zero_grad()\n",
    "            batch_X=batch_X.to(device)\n",
    "            batch_y=batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * batch_X.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in tqdm(test_loader, desc=\"Test\"):\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                test_running_loss += loss.item() * batch_X.size(0)\n",
    "        test_epoch_loss = test_running_loss / len(test_loader.dataset)\n",
    "        test_losses.append(test_epoch_loss)\n",
    "        \n",
    "        if (epoch+1) % 1 == 0 or epoch == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {epoch_loss:.4f} - Test Loss: {test_epoch_loss:.4f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            outputs = model(batch_X)\n",
    "            predictions.extend(outputs.squeeze().tolist())\n",
    "            actuals.extend(batch_y.squeeze().tolist())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167e091-c46c-45ce-9300-f07535c48b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(actuals, predictions)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "print(f\"\\nTest MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R$^2$: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e967d86-e216-4a1c-8398-abc446fa019e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
