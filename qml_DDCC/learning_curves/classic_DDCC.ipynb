{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17c4e4-a535-47b9-940d-acb1c3085816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import sys\n",
    "# !{sys.executable} -m pip install tqdm seaborn \n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72f247-00d6-4584-a7d5-935947db4c3e",
   "metadata": {},
   "source": [
    "# Split data if not already made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b6bb5-9228-471a-b1f3-8fa32ba4f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsize=[ 0.1,0.3, 0.5, 0.7,0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d71b3-0738-4c8b-99a6-171df5c76390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gaussian_kernel = RBF()\n",
    "\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'elastic': ElasticNet(),\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'rfr': RandomForestRegressor(),\n",
    "    'grad': GradientBoostingRegressor(),\n",
    "    'svr': SVR(),\n",
    "    'krr': KernelRidge(),\n",
    "    'gpr': GaussianProcessRegressor()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'ridge': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10, 50, 100, 1000]\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': range(1, 10),\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'rfr': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'grad': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'svr': {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.1, 0.01, 0.001]\n",
    "    },\n",
    "    'krr': {\n",
    "        'kernel': ['linear', 'poly', 'rbf'],\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001]\n",
    "    },\n",
    "    'gpr': {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "        'kernel': [gaussian_kernel]\n",
    "    },\n",
    "    'lasso': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    },\n",
    "    'elastic': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'l1_ratio': [0.2, 0.5, 0.8],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbc2c7-5b1e-4685-a922-3a812a7fb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model,X_tr, y_tr,X_tst,y_tst):\n",
    "    \"\"\"\n",
    "    Perform GridSearchCV for a given model\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    model: str\n",
    "        Name of model\n",
    "\n",
    "    X_tr: np.array\n",
    "        X training\n",
    "\n",
    "    y_tr: np.array\n",
    "        Y Training\n",
    "\n",
    "    X_tst: np.array\n",
    "        X test\n",
    "\n",
    "    y_tst: np.array\n",
    "        y test\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scores: dict\n",
    "        scored models\n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "    # Grab model and model parameters to perform gridsearchcv\n",
    "    current_model = models[model]\n",
    "    current_param_grid = param_grid[model]\n",
    "\n",
    "    grid_search = GridSearchCV(current_model, current_param_grid, cv=5,n_jobs=-1)\n",
    "\n",
    "    print(f'Now fitting {model}... ')\n",
    "\n",
    "    grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f'Completed fitting {model} in {time.time() - st} seconds. ')\n",
    "\n",
    "    # Take the best model and evaluate using known metrics\n",
    "    model=best_model\n",
    "    scores = {}\n",
    "    st = time.time()\n",
    "    print('Now scoring model... ')\n",
    "    y_tr_pred = model.predict(X_tr)\n",
    "    y_tst_pred = model.predict(X_tst)\n",
    "\n",
    "    plt.scatter(y_tr,y_tr_pred)\n",
    "    plt.scatter(y_tst,y_tst_pred)\n",
    "    plt.scatter(y_tr, y_tr)\n",
    "    plt.scatter(y_tst,y_tst)\n",
    "    plt.show()\n",
    "            \n",
    "    scores['MSE_train'] = mean_squared_error(y_tr, y_tr_pred),\n",
    "    scores['R2_train'] = r2_score(y_tr, y_tr_pred)\n",
    "    scores['MAE_train'] = mean_absolute_error(y_tr, y_tr_pred)\n",
    "    scores['MSE_test'] = mean_squared_error(y_tst, y_tst_pred)\n",
    "    scores['R2_test'] = r2_score(y_tst, y_tst_pred)\n",
    "    scores['MAE_test'] = mean_absolute_error(y_tst, y_tst_pred)\n",
    "\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae194fbb-0152-4a2b-afb5-b6eb46b86ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd667055-8d01-462f-ba7d-5ee7a5adcd7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over function dirs and training set sizes \n",
    "# At the end of the loop save the scores\n",
    "\n",
    "performance={}\n",
    "for ts in tqdm(trainsize):\n",
    "    \n",
    "\n",
    "    \n",
    "    with open(f\"./{ts}/{ts}_5_DDCC_train.bin\",'rb') as f:\n",
    "        traindata=joblib.load(f)\n",
    "    \n",
    "    with open(f\"./{ts}/{ts}_5_DDCC_test.bin\",'rb') as f:\n",
    "        testdata=joblib.load(f)\n",
    "        \n",
    "    \n",
    "            \n",
    "    X_train=traindata['X']\n",
    "    y_train=traindata['y'].reshape(-1,)\n",
    "    X_test=testdata['X']\n",
    "    y_test=testdata['y'].reshape(-1,)       \n",
    "\n",
    "    performance[ts]={}\n",
    "    for model in models.keys():\n",
    "        scores=gridsearch(model,X_train, y_train,X_test,y_test)\n",
    "        performance[ts][model]=scores\n",
    "\n",
    "        # Save scores to json\n",
    "        with open(os.path.join(f\"{ts}_{model}_scores.json\"), 'w') as outfile:\n",
    "            json.dump(scores, outfile)\n",
    "            print(f'Scores saved as {outfile.name}. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b96a3d-0f7d-4a28-b6c5-fe0df8624e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in performance.items():\n",
    "    print(k,pd.DataFrame(v).T.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ec5d0-7a41-4622-9d64-be3e0e37299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(function):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    function: str\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "    best: tuple\n",
    "        (model, count)\n",
    "    \"\"\"\n",
    "    dfmelt=[]\n",
    "    for k,v in performance[function].items():\n",
    "        df=pd.DataFrame.from_dict(v).loc[['R2_train','R2_test']].T\n",
    "        df.columns=[df.columns,[k,k]]\n",
    "        dfmelt.append(df.melt(value_vars=df.columns.tolist(),ignore_index=False))\n",
    "    dfmelt=pd.concat(dfmelt)\n",
    "    \n",
    "    pivottable=dfmelt.reset_index().pivot_table(index=['index','variable_1'], columns='variable_0').astype(float).T\n",
    "    \n",
    "    stackedstats=[]\n",
    "    for c in pivottable.columns.levels[0]:\n",
    "        dsc=pivottable[c].T.describe().loc[['mean','min','max']]\n",
    "        dsc=dsc.rename(columns={'value':c})\n",
    "        stackedstats.append(dsc.T.mean().to_frame().rename(columns={0:c}))\n",
    "    stackedstats=pd.concat(stackedstats,axis=1)\n",
    "    \n",
    "    best=stackedstats.T.idxmax()\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a9fc5-ba42-44ec-b223-ea9d656818fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestdf=pd.DataFrame.from_dict({k: find_best(k) for k,v in performance.items()}).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bee6e7-1676-42e2-8b88-80f60c81d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestdf.to_excel('best.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13bb6c-0b7f-4e96-b7a2-9877f71ed682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bar(name):\n",
    "    meltdef=[]\n",
    "    for k,v in performance[name].items():\n",
    "        for k1,v1 in v.items():\n",
    "            for k2,v2 in v1.items():\n",
    "                if \"R2\" in k2:\n",
    "                    meltdef.append((k,k1,k2.replace('R2','R$^{2}$').replace('_',' '),v2))\n",
    "                    \n",
    "    df=pd.DataFrame(meltdef,columns=['Train','Model','Metric','Score'])\n",
    "\n",
    "    BIGGER_SIZE = 12\n",
    "    \n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title    \n",
    "    sns.set_theme(style='white')\n",
    "\n",
    "    g=sns.catplot(\n",
    "        df, kind=\"bar\",\n",
    "        x=\"Train\", y=\"Score\", col=\"Model\", hue='Metric',\n",
    "        height=3.5, aspect=1, col_wrap=5,palette=sns.color_palette(\"Paired\",2)\n",
    "    )\n",
    "    # g.fig.set_size_inches(20,50)\n",
    "    # extract the matplotlib axes_subplot objects from the FacetGrid\n",
    "    for ax in g.axes.ravel():\n",
    "        # iterate through the axes containers\n",
    "        for c in ax.containers:\n",
    "            ax.bar_label(c, fmt='{:.2f}',fontsize=10)\n",
    "\n",
    "    \n",
    "    g.set_axis_labels(\"Training Set Ratio\", \"R$^{2}$\")\n",
    "    g.set_titles(\"{col_var}={col_name}\",y=1,pad=20)\n",
    "    sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "    g.set(ylim=(0, 1))\n",
    "    g.fig.suptitle(f\"{name}\".capitalize())\n",
    "    # plt.title(f\"{name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{name}.png',dpi=300,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ea514-70d4-4bd0-a6e6-12aed36d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dirs: \n",
    "    print(i)\n",
    "    save_bar(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
